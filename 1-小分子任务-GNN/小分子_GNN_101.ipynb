{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **å®‰è£…ä¾èµ–åº“**"
      ],
      "metadata": {
        "id": "X7AN78JLc32N"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QIYUh0E2dZw"
      },
      "source": [
        "## **ä½œè€…ç®€ä»‹**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X91JIVkqUNMV"
      },
      "source": [
        "#### ä½œè€…ï¼š**âš¡å°é—ªç”µâš¡**\n",
        "\n",
        "#### Bç«™ä¸»é¡µ\n",
        "- [å°é—ªç”µçš„Bç«™ä¸»é¡µ](https://space.bilibili.com/122699831?spm_id_from=333.1007.0.0)\n",
        "\n",
        "#### äº¤æµç¾¤\n",
        "æ¬¢è¿åŠ å…¥AIDDäº¤æµç¾¤ï¼  \n",
        "åŠ æˆ‘å¾®ä¿¡ï¼ˆå¾®ä¿¡å·: `xxxFLASHxxx`ï¼‰ï¼Œé‚€è¯·ä½ è¿›ç¾¤ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RahmMfxUWFX"
      },
      "source": [
        "## **å®‰è£…ä¾èµ–åº“**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cf3YlQPJkqE"
      },
      "outputs": [],
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "!pip install rdkit\n",
        "!pip install networkx pandas\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_geometric.datasets import KarateClub\n",
        "dataset = KarateClub()\n",
        "print(f'Dataset: {dataset}:')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **å°åˆ†å­æè¿°ç¬¦ã€æŒ‡çº¹åŠMLP**"
      ],
      "metadata": {
        "id": "4dal0iSwZVDO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2crFDtBL5y2"
      },
      "source": [
        "## **æ•°æ®åˆ†æå¯è§†åŒ–**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nt-BbUtRZor"
      },
      "source": [
        "### å…ˆçœ‹çœ‹æ•°æ®é›†çš„ç”œåº¦åˆ†å¸ƒ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jbneh_1KQp0S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ==========================================\n",
        "# 1. åŠ è½½æ•°æ®\n",
        "# ==========================================\n",
        "csv_path = '/content/SweetpredDB.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "print(f\"æ•°æ®åŠ è½½æˆåŠŸï¼å…±åŒ…å« {len(df)} ä¸ªæ ·æœ¬ã€‚\")\n",
        "print(\"å‰5è¡Œæ•°æ®é¢„è§ˆï¼š\")\n",
        "print(df[['Smiles', 'logSw']].head())\n",
        "\n",
        "# ==========================================\n",
        "# 2. å¯è§†åŒ–ç”œåº¦å€¼ (logSw) åˆ†å¸ƒ\n",
        "# ==========================================\n",
        "\n",
        "# è®¾ç½®é«˜æ¸… DPI\n",
        "plt.rcParams['figure.dpi'] = 600\n",
        "plt.rcParams['savefig.dpi'] = 600\n",
        "sns.set_style(\"whitegrid\") # è®¾ç½®èƒŒæ™¯ç½‘æ ¼\n",
        "\n",
        "# å®šä¹‰é¢œè‰²\n",
        "color_blue = (75 / 255, 116 / 255, 178 / 255)\n",
        "color_red = (219 / 255, 49 / 255, 36 / 255)\n",
        "\n",
        "plt.figure(figsize=(10, 6),dpi=100)\n",
        "\n",
        "# ç»˜åˆ¶ç›´æ–¹å›¾ + KDE å¯†åº¦æ›²çº¿\n",
        "sns.histplot(\n",
        "    data=df,\n",
        "    x='logSw',\n",
        "    kde=True,\n",
        "    color=color_blue,\n",
        "    bins=30,\n",
        "    edgecolor='white',\n",
        "    alpha=0.7,\n",
        "    line_kws={'linewidth': 2}\n",
        ")\n",
        "\n",
        "# æ·»åŠ é˜ˆå€¼çº¿ (x=3)\n",
        "plt.axvline(x=3, color=color_red, linestyle='--', linewidth=2, label='Threshold (3.0)')\n",
        "\n",
        "# æ·»åŠ å¹³å‡å€¼çº¿\n",
        "mean_val = df['logSw'].mean()\n",
        "plt.axvline(x=mean_val, color='gray', linestyle=':', linewidth=2, label=f'Mean ({mean_val:.2f})')\n",
        "\n",
        "# æ·»åŠ æ–‡å­—æ ‡æ³¨\n",
        "plt.text(3.1, plt.gca().get_ylim()[1]*0.85, 'High Sweetness (>3)',\n",
        "         color=color_red, fontsize=11, fontweight='bold')\n",
        "plt.text(2.9, plt.gca().get_ylim()[1]*0.85, 'Low Sweetness (<=3)',\n",
        "         color=color_blue, fontsize=11, fontweight='bold', ha='right')\n",
        "\n",
        "# å›¾è¡¨è®¾ç½®\n",
        "plt.title('Distribution of Sweetness Values (logSw)', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('logSw Value', fontsize=12)\n",
        "plt.ylabel('Count / Density', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTatl317Rea4"
      },
      "source": [
        "### è®¡ç®—åˆ†å­æè¿°ç¬¦å’Œåˆ†å­æŒ‡çº¹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iak7sIq5I-G0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import logging\n",
        "from rdkit import Chem\n",
        "from rdkit import rdBase\n",
        "from rdkit.Chem import Descriptors, AllChem, Draw\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "\n",
        "# ==========================================\n",
        "# é…ç½®ä¸è®¾ç½®\n",
        "# ==========================================\n",
        "\n",
        "# 1. å±è”½ Python è­¦å‘Š\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 2. å±è”½ RDKit è­¦å‘Š\n",
        "rdBase.DisableLog('rdApp.warning')\n",
        "\n",
        "# 3. å±è”½ Matplotlib å­—ä½“æŸ¥æ‰¾è­¦å‘Š (è§£å†³ SimHei not found åˆ·å±)\n",
        "logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)\n",
        "\n",
        "# 4. å¯ç”¨ Colab çš„äº¤äº’å¼è¡¨æ ¼æ˜¾ç¤º\n",
        "try:\n",
        "    from google.colab import data_table\n",
        "    data_table.enable_dataframe_formatter()\n",
        "except ImportError:\n",
        "    print(\"æ³¨æ„: å½“å‰ç¯å¢ƒé Google Colabï¼Œæ— æ³•ä½¿ç”¨äº¤äº’å¼è¡¨æ ¼åŠŸèƒ½ã€‚\")\n",
        "\n",
        "# è®¾ç½®ç»˜å›¾é£æ ¼ (ç§»é™¤ SimHei è®¾ç½®ä»¥é¿å…è­¦å‘Šï¼Œä½¿ç”¨é»˜è®¤å­—ä½“)\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "# plt.rcParams['font.sans-serif'] = ['SimHei'] # æ³¨é‡Šæ‰è¿™è¡Œï¼Œé¿å…æŠ¥é”™\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# ==========================================\n",
        "# 1. æ•°æ®åŠ è½½ä¸ç‰¹å¾è®¡ç®—å‡½æ•°\n",
        "# ==========================================\n",
        "\n",
        "def get_mol_descriptors(mol):\n",
        "    \"\"\"è®¡ç®—å¸¸ç”¨çš„åˆ†å­æè¿°ç¬¦\"\"\"\n",
        "    return {\n",
        "        'MolWt': Descriptors.MolWt(mol),           # åˆ†å­é‡\n",
        "        'LogP': Descriptors.MolLogP(mol),          # è„‚æ°´åˆ†é…ç³»æ•°\n",
        "        'NumHDonors': Descriptors.NumHDonors(mol), # æ°¢é”®ä¾›ä½“æ•°\n",
        "        'NumHAcceptors': Descriptors.NumHAcceptors(mol), # æ°¢é”®å—ä½“æ•°\n",
        "        'TPSA': Descriptors.TPSA(mol),             # æ‹“æ‰‘ææ€§è¡¨é¢ç§¯\n",
        "        'RotatableBonds': Descriptors.NumRotatableBonds(mol) # å¯æ—‹è½¬é”®æ•°\n",
        "    }\n",
        "\n",
        "def get_morgan_fingerprint(mol, n_bits=2048):\n",
        "    \"\"\"è®¡ç®—Morganåˆ†å­æŒ‡çº¹ (ECFP4)\"\"\"\n",
        "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=n_bits)\n",
        "    return np.array(fp)\n",
        "\n",
        "# åŠ è½½æ•°æ®\n",
        "csv_path = '/content/SweetpredDB.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# æ¸…æ´—æ•°æ®ï¼šç§»é™¤æ— æ•ˆåˆ†å­\n",
        "valid_data = []\n",
        "\n",
        "print(\"æ­£åœ¨è®¡ç®—åˆ†å­ç‰¹å¾...\")\n",
        "\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing Molecules\"):\n",
        "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
        "    if mol is not None:\n",
        "        # è®¡ç®—æè¿°ç¬¦\n",
        "        desc = get_mol_descriptors(mol)\n",
        "        # è®¡ç®—æŒ‡çº¹\n",
        "        fp = get_morgan_fingerprint(mol)\n",
        "\n",
        "        entry = {\n",
        "            'Smiles': row['Smiles'],\n",
        "            'logSw': row['logSw'],\n",
        "            'Fingerprint': fp, # è¿™æ˜¯ä¸€ä¸ªé•¿åº¦2048çš„æ•°ç»„\n",
        "            'Mol': mol\n",
        "        }\n",
        "        entry.update(desc)\n",
        "        valid_data.append(entry)\n",
        "\n",
        "df_processed = pd.DataFrame(valid_data)\n",
        "print(f\"\\næ•°æ®å¤„ç†å®Œæˆã€‚åŸå§‹æ•°é‡: {len(df)}, æœ‰æ•ˆæ•°é‡: {len(df_processed)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hrOG52EMIXB"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 2. å•ä¸ªåˆ†å­å¯è§†åŒ–ä¸ç‰¹å¾å±•ç¤º\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"åˆ†å­å±•ç¤º\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "if not df_processed.empty:\n",
        "    sample_row = df_processed.sample(1).iloc[0]\n",
        "\n",
        "    # ç»˜åˆ¶åˆ†å­ç»“æ„\n",
        "    img = Draw.MolToImage(sample_row['Mol'], size=(300, 300))\n",
        "    plt.figure(figsize=(4, 4),dpi=100)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"LogSw: {sample_row['logSw']:.2f}\")\n",
        "    plt.show()\n",
        "\n",
        "    # æ‰“å°æ–‡æœ¬ä¿¡æ¯\n",
        "    print(f\"SMILES: {sample_row['Smiles']}\")\n",
        "    print(\"-\" * 20)\n",
        "    print(\"åˆ†å­æè¿°ç¬¦ (Descriptors):\")\n",
        "    for k in ['MolWt', 'LogP', 'NumHDonors', 'NumHAcceptors', 'TPSA', 'RotatableBonds']:\n",
        "        print(f\"{k}: {sample_row[k]:.2f}\")\n",
        "    print(\"-\" * 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSEpN5WdMRkU"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 3. ä½¿ç”¨ Colab è¡¨æ ¼å±•ç¤ºæ•°æ® (éšæœºæŠ½æ ·)\n",
        "# ==========================================\n",
        "from google.colab import data_table\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"éšæœºæŠ½å– 10 ä¸ªåˆ†å­çš„æŒ‡çº¹é¢„è§ˆ\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "if not df_processed.empty:\n",
        "    # 1. éšæœºæŠ½å– 10 è¡Œ (å¦‚æœæ€»æ•°ä¸è¶³10åˆ™æŠ½å–å…¨éƒ¨)\n",
        "    # random_state=42 ä¿è¯æ¯æ¬¡æŠ½åˆ°çš„éƒ½æ˜¯åŒæ ·çš„ä¸€æ‰¹ï¼Œæƒ³å®Œå…¨éšæœºå¯ä»¥å»æ‰å®ƒ\n",
        "    sample_size = min(20, len(df_processed))\n",
        "    sampled_df = df_processed.sample(n=sample_size, random_state=42)\n",
        "\n",
        "    # 2. å±•å¼€æŒ‡çº¹ (å…³é”®ï¼šæŒ‡å®š index=sampled_df.index ä»¥ä¾¿ä¸åŸå§‹æ•°æ®å¯¹é½)\n",
        "    fp_expanded = pd.DataFrame(sampled_df['Fingerprint'].tolist(), index=sampled_df.index)\n",
        "    fp_expanded.columns = [f'FP_{i}' for i in range(fp_expanded.shape[1])]\n",
        "\n",
        "    # 3. åˆå¹¶ Smiles å’Œ æŒ‡çº¹åˆ—\n",
        "    display_df = pd.concat([sampled_df[['Smiles']], fp_expanded], axis=1)\n",
        "\n",
        "    # 4. è®¾ç½® Colab è¡¨æ ¼çš„æœ€å¤§åˆ—æ•°é™åˆ¶\n",
        "    data_table.DataTable.max_columns = 2100\n",
        "\n",
        "    # 5. æ˜¾ç¤ºè¡¨æ ¼\n",
        "    display(display_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrqRh__GRjpn"
      },
      "source": [
        "### ç…ä¸€ç…å„ç§åˆ†å­æè¿°ç¬¦å’Œç”œåº¦å…³ç³»å¤§ä¸å¤§"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeYo3WA8PIHi"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# ==========================================\n",
        "# 2. å¯è§†åŒ–é…ç½®ä¸æ•°æ®å‡†å¤‡\n",
        "# ==========================================\n",
        "\n",
        "# è®¾ç½®å…¨å±€ DPI ä¸º 600ï¼Œä¿è¯æ‰€æœ‰å›¾è¡¨è¾“å‡ºçš„é«˜æ¸…è´¨é‡\n",
        "plt.rcParams['figure.dpi'] = 200\n",
        "plt.rcParams['savefig.dpi'] = 200\n",
        "\n",
        "# å®šä¹‰é¢œè‰² (æŒ‰ä½ è¦æ±‚çš„ RGB å½’ä¸€åŒ–)\n",
        "color_blue = (75 / 255, 116 / 255, 178 / 255)  # ä½ç”œ\n",
        "color_red = (219 / 255, 49 / 255, 36 / 255)    # é«˜ç”œ\n",
        "custom_palette = [color_blue, color_red]\n",
        "\n",
        "# å®šä¹‰éœ€è¦åˆ†æçš„æè¿°ç¬¦åˆ—å\n",
        "descriptor_cols = ['MolWt', 'LogP', 'NumHDonors', 'NumHAcceptors', 'TPSA', 'RotatableBonds']\n",
        "\n",
        "# åˆ’åˆ†ç”œåº¦ç±»åˆ«ï¼šä»¥ 3 ä¸ºç•Œé™\n",
        "# è¿™é‡Œå‡è®¾ logSw æ˜¯ä½ çš„ç”œåº¦æŒ‡æ ‡\n",
        "df_processed['Sweetness_Class'] = df_processed['logSw'].apply(\n",
        "    lambda x: 'High Sweetness (>3)' if x > 3 else 'Low Sweetness (<=3)'\n",
        ")\n",
        "\n",
        "# ç¡®ä¿åˆ†ç±»é¡ºåº (Low -> Blue, High -> Red)\n",
        "class_order = ['Low Sweetness (<=3)', 'High Sweetness (>3)']\n",
        "\n",
        "# ==========================================\n",
        "# 3. å¯è§†åŒ– Aï¼šåˆ†å­æè¿°ç¬¦ä¸ç”œåº¦çš„çº¿æ€§å…³ç³» (æ•£ç‚¹ + æ‹Ÿåˆçº¿)\n",
        "# ==========================================\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(descriptor_cols):\n",
        "    # ä½¿ç”¨ regplot ç»˜åˆ¶æ•£ç‚¹å’Œçº¿æ€§å›å½’æ‹Ÿåˆçº¿\n",
        "    sns.regplot(\n",
        "        x=col,\n",
        "        y='logSw',\n",
        "        data=df_processed,\n",
        "        ax=axes[i],\n",
        "        scatter_kws={'alpha': 0.5, 'color': 'gray', 's': 15}, # æ•£ç‚¹æ ·å¼\n",
        "        line_kws={'color': 'black', 'linewidth': 1.5}         # æ‹Ÿåˆçº¿æ ·å¼\n",
        "    )\n",
        "    axes[i].set_title(f'{col} vs logSw', fontsize=12, fontweight='bold')\n",
        "    axes[i].set_xlabel(col)\n",
        "    axes[i].set_ylabel('logSw (Sweetness)')\n",
        "\n",
        "plt.suptitle('Linear Relationship: Molecular Descriptors vs Sweetness', fontsize=16, y=1.02)\n",
        "plt.tight_layout()\n",
        "# å¦‚æœéœ€è¦ä¿å­˜å›¾ç‰‡ï¼Œå¯ä»¥ä½¿ç”¨ plt.savefig('scatter_plots.png')\n",
        "plt.show()\n",
        "\n",
        "# ==========================================\n",
        "# 4. å¯è§†åŒ– Bï¼šé«˜ç”œ vs ä½ç”œ çš„æè¿°ç¬¦åˆ†å¸ƒ (ç®±çº¿å›¾)\n",
        "# ==========================================\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(descriptor_cols):\n",
        "    # ç®±çº¿å›¾\n",
        "    sns.boxplot(\n",
        "        x='Sweetness_Class',\n",
        "        y=col,\n",
        "        data=df_processed,\n",
        "        order=class_order,\n",
        "        palette=custom_palette,\n",
        "        ax=axes[i],\n",
        "        width=0.5,\n",
        "        showfliers=False # ä¸æ˜¾ç¤ºå¼‚å¸¸å€¼ç‚¹ï¼Œé¿å…å¤ªä¹±ï¼Œç”± stripplot å±•ç¤º\n",
        "    )\n",
        "    # æŠ–åŠ¨æ•£ç‚¹å›¾ (å±•ç¤ºçœŸå®æ•°æ®åˆ†å¸ƒ)\n",
        "    sns.stripplot(\n",
        "        x='Sweetness_Class',\n",
        "        y=col,\n",
        "        data=df_processed,\n",
        "        order=class_order,\n",
        "        color=\".25\",\n",
        "        alpha=0.3,\n",
        "        size=3,\n",
        "        ax=axes[i]\n",
        "    )\n",
        "\n",
        "    axes[i].set_title(f'{col} Distribution', fontsize=12, fontweight='bold')\n",
        "    axes[i].set_xlabel('')\n",
        "    axes[i].set_ylabel(col)\n",
        "\n",
        "plt.suptitle('Distribution Comparison: High vs Low Sweetness', fontsize=16, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# ==========================================\n",
        "# 1. ç›¸å…³æ€§çƒ­åŠ›å›¾ (ClusterMap)\n",
        "# ==========================================\n",
        "print(\">>> [1/2] æ­£åœ¨ç»˜åˆ¶ç›¸å…³æ€§èšç±»çƒ­åŠ›å›¾ (ClusterMap)...\")\n",
        "\n",
        "# ç¡®ä¿ descriptor_cols å·²å®šä¹‰\n",
        "if 'descriptor_cols' not in locals():\n",
        "    descriptor_cols = ['MolWt', 'LogP', 'NumHDonors', 'NumHAcceptors', 'TPSA', 'RotatableBonds']\n",
        "\n",
        "# é€‰æ‹©ç”¨äºè®¡ç®—ç›¸å…³æ€§çš„æ•°å€¼åˆ— (æè¿°ç¬¦ + ç”œåº¦)\n",
        "cols_to_plot = descriptor_cols + ['logSw']\n",
        "\n",
        "# è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µ\n",
        "corr_matrix = df_processed[cols_to_plot].corr()\n",
        "\n",
        "# ç»˜åˆ¶èšç±»çƒ­åŠ›å›¾\n",
        "g = sns.clustermap(\n",
        "    corr_matrix,\n",
        "    annot=True,       # æ˜¾ç¤ºæ•°å€¼\n",
        "    fmt=\".2f\",        # æ•°å€¼ä¿ç•™2ä½å°æ•°\n",
        "    cmap='coolwarm',  # çº¢è“é…è‰²\n",
        "    center=0,         # é¢œè‰²ä¸­å¿ƒè®¾ä¸º0\n",
        "    figsize=(6, 6),\n",
        "    linewidths=.75,   # æ ¼å­è¾¹æ¡†å®½åº¦\n",
        "    cbar_kws={\"shrink\": .5},\n",
        "    dendrogram_ratio=(.15, .15)\n",
        ")\n",
        "\n",
        "plt.suptitle('Molecular Descriptors Correlation ClusterMap', y=1.02, fontsize=18)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R5H_fJOFK6w7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 0. å®‰è£…ä¾èµ– (å¦‚æœå°šæœªå®‰è£…)\n",
        "# ==========================================\n",
        "!pip install pyvis\n",
        "\n",
        "import networkx as nx\n",
        "from pyvis.network import Network\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import AllChem, Draw\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import base64\n",
        "from io import BytesIO\n",
        "import matplotlib.colors as mcolors\n",
        "import matplotlib.cm as cm\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# ==========================================\n",
        "# 1. è¾…åŠ©å‡½æ•°å®šä¹‰\n",
        "# ==========================================\n",
        "\n",
        "def mol_to_base64_html(mol):\n",
        "    \"\"\"å°† RDKit åˆ†å­å¯¹è±¡è½¬æ¢ä¸ºç®€å•çš„ HTML img æ ‡ç­¾\"\"\"\n",
        "    if mol is None:\n",
        "        return \"\"\n",
        "    img = Draw.MolToImage(mol, size=(200, 200))\n",
        "    buffered = BytesIO()\n",
        "    img.save(buffered, format=\"PNG\")\n",
        "    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
        "    # è¿”å› img æ ‡ç­¾\n",
        "    return f'<img src=\"data:image/png;base64,{img_str}\" width=\"200\" height=\"200\">'\n",
        "\n",
        "def get_color_hex(value, vmin, vmax, cmap_name='coolwarm'):\n",
        "    norm = mcolors.Normalize(vmin=vmin, vmax=vmax)\n",
        "    cmap = cm.get_cmap(cmap_name)\n",
        "    rgba = cmap(norm(value))\n",
        "    return mcolors.to_hex(rgba)\n",
        "\n",
        "# ==========================================\n",
        "# 2. æ•°æ®å‡†å¤‡ï¼šå¼ºåˆ¶å¹³è¡¡é‡‡æ ·\n",
        "# ==========================================\n",
        "print(\">>> [1/3] æ­£åœ¨å‡†å¤‡å¹³è¡¡çš„é«˜ç”œ/ä½ç”œåˆ†å­æ•°æ®...\")\n",
        "\n",
        "# 1. åˆ†ç¦»é«˜ç”œå’Œä½ç”œæ•°æ®\n",
        "# å‡è®¾ df_processed å·²ç»å­˜åœ¨\n",
        "df_high = df_processed[df_processed['logSw'] > 3]\n",
        "df_low = df_processed[df_processed['logSw'] <= 3]\n",
        "\n",
        "# 2. ç¡®å®šæ¯ç±»é‡‡æ ·æ•°é‡ (å–ä¸¤è€…æœ€å°å€¼çš„ 50ï¼Œé˜²æ­¢å›¾å¤ªå¤§å¡é¡¿)\n",
        "n_samples = min(len(df_high), len(df_low), 50)\n",
        "print(f\"æ¯ç±»é‡‡æ ·æ•°é‡: {n_samples} (æ€»è®¡ {n_samples*2})\")\n",
        "\n",
        "# 3. å¹³è¡¡é‡‡æ ·\n",
        "subset_high = df_high.sample(n=n_samples, random_state=42)\n",
        "subset_low = df_low.sample(n=n_samples, random_state=42)\n",
        "\n",
        "# 4. åˆå¹¶å¹¶æ‰“ä¹±\n",
        "subset = pd.concat([subset_high, subset_low]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# å‡†å¤‡åˆ†å­æŒ‡çº¹\n",
        "mols = [Chem.MolFromSmiles(s) for s in subset['Smiles']]\n",
        "fps = [AllChem.GetMorganFingerprintAsBitVect(x, 2, nBits=1024) for x in mols]\n",
        "\n",
        "# é¢„å…ˆè®¡ç®—é¢œè‰²èŒƒå›´\n",
        "min_sw = subset['logSw'].min()\n",
        "max_sw = subset['logSw'].max()\n",
        "\n",
        "# ==========================================\n",
        "# 3. æ„å»º PyVis ç½‘ç»œ\n",
        "# ==========================================\n",
        "print(f\">>> [2/3] æ­£åœ¨æ„å»ºäº¤äº’å¼ç½‘ç»œ (é˜ˆå€¼ Tanimoto > 0.5)...\")\n",
        "\n",
        "# å…³é”®è®¾ç½®ï¼šcdn_resources='in_line' ç¡®ä¿æ‰€æœ‰è„šæœ¬å†…åµŒï¼Œä¸éœ€è¦è”ç½‘åŠ è½½ CDN\n",
        "net = Network(height=\"750px\", width=\"100%\", notebook=True, cdn_resources='in_line', bgcolor=\"#ffffff\", font_color=\"black\")\n",
        "\n",
        "n = len(subset)\n",
        "threshold = 0.5\n",
        "\n",
        "# --- æ·»åŠ èŠ‚ç‚¹ ---\n",
        "for i in range(n):\n",
        "    mol = mols[i]\n",
        "    val = subset.loc[i, 'logSw']\n",
        "    smiles = subset.loc[i, 'Smiles']\n",
        "\n",
        "    img_html = mol_to_base64_html(mol)\n",
        "\n",
        "    # æ„é€  Tooltip (HTMLæ ¼å¼)\n",
        "    # åŒ…å« ID, ç”œåº¦, SMILES å’Œ åˆ†å­ç»“æ„å›¾\n",
        "    title_html = (\n",
        "        f\"<b>ID:</b> {i}<br>\"\n",
        "        f\"<b>Sweetness:</b> {val:.3f}<br>\"\n",
        "        f\"<b>SMILES:</b> {smiles[:15]}...<br>\"\n",
        "        f\"{img_html}\"\n",
        "    )\n",
        "\n",
        "    node_color = get_color_hex(val, min_sw, max_sw)\n",
        "\n",
        "    # æ·»åŠ èŠ‚ç‚¹\n",
        "    net.add_node(i, label=str(i), title=title_html, color=node_color, size=20, borderWidth=1)\n",
        "\n",
        "# --- æ·»åŠ è¾¹ ---\n",
        "for i in range(n):\n",
        "    for j in range(i + 1, n):\n",
        "        sim = DataStructs.TanimotoSimilarity(fps[i], fps[j])\n",
        "        if sim > threshold:\n",
        "            # è¾¹è¶Šç²—ä»£è¡¨è¶Šç›¸ä¼¼\n",
        "            width = (sim - threshold) * 5\n",
        "            net.add_edge(i, j, value=sim, title=f\"Similarity: {sim:.2f}\", color='#cccccc', width=width)\n",
        "\n",
        "# ==========================================\n",
        "# 4. åœ¨ Colab ä¸­ç›´æ¥æ¸²æŸ“ (ä¸ä¸‹è½½)\n",
        "# ==========================================\n",
        "print(\">>> [3/3] æ­£åœ¨æ¸²æŸ“å¯è§†åŒ–...\")\n",
        "\n",
        "# æ·»åŠ ç‰©ç†æ§åˆ¶é¢æ¿\n",
        "net.show_buttons(filter_=['physics'])\n",
        "\n",
        "# ä¿å­˜ä¸º HTML æ–‡ä»¶\n",
        "html_file_name = \"balanced_sweetness_network.html\"\n",
        "net.save_graph(html_file_name)\n",
        "\n",
        "# æ ¸å¿ƒé­”æ³•ï¼šè¯»å– HTML å†…å®¹å¹¶ç›´æ¥æ˜¾ç¤ºåœ¨ Output åŒºåŸŸ\n",
        "print(\"âœ… äº¤äº’å¼å›¾è¡¨å·²ç”Ÿæˆï¼Œè¯·ç›´æ¥åœ¨ä¸‹æ–¹æŸ¥çœ‹ï¼š\")\n",
        "display(HTML(filename=html_file_name))"
      ],
      "metadata": {
        "id": "HzWx36LOMYA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfiZB5IpRwZ9"
      },
      "source": [
        "### T-SNEé™ç»´å¯è§†åŒ–ä¸€ä¸‹é«˜ç”œ/ä½ç”œåˆ†å­çš„åˆ†å­æè¿°ç¬¦å’Œåˆ†å­æŒ‡çº¹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hLJ6pLLRvXl"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ==========================================\n",
        "# 5. å¯è§†åŒ– Cï¼št-SNE é™ç»´å¯è§†åŒ–\n",
        "# ==========================================\n",
        "\n",
        "print(\"æ­£åœ¨è®¡ç®— t-SNEï¼Œè¯·ç¨å€™...\")\n",
        "\n",
        "# --- 5.1 åŸºäºåˆ†å­æè¿°ç¬¦ (Descriptors) çš„ t-SNE ---\n",
        "\n",
        "# æå–æè¿°ç¬¦æ•°æ®å¹¶æ ‡å‡†åŒ–\n",
        "X_desc = df_processed[descriptor_cols].values\n",
        "scaler = StandardScaler()\n",
        "X_desc_scaled = scaler.fit_transform(X_desc)\n",
        "\n",
        "# è®¡ç®— t-SNE\n",
        "tsne_desc = TSNE(n_components=2, random_state=42, perplexity=30, init='pca', learning_rate='auto')\n",
        "X_embedded_desc = tsne_desc.fit_transform(X_desc_scaled)\n",
        "\n",
        "# å°†ç»“æœå­˜å…¥ DataFrame\n",
        "df_processed['tsne_desc_x'] = X_embedded_desc[:, 0]\n",
        "df_processed['tsne_desc_y'] = X_embedded_desc[:, 1]\n",
        "\n",
        "\n",
        "# --- 5.2 åŸºäºåˆ†å­æŒ‡çº¹ (Fingerprints) çš„ t-SNE ---\n",
        "\n",
        "# æå–æŒ‡çº¹æ•°æ® (å°† Series ä¸­çš„ array å †å æˆçŸ©é˜µ)\n",
        "X_fp = np.stack(df_processed['Fingerprint'].values)\n",
        "\n",
        "# è®¡ç®— t-SNE\n",
        "tsne_fp = TSNE(n_components=2, random_state=42, perplexity=30, init='pca', learning_rate='auto')\n",
        "X_embedded_fp = tsne_fp.fit_transform(X_fp)\n",
        "\n",
        "df_processed['tsne_fp_x'] = X_embedded_fp[:, 0]\n",
        "df_processed['tsne_fp_y'] = X_embedded_fp[:, 1]\n",
        "\n",
        "\n",
        "# --- 5.3 ç»˜åˆ¶ t-SNE ç»“æœ ---\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
        "\n",
        "# ç»˜å›¾å‡½æ•°å°è£…\n",
        "def plot_tsne(ax, x_col, y_col, title):\n",
        "    sns.scatterplot(\n",
        "        x=x_col, y=y_col,\n",
        "        hue='Sweetness_Class',\n",
        "        hue_order=class_order,\n",
        "        palette=custom_palette,\n",
        "        data=df_processed,\n",
        "        alpha=0.8,\n",
        "        s=60,\n",
        "        ax=ax\n",
        "    )\n",
        "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
        "    ax.legend(title='Sweetness Class', loc='upper right')\n",
        "    ax.set_xlabel('t-SNE Dim 1')\n",
        "    ax.set_ylabel('t-SNE Dim 2')\n",
        "\n",
        "# ç”»å›¾\n",
        "plot_tsne(axes[0], 'tsne_desc_x', 'tsne_desc_y', 't-SNE: Molecular Descriptors')\n",
        "plot_tsne(axes[1], 'tsne_fp_x', 'tsne_fp_y', 't-SNE: Morgan Fingerprints (ECFP4)')\n",
        "\n",
        "plt.suptitle('Manifold Learning Visualization (t-SNE)', fontsize=16, y=0.95)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# ==========================================\n",
        "# 5. å¯è§†åŒ– Cï¼š3D t-SNE é™ç»´å¯è§†åŒ– (äº¤äº’å¼)\n",
        "# ==========================================\n",
        "\n",
        "print(\"æ­£åœ¨è®¡ç®— 3D t-SNEï¼Œè®¡ç®—é‡ç¨å¤§ï¼Œè¯·ç¨å€™...\")\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 1. æ•°æ®å‡†å¤‡ä¸è®¡ç®— (n_components=3)\n",
        "# -------------------------------------------------------\n",
        "\n",
        "# --- A. åŸºäºåˆ†å­æè¿°ç¬¦ (Descriptors) ---\n",
        "# æå–å¹¶æ ‡å‡†åŒ–\n",
        "X_desc = df_processed[descriptor_cols].values\n",
        "scaler = StandardScaler()\n",
        "X_desc_scaled = scaler.fit_transform(X_desc)\n",
        "\n",
        "# è®¡ç®— 3D t-SNE\n",
        "tsne_desc = TSNE(n_components=3, random_state=42, perplexity=30, init='pca', learning_rate='auto')\n",
        "X_embedded_desc = tsne_desc.fit_transform(X_desc_scaled)\n",
        "\n",
        "# å­˜å…¥ DataFrame\n",
        "df_processed['tsne_desc_x'] = X_embedded_desc[:, 0]\n",
        "df_processed['tsne_desc_y'] = X_embedded_desc[:, 1]\n",
        "df_processed['tsne_desc_z'] = X_embedded_desc[:, 2] # æ–°å¢ Z è½´\n",
        "\n",
        "\n",
        "# --- B. åŸºäºåˆ†å­æŒ‡çº¹ (Fingerprints) ---\n",
        "# æå–æŒ‡çº¹çŸ©é˜µ\n",
        "X_fp = np.stack(df_processed['Fingerprint'].values)\n",
        "\n",
        "# è®¡ç®— 3D t-SNE\n",
        "tsne_fp = TSNE(n_components=3, random_state=42, perplexity=30, init='pca', learning_rate='auto')\n",
        "X_embedded_fp = tsne_fp.fit_transform(X_fp)\n",
        "\n",
        "# å­˜å…¥ DataFrame\n",
        "df_processed['tsne_fp_x'] = X_embedded_fp[:, 0]\n",
        "df_processed['tsne_fp_y'] = X_embedded_fp[:, 1]\n",
        "df_processed['tsne_fp_z'] = X_embedded_fp[:, 2] # æ–°å¢ Z è½´\n",
        "\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 2. å®šä¹‰ç»˜å›¾å‡½æ•° (ä½¿ç”¨ Plotly Express)\n",
        "# -------------------------------------------------------\n",
        "\n",
        "# å®šä¹‰é¢œè‰²æ˜ å°„ (Hexæ ¼å¼ï¼Œå¯¹åº”ä¹‹å‰çš„çº¢è“é…è‰²)\n",
        "color_map = {\n",
        "    'Low Sweetness (<=3)': '#4B74B2',  # è“è‰²\n",
        "    'High Sweetness (>3)': '#DB3124'   # çº¢è‰²\n",
        "}\n",
        "\n",
        "def plot_3d_tsne(x, y, z, title, filename_suffix):\n",
        "    \"\"\"\n",
        "    ç»˜åˆ¶å•ä¸ª 3D æ•£ç‚¹å›¾\n",
        "    \"\"\"\n",
        "    fig = px.scatter_3d(\n",
        "        df_processed,\n",
        "        x=x, y=y, z=z,\n",
        "        color='Sweetness_Class',\n",
        "        color_discrete_map=color_map,\n",
        "\n",
        "        # æ‚¬åœæ˜¾ç¤ºçš„ä¿¡æ¯ (éå¸¸æœ‰ç”¨ï¼)\n",
        "        hover_data={\n",
        "            'Smiles': True,\n",
        "            'logSw': True,\n",
        "            x: False, y: False, z: False # éšè—åæ ‡å€¼ï¼Œåªçœ‹åˆ†å­ä¿¡æ¯\n",
        "        },\n",
        "        title=title,\n",
        "        opacity=0.7,\n",
        "        size_max=8\n",
        "    )\n",
        "\n",
        "    # ä¼˜åŒ–ç‚¹çš„å¤§å°å’Œæ ‡è®°\n",
        "    fig.update_traces(marker=dict(size=4, line=dict(width=0)))\n",
        "\n",
        "    # è®¾ç½®å¸ƒå±€\n",
        "    fig.update_layout(\n",
        "        margin=dict(l=0, r=0, b=0, t=40),\n",
        "        scene=dict(\n",
        "            xaxis_title='t-SNE Dim 1',\n",
        "            yaxis_title='t-SNE Dim 2',\n",
        "            zaxis_title='t-SNE Dim 3'\n",
        "        ),\n",
        "        legend_title_text='Sweetness Class'\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 3. ç»˜åˆ¶å¹¶å±•ç¤ºå›¾è¡¨\n",
        "# -------------------------------------------------------\n",
        "\n",
        "print(\"\\n>>> äº¤äº’å¼ 3D å›¾è¡¨ 1: åŸºäºåˆ†å­æè¿°ç¬¦\")\n",
        "plot_3d_tsne('tsne_desc_x', 'tsne_desc_y', 'tsne_desc_z',\n",
        "             '3D t-SNE: Molecular Descriptors', 'desc')\n",
        "\n",
        "print(\"\\n>>> äº¤äº’å¼ 3D å›¾è¡¨ 2: åŸºäºåˆ†å­æŒ‡çº¹\")\n",
        "plot_3d_tsne('tsne_fp_x', 'tsne_fp_y', 'tsne_fp_z',\n",
        "             '3D t-SNE: Morgan Fingerprints', 'fp')"
      ],
      "metadata": {
        "id": "m9a9XgckJdCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### è®­ç»ƒä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹åˆ†å­ç”œåº¦"
      ],
      "metadata": {
        "id": "wZ-3BB6-Atb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ==========================================\n",
        "# 0. æ•°æ®å‡†å¤‡\n",
        "# ==========================================\n",
        "SEED = 42\n",
        "\n",
        "# Aç»„ç‰¹å¾ï¼šåˆ†å­æè¿°ç¬¦ (æ ‡å‡†åŒ–)\n",
        "descriptor_cols = ['MolWt', 'LogP', 'NumHDonors', 'NumHAcceptors', 'TPSA', 'RotatableBonds']\n",
        "X_desc = df_processed[descriptor_cols].values\n",
        "scaler = StandardScaler()\n",
        "X_desc_scaled = scaler.fit_transform(X_desc)\n",
        "\n",
        "# Bç»„ç‰¹å¾ï¼šMorganæŒ‡çº¹\n",
        "X_fp = np.stack(df_processed['Fingerprint'].values).astype(float)\n",
        "\n",
        "# ç›®æ ‡å€¼\n",
        "y = df_processed['logSw'].values\n",
        "\n",
        "# åŒæ—¶åˆ‡åˆ†ä¸¤ç»„ç‰¹å¾ï¼Œç¡®ä¿ y_test ä¸€è‡´ï¼Œæ–¹ä¾¿å…¬å¹³å¯¹æ¯”\n",
        "X_desc_train, X_desc_test, X_fp_train, X_fp_test, y_train, y_test = train_test_split(\n",
        "    X_desc_scaled, X_fp, y, test_size=0.2, random_state=SEED\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 1. å®šä¹‰8ä¸ªæ¨¡å‹ (4ç§ç®—æ³• x 2ç§ç‰¹å¾)\n",
        "# ==========================================\n",
        "# ä¸ºäº†æ–¹ä¾¿ï¼Œæˆ‘ä»¬å°†è®­ç»ƒé›†å’Œæµ‹è¯•é›†å°è£…åœ¨å…ƒç»„ä¸­\n",
        "# æ ¼å¼: \"æ¨¡å‹å\": (æ¨¡å‹å¯¹è±¡, è®­ç»ƒæ•°æ®, æµ‹è¯•æ•°æ®)\n",
        "\n",
        "models = {\n",
        "    # --- 1. çº¿æ€§æ¨¡å‹ ---\n",
        "    \"Linear Reg (Descriptors)\": (\n",
        "        LinearRegression(),\n",
        "        X_desc_train, X_desc_test\n",
        "    ),\n",
        "    \"Linear Ridge (Fingerprints)\": (\n",
        "        Ridge(alpha=1.0), # æŒ‡çº¹ç»´åº¦é«˜ï¼Œä½¿ç”¨Ridgeé˜²æ­¢è¿‡æ‹Ÿåˆ\n",
        "        X_fp_train, X_fp_test\n",
        "    ),\n",
        "\n",
        "    # --- 2. éšæœºæ£®æ— (é›†æˆå­¦ä¹ -Bagging) ---\n",
        "    \"Random Forest (Descriptors)\": (\n",
        "        RandomForestRegressor(n_estimators=100, random_state=SEED, n_jobs=-1),\n",
        "        X_desc_train, X_desc_test\n",
        "    ),\n",
        "    \"Random Forest (Fingerprints)\": (\n",
        "        RandomForestRegressor(n_estimators=100, random_state=SEED, n_jobs=-1),\n",
        "        X_fp_train, X_fp_test\n",
        "    ),\n",
        "\n",
        "    # --- 3. SVM (æ”¯æŒå‘é‡æœº) ---\n",
        "    \"SVR (Descriptors)\": (\n",
        "        SVR(kernel='rbf', C=1.0, epsilon=0.1), # RBFæ ¸å¤„ç†éçº¿æ€§\n",
        "        X_desc_train, X_desc_test\n",
        "    ),\n",
        "    \"SVR (Fingerprints)\": (\n",
        "        SVR(kernel='rbf', C=1.0, epsilon=0.1),\n",
        "        X_fp_train, X_fp_test\n",
        "    ),\n",
        "\n",
        "    # --- 4. XGBoost (é›†æˆå­¦ä¹ -Boosting) ---\n",
        "    \"XGBoost (Descriptors)\": (\n",
        "        XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=SEED, n_jobs=-1),\n",
        "        X_desc_train, X_desc_test\n",
        "    ),\n",
        "    \"XGBoost (Fingerprints)\": (\n",
        "        XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=SEED, n_jobs=-1),\n",
        "        X_fp_train, X_fp_test\n",
        "    )\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# 2. è®­ç»ƒä¸è¯„ä¼°\n",
        "# ==========================================\n",
        "results = []\n",
        "predictions = {}\n",
        "\n",
        "print(f\"{'Model Name':<30} | {'RMSE':<10} | {'R2 Score':<10}\")\n",
        "print(\"-\" * 55)\n",
        "\n",
        "for name, (model, X_tr, X_te) in models.items():\n",
        "    # è®­ç»ƒ\n",
        "    model.fit(X_tr, y_train)\n",
        "    # é¢„æµ‹\n",
        "    y_pred = model.predict(X_te)\n",
        "    predictions[name] = y_pred\n",
        "\n",
        "    # è¯„ä¼°\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    results.append({\"Model\": name, \"RMSE\": rmse, \"R2\": r2})\n",
        "    print(f\"{name:<30} | {rmse:<10.4f} | {r2:<10.4f}\")\n",
        "\n",
        "print(\"-\" * 55)\n",
        "\n",
        "# ==========================================\n",
        "# 3. å¯è§†åŒ–å¯¹æ¯” (2è¡Œ4åˆ—)\n",
        "# ==========================================\n",
        "# è®¾ç½®å¸ƒå±€ï¼šç¬¬ä¸€è¡Œæ˜¯åŸºäºæè¿°ç¬¦çš„æ¨¡å‹ï¼Œç¬¬äºŒè¡Œæ˜¯åŸºäºæŒ‡çº¹çš„æ¨¡å‹\n",
        "fig, axes = plt.subplots(2, 4, figsize=(24, 10), dpi=600)\n",
        "# æ‰å¹³åŒ–è½´æ•°ç»„æ–¹ä¾¿éå†ï¼Œä½†æˆ‘ä»¬éœ€è¦æŒ‰ç‰¹å®šé¡ºåºå¡«å…¥\n",
        "# æˆ‘ä»¬æ‰‹åŠ¨æŒ‡å®šé¡ºåºä»¥ä¿æŒå¯¹é½ï¼š\n",
        "# åˆ—é¡ºåº: Linear, RF, SVR, XGB\n",
        "\n",
        "# å®šä¹‰ç»˜å›¾é¡ºåºå¯¹åº”çš„é”®å\n",
        "plot_order = [\n",
        "    [\"Linear Reg (Descriptors)\", \"Random Forest (Descriptors)\", \"SVR (Descriptors)\", \"XGBoost (Descriptors)\"],\n",
        "    [\"Linear Ridge (Fingerprints)\", \"Random Forest (Fingerprints)\", \"SVR (Fingerprints)\", \"XGBoost (Fingerprints)\"]\n",
        "]\n",
        "\n",
        "color_scatter = (75/255, 116/255, 178/255)\n",
        "color_line = (219/255, 49/255, 36/255)\n",
        "\n",
        "for row in range(2):\n",
        "    for col in range(4):\n",
        "        ax = axes[row, col]\n",
        "        model_name = plot_order[row][col]\n",
        "        y_pred = predictions[model_name]\n",
        "\n",
        "        # è·å–è¯¥æ¨¡å‹çš„åˆ†æ•°\n",
        "        res = next(item for item in results if item[\"Model\"] == model_name)\n",
        "\n",
        "        # æ•£ç‚¹å›¾\n",
        "        ax.scatter(y_test, y_pred, alpha=0.8, color=color_scatter, s=30)\n",
        "\n",
        "        # å®Œç¾é¢„æµ‹çº¿\n",
        "        min_val = min(y_test.min(), y_pred.min())\n",
        "        max_val = max(y_test.max(), y_pred.max())\n",
        "        ax.plot([min_val, max_val], [min_val, max_val], '--', color=color_line, lw=2)\n",
        "\n",
        "        # æ ‡æ³¨\n",
        "        ax.text(0.05, 0.95, f'$R^2 = {res[\"R2\"]:.3f}$\\n$RMSE = {res[\"RMSE\"]:.3f}$',\n",
        "                 transform=ax.transAxes, verticalalignment='top',\n",
        "                 bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
        "\n",
        "        ax.set_title(model_name, fontsize=11, fontweight='bold')\n",
        "        ax.set_xlabel('True')\n",
        "        ax.set_ylabel('Pred')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle(\"Benchmark: Descriptors (Row 1) vs Fingerprints (Row 2)\", fontsize=16, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ==========================================\n",
        "# 4. è‡ªåŠ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š\n",
        "# ==========================================\n",
        "# æ‰¾å‡ºR2æœ€é«˜çš„æ¨¡å‹\n",
        "best_model = max(results, key=lambda x: x['R2'])\n",
        "\n",
        "print(\"\\n\" + \"=\"*20 + \" æ·±åº¦åˆ†æ \" + \"=\"*20)\n",
        "print(f\"ğŸ† æœ€ä½³ä¼ ç»Ÿæ¨¡å‹: {best_model['Model']} (R2={best_model['R2']:.4f})\")\n",
        "print(\"\\nğŸ” æ ¸å¿ƒè§‚å¯Ÿç‚¹ï¼š\")\n",
        "print(\"1. ç‰¹å¾å¯¹æ¯”ï¼šé€šå¸¸æƒ…å†µä¸‹ï¼ŒåŸºäºæŒ‡çº¹(Fingerprints)çš„æ¨¡å‹ä¸Šé™æ›´é«˜ï¼Œå› ä¸ºåŒ…å«äº†æ›´å¤šç»“æ„ä¿¡æ¯ï¼›\")\n",
        "print(\"   ä½†æè¿°ç¬¦(Descriptors)åœ¨ç®€å•æ¨¡å‹ä¸Šå¯èƒ½æ›´ç¨³å®šï¼Œä¸”è®¡ç®—æå¿«ã€‚\")\n",
        "print(\"2. çº¿æ€§ vs éçº¿æ€§ï¼šè§‚å¯Ÿ Linear Reg æ˜¯å¦æ˜¾è‘—å¼±äº RF/XGB/SVRï¼Ÿ\")\n",
        "print(\"   å¦‚æœæ˜¯ï¼Œè¯´æ˜åˆ†å­ç”œåº¦å…·æœ‰å¼ºçƒˆçš„éçº¿æ€§ç‰¹å¾ï¼ˆæ„æ•ˆå…³ç³»å¤æ‚ï¼‰ã€‚\")\n",
        "print(\"3. XGBoost vs RFï¼šè¿™ä¸¤ä¸ªéƒ½æ˜¯é›†æˆå­¦ä¹ å¼ºè€…ï¼ŒXGBoosté€šå¸¸ç¨èƒœä¸€ç­¹ï¼Œä½†ä¹Ÿæ›´éš¾è°ƒå‚ã€‚\")\n",
        "print(\"4. GNNçš„æŒ‘æˆ˜ï¼šGNN éœ€è¦å‡»è´¥è¿™é‡Œè¡¨ç°æœ€å¥½çš„æ¨¡å‹ï¼ˆä¾‹å¦‚ XGBoost+Fingerprintsï¼‰æ‰èƒ½è¯æ˜å…¶ç«¯åˆ°ç«¯å­¦ä¹ çš„ä»·å€¼ã€‚\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "id": "ULPTt9QQAvjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### è®­ç»ƒä¸€ä¸ªMLPæ¨¡å‹é¢„æµ‹åˆ†å­ç”œåº¦"
      ],
      "metadata": {
        "id": "hyCp8UqaQam3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Z9DXQ57Uk2r"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ==========================================\n",
        "# 0. é…ç½®ä¸è®¾å¤‡é€‰æ‹©\n",
        "# ==========================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# è®¾ç½®ç»˜å›¾å‚æ•°\n",
        "plt.rcParams['figure.dpi'] = 300\n",
        "plt.rcParams['savefig.dpi'] = 300\n",
        "color_blue = (75 / 255, 116 / 255, 178 / 255)\n",
        "color_red = (219 / 255, 49 / 255, 36 / 255)\n",
        "\n",
        "# ==========================================\n",
        "# 1. æ•°æ®å‡†å¤‡\n",
        "# ==========================================\n",
        "# (å‡è®¾ df_processed, descriptor_cols å·²ç»åœ¨ç¯å¢ƒä¸­å®šä¹‰)\n",
        "\n",
        "# --- A. å‡†å¤‡ç‰¹å¾ ---\n",
        "# 1. æè¿°ç¬¦\n",
        "X_desc_raw = df_processed[descriptor_cols].values\n",
        "scaler_desc = StandardScaler()\n",
        "X_desc_scaled = scaler_desc.fit_transform(X_desc_raw)\n",
        "\n",
        "# 2. æŒ‡çº¹\n",
        "X_fp_raw = np.stack(df_processed['Fingerprint'].values)\n",
        "X_fp_float = X_fp_raw.astype(float)\n",
        "\n",
        "# --- B. ç›®æ ‡å˜é‡ ---\n",
        "y_val = df_processed['logSw'].values.reshape(-1, 1)\n",
        "\n",
        "# --- C. æ•°æ®åŠ è½½å™¨ ---\n",
        "def create_dataloaders(X, y, batch_size=32):\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    X_val, X_test, y_val_set, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "    tensor_X_train = torch.FloatTensor(X_train).to(device)\n",
        "    tensor_y_train = torch.FloatTensor(y_train).to(device)\n",
        "    tensor_X_val = torch.FloatTensor(X_val).to(device)\n",
        "    tensor_y_val = torch.FloatTensor(y_val_set).to(device)\n",
        "    tensor_X_test = torch.FloatTensor(X_test).to(device)\n",
        "    tensor_y_test = torch.FloatTensor(y_test).to(device)\n",
        "\n",
        "    train_loader = DataLoader(TensorDataset(tensor_X_train, tensor_y_train), batch_size=batch_size, shuffle=True)\n",
        "    return train_loader, tensor_X_val, tensor_y_val, tensor_X_test, tensor_y_test\n",
        "\n",
        "print(\"å‡†å¤‡æ•°æ®...\")\n",
        "data_desc = create_dataloaders(X_desc_scaled, y_val)\n",
        "data_fp = create_dataloaders(X_fp_float, y_val)\n",
        "\n",
        "# ==========================================\n",
        "# 2. å®šä¹‰æ›´æ·±çš„ MLP æ¨¡å‹ (æ˜¾å¼å®šä¹‰å±‚ç»“æ„)\n",
        "# ==========================================\n",
        "\n",
        "class SweetNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128):\n",
        "        super(SweetNet, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            # --- ç¬¬1å±‚éšè—å±‚ (Input -> Hidden) ---\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            # --- ç¬¬2å±‚éšè—å±‚ (Hidden -> Hidden/2) ---\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            # --- ç¬¬3å±‚éšè—å±‚ (Hidden/2 -> Hidden/4) ---\n",
        "            # è¿™æ˜¯æ–°å¢çš„ä¸€å±‚ï¼Œè®©ç½‘ç»œå˜æ·±\n",
        "            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            # --- è¾“å‡ºå±‚ (Hidden/4 -> Output) ---\n",
        "            nn.Linear(hidden_dim // 4, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# ==========================================\n",
        "# 3. è®­ç»ƒå‡½æ•°\n",
        "# ==========================================\n",
        "def train_model(model, data_pack, epochs=100, lr=0.001, name=\"Model\"):\n",
        "    train_loader, X_val, y_val, X_test, y_test = data_pack\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    model.train()\n",
        "    print(f\"å¼€å§‹è®­ç»ƒ {name} ...\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        batch_losses = []\n",
        "        for inputs, targets in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            batch_losses.append(loss.item())\n",
        "\n",
        "        avg_train_loss = np.mean(batch_losses)\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_outputs = model(X_val)\n",
        "            val_loss = criterion(val_outputs, y_val).item()\n",
        "            val_losses.append(val_loss)\n",
        "        model.train()\n",
        "\n",
        "        if (epoch+1) % 1 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_preds = model(X_test).cpu().numpy()\n",
        "        y_test_np = y_test.cpu().numpy()\n",
        "\n",
        "    metrics = {\n",
        "        'rmse': np.sqrt(mean_squared_error(y_test_np, test_preds)),\n",
        "        'r2': r2_score(y_test_np, test_preds)\n",
        "    }\n",
        "    return train_losses, val_losses, y_test_np, test_preds, metrics\n",
        "\n",
        "# ==========================================\n",
        "# 4. æ‰§è¡Œè®­ç»ƒ\n",
        "# ==========================================\n",
        "\n",
        "# --- æ¨¡å‹ A: æè¿°ç¬¦æ¨¡å‹ (è¾“å…¥ç»´åº¦è¾ƒå°ï¼Œéšè—å±‚ç»™å¤§ä¸€ç‚¹) ---\n",
        "model_desc = SweetNet(input_dim=6, hidden_dim=128).to(device)\n",
        "print(f\"\\næ¨¡å‹ç»“æ„ (Descriptors):\\n{model_desc}\")\n",
        "hist_desc = train_model(model_desc, data_desc, epochs=150, lr=0.005, name=\"Descriptors MLP\")\n",
        "\n",
        "# --- æ¨¡å‹ B: æŒ‡çº¹æ¨¡å‹ (è¾“å…¥ç»´åº¦å¤§ï¼Œéšè—å±‚ç»™æ›´å¤§) ---\n",
        "model_fp = SweetNet(input_dim=2048, hidden_dim=512).to(device)\n",
        "print(f\"\\næ¨¡å‹ç»“æ„ (Fingerprints):\\n{model_fp}\")\n",
        "hist_fp = train_model(model_fp, data_fp, epochs=150, lr=0.001, name=\"Fingerprints MLP\")\n",
        "\n",
        "# ==========================================\n",
        "# 5. å¯è§†åŒ–ç»“æœ\n",
        "# ==========================================\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "\n",
        "def plot_results(ax_loss, ax_pred, hist, title_prefix):\n",
        "    # Loss\n",
        "    ax_loss.plot(hist[0], label='Train', color=color_blue)\n",
        "    ax_loss.plot(hist[1], label='Val', color=color_red, linestyle='--')\n",
        "    ax_loss.set_title(f'{title_prefix} Loss')\n",
        "    ax_loss.legend()\n",
        "    ax_loss.grid(True, alpha=0.3)\n",
        "\n",
        "    # Pred\n",
        "    y_true, y_pred, metrics = hist[2], hist[3], hist[4]\n",
        "    ax_pred.scatter(y_true, y_pred, alpha=0.8, color=color_blue, s=30)\n",
        "    min_v, max_v = min(y_true.min(), y_pred.min()), max(y_true.max(), y_pred.max())\n",
        "    ax_pred.plot([min_v, max_v], [min_v, max_v], '--', color=color_red, lw=2)\n",
        "    ax_pred.text(0.05, 0.95, f'R2={metrics[\"r2\"]:.3f}\\nRMSE={metrics[\"rmse\"]:.3f}',\n",
        "                 transform=ax_pred.transAxes, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "    ax_pred.set_title(f'{title_prefix} Pred')\n",
        "    ax_pred.grid(True, alpha=0.3)\n",
        "\n",
        "plot_results(axes[0,0], axes[0,1], hist_desc, \"Descriptors\")\n",
        "plot_results(axes[1,0], axes[1,1], hist_fp, \"Fingerprints\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl4HY4dFPxwV"
      },
      "source": [
        "# **å°åˆ†å­ä»»åŠ¡â€”â€”åŸºäºGNNçš„åŒ–åˆç‰©ç”œåº¦é¢„æµ‹-å›¾çº§åˆ«ä»»åŠ¡**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNmrivCSRars"
      },
      "source": [
        "## **1-åˆ¶ä½œGraphæ•°æ®é›†**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_z2apL5gfmP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from torch_geometric.data import Data\n",
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from scipy.sparse import coo_matrix\n",
        "import numpy as np\n",
        "\n",
        "# è¾…åŠ©å‡½æ•°\n",
        "def one_hot_encoding(value, choices):\n",
        "    encoding = [0] * (len(choices) + 1)\n",
        "    index = choices.index(value) if value in choices else -1\n",
        "    encoding[index] = 1\n",
        "    return encoding\n",
        "\n",
        "# ç‰¹å¾æå–å™¨ç±»ï¼ˆä¿®å¤äº†è¾¹ç‰¹å¾é”™ä½é—®é¢˜ï¼‰\n",
        "class MoleculeFeaturizer(object):\n",
        "    def __init__(self, bond_features=True):\n",
        "        self.bond_features = bond_features\n",
        "\n",
        "    def _atom_featurizer(self, atom):\n",
        "        atomic_numer = [1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 28, 29,\n",
        "                        30, 31, 32, 33, 34, 35, 36, 37, 38, 46, 47, 48, 49, 50, 51, 52, 53]\n",
        "        atom_type_value = atom.GetAtomicNum()\n",
        "        atom_type_features = one_hot_encoding(atom_type_value, atomic_numer)\n",
        "\n",
        "        degree_choices = list(range(5))\n",
        "        degree = atom.GetTotalDegree()\n",
        "        degree_features = one_hot_encoding(degree, degree_choices)\n",
        "\n",
        "        hybridization_choices = list(range(len(Chem.HybridizationType.names) - 1))\n",
        "        hybridization = int(atom.GetHybridization())\n",
        "        hybrid_features = one_hot_encoding(hybridization, hybridization_choices)\n",
        "\n",
        "        chiral_tag_choices = list(range(len(Chem.ChiralType.names) - 1))\n",
        "        chiral_tag = atom.GetChiralTag()\n",
        "        chiral_tag_features = one_hot_encoding(chiral_tag, chiral_tag_choices)\n",
        "\n",
        "        num_Hs_choices = list(range(5))\n",
        "        num_Hs = atom.GetTotalNumHs()\n",
        "        num_Hs_features = one_hot_encoding(num_Hs, num_Hs_choices)\n",
        "\n",
        "        aromatic_features = [1 if atom.GetIsAromatic() else 0]\n",
        "\n",
        "        return atom_type_features + degree_features + hybrid_features + chiral_tag_features + num_Hs_features + aromatic_features\n",
        "\n",
        "    def _bond_featurizer(self, bond):\n",
        "        bond_type = bond.GetBondType()\n",
        "        bond_type_one_hot_encoding = [\n",
        "            int(bond_type == Chem.rdchem.BondType.SINGLE),\n",
        "            int(bond_type == Chem.rdchem.BondType.DOUBLE),\n",
        "            int(bond_type == Chem.rdchem.BondType.TRIPLE),\n",
        "            int(bond_type == Chem.rdchem.BondType.AROMATIC)\n",
        "        ]\n",
        "        addition_bond_features = [\n",
        "            int(bond.GetIsConjugated()),\n",
        "            int(bond.IsInRing())\n",
        "        ]\n",
        "        return bond_type_one_hot_encoding + addition_bond_features\n",
        "\n",
        "    def __call__(self, mol):\n",
        "        self.feature_dict = {}\n",
        "\n",
        "        # åŸå­ç‰¹å¾\n",
        "        atom_features = [self._atom_featurizer(atom) for atom in mol.GetAtoms()]\n",
        "        self.feature_dict['x'] = atom_features\n",
        "\n",
        "        # è¾¹ç´¢å¼•\n",
        "        adj = Chem.GetAdjacencyMatrix(mol)\n",
        "        coo_adj = coo_matrix(adj)\n",
        "        edge_index = torch.tensor([coo_adj.row, coo_adj.col], dtype=torch.long)\n",
        "        self.feature_dict['edge_index'] = edge_index\n",
        "\n",
        "        # è¾¹ç‰¹å¾ï¼ˆä¸ edge_index ä¿æŒé¡ºåºä¸€è‡´ï¼‰\n",
        "        bond_features = []\n",
        "        if self.bond_features and edge_index.size(1) > 0:\n",
        "            for i, j in zip(coo_adj.row, coo_adj.col):\n",
        "                bond = mol.GetBondBetweenAtoms(int(i), int(j))\n",
        "                if bond is not None:\n",
        "                    bond_features.append(self._bond_featurizer(bond))\n",
        "                else:\n",
        "                    bond_features.append([0] * 6)  # ç”¨é›¶å‘é‡å¡«è¡¥æ— æ•ˆè¾¹\n",
        "        else:\n",
        "            bond_features = []\n",
        "\n",
        "        self.feature_dict['edge_attr'] = bond_features\n",
        "\n",
        "        return self.feature_dict\n",
        "\n",
        "# æ•°æ®é›†ç±»\n",
        "class MolDataset:\n",
        "    def __init__(self, csv_path, save_path='./processed_dataset.pt'):\n",
        "        self.csv_path = csv_path\n",
        "        self.save_path = save_path\n",
        "        self.featurizer = MoleculeFeaturizer()\n",
        "        self.data_list = []\n",
        "\n",
        "\n",
        "        self._process_csv()\n",
        "\n",
        "    def _process_csv(self):\n",
        "        try:\n",
        "            df = pd.read_csv(self.csv_path)\n",
        "            print(f\"Successfully loaded CSV file from {self.csv_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading CSV file: {e}\")\n",
        "            return\n",
        "\n",
        "        if not all(col in df.columns for col in ['Smiles', 'logSw']):\n",
        "            print(\"CSV file must contain 'Smiles' and 'logSw' columns\")\n",
        "            return\n",
        "\n",
        "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing molecules\"):\n",
        "            smiles = row['Smiles']\n",
        "            label = row['logSw']\n",
        "\n",
        "            mol = Chem.MolFromSmiles(smiles)\n",
        "            if mol is None:\n",
        "                print(f\"Skipping invalid SMILES: {smiles}\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                features = self.featurizer(mol)\n",
        "\n",
        "                data = Data()\n",
        "                data.smiles = smiles\n",
        "                data.y = torch.tensor([label], dtype=torch.float32)\n",
        "                data.x = torch.tensor(features['x'], dtype=torch.float32)\n",
        "                data.edge_index = features['edge_index']\n",
        "\n",
        "                if len(features['edge_attr']) > 0:\n",
        "                    data.edge_attr = torch.tensor(features['edge_attr'], dtype=torch.float32)\n",
        "                else:\n",
        "                    data.edge_attr = torch.empty((0, 6), dtype=torch.float32)\n",
        "\n",
        "                self.data_list.append(data)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing molecule {smiles}: {e}\")\n",
        "                continue\n",
        "\n",
        "        if self.data_list:\n",
        "            torch.save(self.data_list, self.save_path)\n",
        "            print(f\"Processed dataset saved to {self.save_path}\")\n",
        "        else:\n",
        "            print(\"No valid molecules processed\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data_list[idx]\n",
        "\n",
        "# å¯åŠ¨æ•°æ®å¤„ç†æµç¨‹\n",
        "if __name__ == \"__main__\":\n",
        "    csv_path = '/content/SweetpredDB.csv'\n",
        "    dataset = MolDataset(csv_path)\n",
        "\n",
        "    if len(dataset) > 0:\n",
        "        print(f\"\\næ•°æ®é›†åŒ…å« {len(dataset)} ä¸ªæœ‰æ•ˆåˆ†å­\")\n",
        "        sample = dataset[0]\n",
        "        print(\"\\nç¬¬ä¸€ä¸ªåˆ†å­ä¿¡æ¯:\")\n",
        "        print(f\"SMILES: {sample.smiles}\")\n",
        "        print(f\"ç”œåº¦å€¼: {sample.y.item()}\")\n",
        "        print(f\"åŸå­ç‰¹å¾ç»´åº¦: {sample.x.shape}\")\n",
        "        print(f\"è¾¹ç´¢å¼•ç»´åº¦: {sample.edge_index.shape}\")\n",
        "        if hasattr(sample, 'edge_attr'):\n",
        "            print(f\"è¾¹ç‰¹å¾ç»´åº¦: {sample.edge_attr.shape}\")\n",
        "    else:\n",
        "        print(\"æ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥è¾“å…¥æ–‡ä»¶\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmVJc3v71i2l"
      },
      "source": [
        "### **åˆ†å­å›¾æ•°æ®é¢„å¤„ç†åŸç†è§£é‡Š**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoPrR0zk0-Xg"
      },
      "source": [
        "\n",
        "\n",
        "æœ¬é¡¹ç›®çš„æ ¸å¿ƒç›®æ ‡æ˜¯**å°†SMILESæ ¼å¼çš„åˆ†å­æ•°æ®è½¬åŒ–ä¸ºé€‚ç”¨äºå›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰æ¨¡å‹çš„æ•°æ®ç»“æ„**ï¼Œç”¨äºé¢„æµ‹åˆ†å­çš„ç”œåº¦ï¼ˆlogSwï¼‰ã€‚è¿™ä¸ªé¢„å¤„ç†æµç¨‹æ˜¯å›¾ç¥ç»ç½‘ç»œæ¨¡å‹çš„å…³é”®æ­¥éª¤ï¼Œå®ƒå°†åˆ†å­è¡¨ç¤ºä»å­—ç¬¦ä¸²ï¼ˆSMILESï¼‰è½¬æ¢ä¸ºå›¾ç»“æ„ï¼Œä»è€Œèƒ½å¤Ÿåˆ©ç”¨å›¾ç»“æ„çš„è¡¨è¾¾èƒ½åŠ›å’ŒGNNçš„å¼ºå¤§å­¦ä¹ èƒ½åŠ›å»ºæ¨¡åˆ†å­çš„ç»“æ„-æ€§è´¨å…³ç³»ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### ä¸€ã€ä¸ºä»€ä¹ˆç”¨å›¾ç»“æ„è¡¨ç¤ºåˆ†å­ï¼Ÿ\n",
        "\n",
        "åœ¨åŒ–å­¦ä¸­ï¼Œä¸€ä¸ªåˆ†å­å¯ä»¥è¢«çœ‹ä½œæ˜¯ä¸€ä¸ªæ— å‘å›¾ï¼Œå…¶ä¸­ï¼š\n",
        "- **åŸå­æ˜¯èŠ‚ç‚¹ï¼ˆnodesï¼‰**\n",
        "- **å…±ä»·é”®æ˜¯è¾¹ï¼ˆedgesï¼‰**\n",
        "\n",
        "è€Œ**å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰**æ­£æ˜¯ä¸“ä¸ºè¿™ç§éæ¬§å‡ é‡Œå¾—ç»“æ„ï¼ˆå¦‚å›¾ç»“æ„ï¼‰è®¾è®¡çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚é€šè¿‡åœ¨å›¾ä¸Šè¿›è¡Œæ¶ˆæ¯ä¼ é€’ï¼ˆMessage Passingï¼‰ï¼ŒGNNèƒ½æœ‰æ•ˆå­¦ä¹ æ¯ä¸ªèŠ‚ç‚¹ï¼ˆåŸå­ï¼‰åœ¨å…¶é‚»å±…ç¯å¢ƒä¸‹çš„è¡¨ç¤ºï¼Œå¹¶æœ€ç»ˆèšåˆä¸ºæ•´ä¸ªåˆ†å­çš„å…¨å±€è¡¨ç¤ºï¼Œç”¨äºé¢„æµ‹åˆ†å­çš„æ€§è´¨ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### äºŒã€SMILESåˆ°åˆ†å­å›¾çš„è½¬æ¢è¿‡ç¨‹\n",
        "\n",
        "é¡¹ç›®ä¸­ä½¿ç”¨äº†`RDKit`æ¥å°†SMILESå­—ç¬¦ä¸²è½¬æ¢ä¸ºåˆ†å­å›¾ã€‚RDKit æ˜¯åŒ–å­¦ä¿¡æ¯å­¦ä¸­å¸¸ç”¨çš„å·¥å…·åŒ…ï¼Œå®ƒå¯ä»¥ï¼š\n",
        "- å°†SMILESè§£æä¸ºåˆ†å­ç»“æ„\n",
        "- è·å–åŸå­çš„æ€§è´¨ï¼Œå¦‚åŸå­åºæ•°ã€æ‚åŒ–çŠ¶æ€ã€æ‰‹æ€§ç­‰\n",
        "- è·å–åŸå­ä¹‹é—´çš„é”®ç±»å‹ï¼Œå¦‚å•é”®ã€åŒé”®ã€èŠ³é¦™é”®ç­‰\n",
        "\n",
        "---\n",
        "\n",
        "#### ä¸‰ã€èŠ‚ç‚¹ï¼ˆåŸå­ï¼‰ç‰¹å¾è®¾è®¡\n",
        "\n",
        "èŠ‚ç‚¹ç‰¹å¾æ˜¯GNNçš„è¾“å…¥ä¹‹ä¸€ï¼Œç›´æ¥å†³å®šæ¨¡å‹èƒ½å¦å……åˆ†ç†è§£åŸå­åŒ–å­¦å±æ€§ã€‚æœ¬é¡¹ç›®ä¸­æ¯ä¸ªåŸå­çš„ç‰¹å¾æ˜¯**å¤šä¸ªç¦»æ•£å±æ€§çš„one-hotç¼–ç æ‹¼æ¥**ï¼ŒåŒ…æ‹¬ï¼š\n",
        "\n",
        "| ç‰¹å¾ | å«ä¹‰ | åŒ–å­¦æ„ä¹‰ |\n",
        "|------|------|----------|\n",
        "| åŸå­åºæ•° | å…ƒç´ ç§ç±»ï¼ˆå¦‚C, O, Nç­‰ï¼‰ | å†³å®šåŸå­çš„åŸºæœ¬å±æ€§ï¼Œå¦‚ç”µè´Ÿæ€§ã€æˆé”®èƒ½åŠ› |\n",
        "| åŸå­åº¦ï¼ˆdegreeï¼‰ | ä¸åŸå­ç›¸è¿çš„é”®æ•° | è¡¨å¾åŸå­çš„è¿æ¥æ€§ï¼Œå¦‚ç«¯åŸºã€ä¸­é—´åŸºå›¢ |\n",
        "| æ‚åŒ–è½¨é“ç±»å‹ | spã€sp2ã€sp3ç­‰ | åæ˜ ç”µå­æ’å¸ƒï¼Œå†³å®šåˆ†å­çš„ç«‹ä½“ç»“æ„ |\n",
        "| æ‰‹æ€§æ ‡è®° | S/Ræˆ–None | è¡¨ç¤ºæ‰‹æ€§ä¸­å¿ƒï¼Œå½±å“åˆ†å­çš„ç«‹ä½“å¼‚æ„æ€§ |\n",
        "| æ°¢åŸå­æ•° | ä¸åŸå­ç»‘å®šçš„æ°¢æ•° | å½±å“ææ€§ã€åˆ†å­å¤§å°ç­‰ |\n",
        "| èŠ³é¦™æ€§ | æ˜¯å¦ä¸ºèŠ³é¦™ç¯ç»“æ„çš„ä¸€éƒ¨åˆ† | èŠ³é¦™ç¯å…·æœ‰ç‰¹æ®Šç¨³å®šæ€§ï¼Œå½±å“åŒ–å­¦æ´»æ€§ |\n",
        "\n",
        "**è¿™äº›ç‰¹å¾æœ‰åŠ©äºç¥ç»ç½‘ç»œæ•æ‰åŸå­åœ¨åˆ†å­ä¸­æ‰€å¤„çš„åŒ–å­¦ç¯å¢ƒã€‚**\n",
        "\n",
        "---\n",
        "\n",
        "#### å››ã€è¾¹ï¼ˆé”®ï¼‰ç‰¹å¾è®¾è®¡\n",
        "\n",
        "å›¾ç»“æ„ä¸­çš„è¾¹è¡¨ç¤ºåŸå­ä¹‹é—´çš„å…±ä»·é”®ã€‚è¾¹ç‰¹å¾åŒæ ·é‡‡ç”¨one-hotå½¢å¼ï¼Œç¼–ç äº†ä»¥ä¸‹ä¿¡æ¯ï¼š\n",
        "\n",
        "| ç‰¹å¾ | å«ä¹‰ |\n",
        "|------|------|\n",
        "| é”®ç±»å‹ | å•é”®ã€åŒé”®ã€ä¸‰é”®ã€èŠ³é¦™é”® |\n",
        "| æ˜¯å¦å…±è½­ | ä¸Ï€ç”µå­ç¦»åŸŸæœ‰å…³ï¼Œå¦‚è‹¯ç¯ |\n",
        "| æ˜¯å¦åœ¨ç¯å†… | åˆ¤æ–­è¯¥é”®æ˜¯å¦æ„æˆç¯ç»“æ„ |\n",
        "\n",
        "è¿™äº›ç‰¹å¾æœ‰åŠ©äºæ¨¡å‹åˆ¤æ–­ç»“æ„ä¸­çš„**Ï€-å…±è½­ç³»ç»Ÿã€ç¯å¼ åŠ›**ç­‰å¯¹åˆ†å­æ€§è´¨çš„é‡è¦å½±å“ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### äº”ã€æ„é€  PyG æ‰€éœ€çš„å›¾æ•°æ®å¯¹è±¡\n",
        "\n",
        "æœ€ç»ˆï¼Œæ¯ä¸ªåˆ†å­è¢«è¡¨ç¤ºä¸º`torch_geometric.data.Data`å¯¹è±¡ï¼Œå…¶ä¸­åŒ…å«ï¼š\n",
        "- `x`: åŸå­ç‰¹å¾çŸ©é˜µï¼Œå½¢çŠ¶ä¸º`[åŸå­æ•°, ç‰¹å¾ç»´æ•°]`\n",
        "- `edge_index`: è¾¹çš„ç´¢å¼•ï¼Œå½¢çŠ¶ä¸º`[2, è¾¹æ•°]`ï¼Œç”¨ä¸¤ä¸ªæ•°ç»„åˆ†åˆ«è¡¨ç¤ºæ¯æ¡è¾¹çš„èµ·ç‚¹å’Œç»ˆç‚¹åŸå­\n",
        "- `edge_attr`: è¾¹çš„ç‰¹å¾çŸ©é˜µï¼ˆå¯é€‰ï¼‰\n",
        "- `y`: æ ‡ç­¾å€¼ï¼Œå³ç›®æ ‡æ€§è´¨ï¼ˆå¦‚ç”œåº¦ï¼‰\n",
        "\n",
        "è¿™æ ·çš„è¡¨ç¤ºå¯ä»¥è¢«**PyTorch Geometricï¼ˆPyGï¼‰**ç›´æ¥ç”¨äºè®­ç»ƒå›¾ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œå¦‚ GCNã€GATã€GIN ç­‰ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### å…­ã€ä¸æ·±åº¦å­¦ä¹ çš„è¿æ¥\n",
        "\n",
        "æ„å»ºå®Œå›¾ç»“æ„åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œå¯¹è¿™äº›å›¾è¿›è¡Œå»ºæ¨¡ï¼š\n",
        "\n",
        "1. **å›¾å·ç§¯å±‚ï¼ˆGNN layersï¼‰**ä¼šæ ¹æ®è¾¹çš„ç»“æ„å’Œè¾¹ç‰¹å¾ï¼Œå­¦ä¹ æ¯ä¸ªåŸå­çš„éšç©ºé—´è¡¨ç¤ºã€‚\n",
        "2. **å›¾æ± åŒ–ï¼ˆglobal poolingï¼‰**ä¼šæŠŠåŸå­çš„è¡¨ç¤ºæ•´åˆæˆæ•´ä¸ªåˆ†å­çš„è¡¨ç¤ºã€‚\n",
        "3. **å…¨è¿æ¥å±‚ï¼ˆMLPï¼‰**å°†æœ€ç»ˆå›¾å‘é‡æ˜ å°„åˆ°ç›®æ ‡å±æ€§ï¼ˆlogSwï¼‰ä¸Šï¼Œå®ç°åˆ†å­æ€§è´¨çš„é¢„æµ‹ã€‚\n",
        "\n",
        "è¿™ç§æ–¹å¼ç›¸æ¯”ä¼ ç»Ÿçš„æ‰‹å·¥ç‰¹å¾å·¥ç¨‹ï¼Œå…·æœ‰æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›å’Œç«¯åˆ°ç«¯å­¦ä¹ èƒ½åŠ›ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### ä¸ƒã€å°ç»“\n",
        "\n",
        "æœ¬æ•°æ®å¤„ç†è¿‡ç¨‹å®ç°äº†ï¼š\n",
        "- ä»åŒ–å­¦SMILESå­—ç¬¦ä¸²è‡ªåŠ¨ç”Ÿæˆå›¾ç»“æ„\n",
        "- ä¿ç•™å¹¶ç¼–ç å…³é”®çš„åŒ–å­¦å±æ€§ä¿¡æ¯\n",
        "- æ„é€ é€‚åˆå›¾ç¥ç»ç½‘ç»œæ¨¡å‹è®­ç»ƒçš„æ•°æ®é›†\n",
        "\n",
        "ä¸ºåç»­çš„å›¾ç¥ç»ç½‘ç»œæ¨¡å‹æ‰“ä¸‹åšå®åŸºç¡€ï¼Œå®ç°ä»åˆ†å­ç»“æ„åˆ°æ€§è´¨çš„**æ·±åº¦å»ºæ¨¡ä¸ç²¾å‡†é¢„æµ‹**ã€‚è¿™å°±æ˜¯å›¾ç¥ç»ç½‘ç»œåœ¨åŒ–å­¦ä¸­çš„é­…åŠ›æ‰€åœ¨ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ3tqkb41kuQ"
      },
      "source": [
        "### **ä¸ºä»€ä¹ˆè¦ä½¿ç”¨One-Hotç¼–ç ï¼Œè€Œä¸æ˜¯ç›´æ¥ä½¿ç”¨åŸå§‹ç¦»æ•£å±æ€§ï¼Ÿ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfWj2RhX1ZsL"
      },
      "source": [
        "\n",
        "\n",
        "åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œæ•°æ®çš„é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹å¯¹æ¨¡å‹çš„è¡¨ç°è‡³å…³é‡è¦ã€‚å°¤å…¶æ˜¯åœ¨å¤„ç†åƒåŒ–å­¦åˆ†å­è¿™ç§å¤æ‚çš„ç»“æ„æ•°æ®æ—¶ï¼Œå¦‚ä½•æœ‰æ•ˆåœ°è¡¨ç¤ºç¦»æ•£å±æ€§ï¼ˆä¾‹å¦‚åŸå­çš„ç±»å‹ã€æ‚åŒ–çŠ¶æ€ã€é”®çš„ç±»å‹ç­‰ï¼‰æ˜¯ä¸€ä¸ªé‡è¦çš„é—®é¢˜ã€‚ä¸ºäº†ä½¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°å­¦ä¹ è¿™äº›ç¦»æ•£å±æ€§ï¼Œæˆ‘ä»¬é€šå¸¸é€‰æ‹©ä½¿ç”¨**One-Hotç¼–ç **ï¼Œè€Œä¸æ˜¯ç›´æ¥ä½¿ç”¨åŸå§‹çš„ç¦»æ•£å±æ€§å€¼ã€‚ä»¥ä¸‹æ˜¯å‡ ä¸ªä¸»è¦åŸå› ï¼š\n",
        "\n",
        "---\n",
        "\n",
        "#### ä¸€ã€æ·±åº¦å­¦ä¹ æ¨¡å‹çš„éœ€æ±‚\n",
        "\n",
        "æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå°¤å…¶æ˜¯ç¥ç»ç½‘ç»œï¼Œå€¾å‘äºå¤„ç†æ•°å€¼æ•°æ®ï¼Œå› ä¸ºæ•°å€¼æ•°æ®çš„å¤§å°å…³ç³»å¯ä»¥é€šè¿‡æ•°å­¦è¿ç®—ï¼ˆå¦‚åŠ æ³•ã€ä¹˜æ³•ç­‰ï¼‰æ•æ‰å’Œåˆ©ç”¨ã€‚å¯¹äºç¦»æ•£å±æ€§ï¼š\n",
        "- **åŸå§‹ç¦»æ•£å±æ€§**ï¼ˆå¦‚åŸå­ç±»å‹ç¼–å·ã€æ‚åŒ–ç±»å‹ç¼–å·ï¼‰é€šå¸¸æ˜¯æ•´æ•°æˆ–è€…åˆ†ç±»æ ‡è¯†ç¬¦ï¼Œå®ƒä»¬ä¹‹é—´å¹¶æ²¡æœ‰æ˜¾è‘—çš„é¡ºåºå…³ç³»ã€‚ä¾‹å¦‚ï¼ŒåŸå­åºæ•°ï¼ˆ1ä»£è¡¨æ°¢ï¼Œ6ä»£è¡¨ç¢³ï¼‰æœ¬è´¨ä¸Šåªæ˜¯ä¸€ä¸ªæ ‡ç­¾ï¼Œè€Œä¸æ˜¯â€œ1æ¯”6å¤§â€è¿™æ ·æœ‰æ„ä¹‰çš„æ•°å€¼å…³ç³»ã€‚\n",
        "- **One-Hotç¼–ç **å°†è¿™äº›ç¦»æ•£çš„ç±»åˆ«è½¬æ¢ä¸ºä¸€ä¸ªå‘é‡ï¼Œå…¶ä¸­æ¯ä¸ªç±»åˆ«éƒ½å¯¹åº”ä¸€ä¸ªç‰¹å®šä½ç½®çš„1ï¼Œè€Œå…¶ä»–ä½ç½®æ˜¯0ã€‚è¿™æ ·ï¼Œæ¨¡å‹ä¸ä¼šè¯¯è§£è¿™äº›ç¦»æ•£ç±»åˆ«ä¹‹é—´çš„â€œå¤§å°å…³ç³»â€ï¼Œå› ä¸ºOne-Hotç¼–ç çš„æ‰€æœ‰ç±»åˆ«ä¹‹é—´æ˜¯**ç­‰è·çš„**ï¼Œå³å®ƒä»¬ä¹‹é—´æ²¡æœ‰å†…åœ¨çš„æ•°å­¦é¡ºåºå…³ç³»ã€‚\n",
        "\n",
        "é€šè¿‡One-Hotç¼–ç ï¼Œæˆ‘ä»¬æœ‰æ•ˆé¿å…äº†æ¨¡å‹å­¦ä¹ åˆ°é”™è¯¯çš„å…³ç³»ï¼Œä¾‹å¦‚é”™è¯¯åœ°è®¤ä¸ºæ°¢ï¼ˆç¼–å·1ï¼‰å’Œç¢³ï¼ˆç¼–å·6ï¼‰ä¹‹é—´çš„æ•°å€¼å·®è·æœ‰å®é™…æ„ä¹‰ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### äºŒã€é¿å…æ¨¡å‹è¯¯è§£ç±»åˆ«é—´çš„é¡ºåºå…³ç³»\n",
        "\n",
        "å‡è®¾æˆ‘ä»¬ç›´æ¥å°†åŸå§‹çš„ç¦»æ•£å±æ€§ï¼ˆä¾‹å¦‚åŸå­ç±»å‹ï¼‰ä½œä¸ºæ¨¡å‹è¾“å…¥ï¼Œå¦‚æœæˆ‘ä»¬ç”¨æ•´æ•°è¡¨ç¤ºåŸå­ç±»å‹ï¼ˆä¾‹å¦‚ï¼Œæ°¢æ˜¯1ï¼Œæ°®æ˜¯2ï¼Œç¢³æ˜¯3ï¼‰ï¼Œç¥ç»ç½‘ç»œå¯èƒ½ä¼š**è¯¯è§£**è¿™äº›æ•´æ•°ä¹‹é—´å­˜åœ¨æŸç§é¡ºåºå…³ç³»ï¼Œæ¯”å¦‚ï¼š\n",
        "- æ•°å­—â€œ1â€å¯èƒ½åœ¨æ¨¡å‹å†…éƒ¨è¢«è§†ä¸ºæ¯”â€œ6â€å°ï¼Œæˆ–è€…â€œ6â€ä¸â€œ1â€ä¹‹é—´æœ‰æŸç§è·ç¦»ï¼ˆä¾‹å¦‚6å’Œ1ä¹‹é—´å·®å€¼æ˜¯5ï¼‰ã€‚\n",
        "  \n",
        "è¿™ç§å…³ç³»å¯¹åŸå­ç±»å‹æ¥è¯´æ˜¯æ²¡æœ‰æ„ä¹‰çš„ï¼Œå› ä¸ºåŸå­ç±»å‹ä¹‹é—´æ²¡æœ‰è‡ªç„¶çš„é¡ºåºã€‚å®é™…ä¸Šï¼Œæ°¢ï¼ˆ1ï¼‰å’Œç¢³ï¼ˆ6ï¼‰æ˜¯å®Œå…¨ä¸åŒçš„å…ƒç´ ï¼Œç›´æ¥ç”¨æ•°å­—è¡¨ç¤ºä¼šå¯¼è‡´æ¨¡å‹åœ¨å­¦ä¹ æ—¶å¼•å…¥é”™è¯¯çš„å‡è®¾ã€‚\n",
        "\n",
        "**One-Hotç¼–ç **é€šè¿‡å°†æ¯ä¸ªç±»åˆ«è¡¨ç¤ºä¸ºä¸€ä¸ªç‹¬ç«‹çš„äºŒè¿›åˆ¶å‘é‡ï¼Œæ¶ˆé™¤äº†è¿™ç§è¯¯è§£ï¼Œä½¿å¾—æ¯ä¸ªç±»åˆ«éƒ½æ˜¯ç‹¬ç«‹çš„ã€‚æ¯”å¦‚ï¼š\n",
        "- æ°¢ä¼šè¢«è¡¨ç¤ºä¸º[1, 0, 0, ..., 0]ï¼ˆåœ¨åŸå­ç±»å‹ç‰¹å¾å‘é‡ä¸­åªæœ‰æ°¢çš„å¯¹åº”ä½ç½®æ˜¯1ï¼Œå…¶ä»–ä½ç½®æ˜¯0ï¼‰\n",
        "- ç¢³ä¼šè¢«è¡¨ç¤ºä¸º[0, 0, 1, ..., 0]\n",
        "  \n",
        "è¿™æ„å‘³ç€æ¨¡å‹åªèƒ½é€šè¿‡å­¦ä¹ æ¯ä¸ªç±»åˆ«å¯¹åº”çš„å•ç‹¬ç»´åº¦æ¥åˆ¤æ–­åŸå­çš„ç±»å‹ï¼Œè€Œä¸ä¼šé”™è¯¯åœ°å­¦ä¹ åˆ°å®ƒä»¬ä¹‹é—´çš„å¤§å°å…³ç³»ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### ä¸‰ã€ç®€åŒ–æ¨¡å‹çš„å­¦ä¹ è¿‡ç¨‹\n",
        "\n",
        "ä½¿ç”¨One-Hotç¼–ç çš„å¦ä¸€ä¸ªä¼˜åŠ¿æ˜¯**ç®€åŒ–äº†æ¨¡å‹çš„å­¦ä¹ è¿‡ç¨‹**ã€‚One-Hotç¼–ç ä½¿å¾—æ¯ä¸ªç¦»æ•£å±æ€§çš„æ¯ä¸ªå–å€¼éƒ½èƒ½ç‹¬ç«‹åœ°è¿›è¡Œå­¦ä¹ ï¼Œè€Œä¸å¿…æ‹…å¿ƒè¿™äº›å–å€¼ä¹‹é—´çš„æ½œåœ¨å…³ç³»ã€‚\n",
        "- å¦‚æœæˆ‘ä»¬ç›´æ¥ä½¿ç”¨åŸå§‹çš„ç¦»æ•£å±æ€§ï¼ˆä¾‹å¦‚æ•´æ•°ç¼–ç ï¼‰ï¼Œæ¨¡å‹å¿…é¡»è‡ªåŠ¨å­¦ä¹ è¿™äº›å±æ€§ä¹‹é—´çš„å…³ç³»ï¼Œå¯èƒ½ä¼šå¯¼è‡´è¾ƒé•¿çš„è®­ç»ƒæ—¶é—´æˆ–æ€§èƒ½ä¸‹é™ã€‚\n",
        "- One-Hotç¼–ç é€šè¿‡ä¸ºæ¯ä¸ªç±»åˆ«åˆ›å»ºç‹¬ç«‹çš„ç‰¹å¾ç»´åº¦ï¼Œ**æ˜ç¡®åœ°å°†ç±»åˆ«ä¹‹é—´çš„å…³ç³»éš”ç¦»å¼€**ï¼Œè®©æ¨¡å‹åœ¨å­¦ä¹ æ—¶ä¸“æ³¨äºå¦‚ä½•åŒºåˆ†æ¯ä¸ªç±»åˆ«çš„ç‰¹å¾ï¼Œè€Œä¸éœ€è¦æ‹…å¿ƒç±»åˆ«ä¹‹é—´çš„æ½œåœ¨æ•°å€¼å…³ç³»ã€‚\n",
        "\n",
        "ä¾‹å¦‚ï¼Œåœ¨åŒ–å­¦åˆ†å­ä¸­ï¼ŒåŸå­ç±»å‹ã€æ‚åŒ–çŠ¶æ€ã€æ‰‹æ€§ç­‰å„è‡ªæ˜¯ç‹¬ç«‹çš„ç‰¹å¾ï¼ŒOne-Hotç¼–ç èƒ½å¤Ÿè®©æ¨¡å‹ä¸“æ³¨äºä»è¿™äº›ç‹¬ç«‹ç‰¹å¾ä¸­å­¦ä¹ æ›´å¤æ‚çš„æ¨¡å¼ï¼Œè€Œä¸ä¼šå› ä¸ºç±»åˆ«é—´çš„é”™è¯¯é¡ºåºè€Œå½±å“æ€§èƒ½ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### å››ã€æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›\n",
        "\n",
        "One-Hotç¼–ç æœ‰åŠ©äºæé«˜æ¨¡å‹çš„**æ³›åŒ–èƒ½åŠ›**ï¼Œå°¤å…¶æ˜¯åœ¨é¢å¯¹æ–°çš„ã€æœªè§è¿‡çš„ç±»åˆ«æ—¶ã€‚å¦‚æœæˆ‘ä»¬ä½¿ç”¨åŸå§‹çš„ç¦»æ•£å±æ€§ï¼ˆä¾‹å¦‚æ•´æ•°ï¼‰ï¼Œä¸€æ—¦æ¨¡å‹é‡åˆ°ä¸€ä¸ªæ²¡æœ‰åœ¨è®­ç»ƒé›†å‡ºç°è¿‡çš„å€¼ï¼Œæ¨¡å‹å¯èƒ½æ— æ³•æ­£ç¡®ç†è§£è¿™ä¸ªå€¼å¹¶è¿›è¡Œæœ‰æ•ˆé¢„æµ‹ã€‚è€ŒOne-Hotç¼–ç é€šè¿‡å°†æ¯ä¸ªç±»åˆ«ç‹¬ç«‹è¡¨ç¤ºä¸ºä¸€ä¸ªå‘é‡ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨é¢å¯¹æ–°çš„ç±»åˆ«æ—¶ä»ç„¶èƒ½å¤Ÿè¿›è¡Œæœ‰æ•ˆçš„å­¦ä¹ ï¼Œå› ä¸ºæ¯ä¸ªç±»åˆ«éƒ½æœ‰ä¸€ä¸ªæ˜ç¡®çš„è¡¨ç¤ºã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### äº”ã€æ€»ç»“\n",
        "\n",
        "é€šè¿‡ä½¿ç”¨One-Hotç¼–ç ï¼Œæˆ‘ä»¬å®ç°äº†ï¼š\n",
        "- **æ¶ˆé™¤æ— å…³é¡ºåºå…³ç³»**ï¼Œé˜²æ­¢æ¨¡å‹é”™è¯¯å­¦ä¹ ç±»åˆ«ä¹‹é—´çš„æ•°å€¼å…³ç³»ï¼›\n",
        "- **ç®€åŒ–æ¨¡å‹çš„å­¦ä¹ è¿‡ç¨‹**ï¼Œè®©æ¨¡å‹æ›´ä¸“æ³¨äºæ¯ä¸ªç‰¹å¾ï¼›\n",
        "- **æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›**ï¼Œè®©æ¨¡å‹æ›´å¥½åœ°å¤„ç†æ–°ç±»åˆ«ã€‚\n",
        "\n",
        "æ€»çš„æ¥è¯´ï¼ŒOne-Hotç¼–ç æ˜¯ä¸€ç§åœ¨æ·±åº¦å­¦ä¹ ä¸­å¹¿æ³›ä½¿ç”¨çš„æŠ€æœ¯ï¼Œå®ƒèƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†ç¦»æ•£å±æ€§ï¼Œå¹¶ä¸ºæ¨¡å‹æä¾›æ¸…æ™°ã€æ— æ­§ä¹‰çš„è¾“å…¥ï¼Œä»è€Œå¢å¼ºæ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›å’Œé¢„æµ‹èƒ½åŠ›ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijrdgHc3DipJ"
      },
      "source": [
        "### **è®©æˆ‘ä»¬éšæœºæ‰¾ä¸€ä¸ªæ•°æ®ç…ç…å®ƒé•¿ä»€ä¹ˆæ ·**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lOrFkT0ZHTB"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch_geometric.utils import to_networkx, to_dense_adj\n",
        "from rdkit.Chem import Draw, AllChem\n",
        "from google.colab import data_table\n",
        "\n",
        "# å¯ç”¨ Colab çš„äº¤äº’å¼è¡¨æ ¼æ˜¾ç¤ºï¼Œå¹¶è®¾ç½®ä¸åšæˆªæ–­\n",
        "data_table.enable_dataframe_formatter()\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "def visualize_and_inspect_aligned_molecule(dataset):\n",
        "    if len(dataset) == 0:\n",
        "        print(\"æ•°æ®é›†ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œå¯è§†åŒ–ã€‚\")\n",
        "        return\n",
        "\n",
        "    # 1. ç­›é€‰é‡åŸå­æ•°å°äº 15 çš„åˆ†å­ (ä¿æŒå›¾è¡¨æ¸…æ™°)\n",
        "    small_molecules_indices = []\n",
        "    for i in range(len(dataset)):\n",
        "        if dataset[i].x.shape[0] < 15:\n",
        "            small_molecules_indices.append(i)\n",
        "\n",
        "    if not small_molecules_indices:\n",
        "        print(\"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„åˆ†å­ã€‚\")\n",
        "        return\n",
        "\n",
        "    # 2. éšæœºæŠ½å–ä¸€ä¸ªç¬¦åˆæ¡ä»¶çš„æ ·æœ¬\n",
        "    idx = random.choice(small_molecules_indices)\n",
        "    data = dataset[idx]\n",
        "\n",
        "    print(f\"\\n{'='*40}\")\n",
        "    print(f\"éšæœºæŠ½å–çš„æ ·æœ¬ç´¢å¼•: {idx}\")\n",
        "    print(f\"SMILES: {data.smiles}\")\n",
        "    print(f\"ç”œåº¦å€¼ (Label): {data.y.item()}\")\n",
        "    print(f\"åŸå­æ•°é‡: {data.x.shape[0]}\")\n",
        "    print(f\"{'='*40}\\n\")\n",
        "\n",
        "    # =========================================\n",
        "    # å¯è§†åŒ–éƒ¨åˆ† (å›¾åƒ - åæ ‡å¯¹é½ç‰ˆ)\n",
        "    # =========================================\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "    # --- å‡†å¤‡ RDKit åˆ†å­å¯¹è±¡å¹¶è®¡ç®— 2D åæ ‡ ---\n",
        "    mol = Chem.MolFromSmiles(data.smiles)\n",
        "    if mol:\n",
        "        # å¼ºåˆ¶è®¡ç®— 2D åæ ‡ï¼Œè¿™æ ·æˆ‘ä»¬æ‰èƒ½è·å–æ¯ä¸ªåŸå­çš„ (x, y) ä½ç½®\n",
        "        AllChem.Compute2DCoords(mol)\n",
        "\n",
        "        # ç»™åŸå­æ‰“ä¸Šç´¢å¼•æ ‡ç­¾\n",
        "        for i, atom in enumerate(mol.GetAtoms()):\n",
        "            atom.SetProp('molAtomMapNumber', str(i))\n",
        "\n",
        "        # ç»˜åˆ¶å·¦å›¾ï¼šRDKit æ ‡å‡†åŒ–å­¦ç»“æ„\n",
        "        img = Draw.MolToImage(mol, size=(500, 500))\n",
        "        axes[0].imshow(img)\n",
        "        axes[0].set_title(f\"RDKit Chemical Structure\\n(Index: {idx})\", fontsize=12, fontweight='bold')\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        # --- è·å– RDKit åæ ‡ç”¨äº NetworkX ---\n",
        "        # RDKit çš„ Conformer å­˜å‚¨äº†åŸå­çš„ç©ºé—´ä½ç½®\n",
        "        conf = mol.GetConformer()\n",
        "        rdkit_pos = {}\n",
        "        for i in range(mol.GetNumAtoms()):\n",
        "            # è·å–ç¬¬ i ä¸ªåŸå­çš„ä½ç½®\n",
        "            pt = conf.GetAtomPosition(i)\n",
        "            # å­˜å…¥å­—å…¸ {èŠ‚ç‚¹ç´¢å¼•: (xåæ ‡, yåæ ‡)}\n",
        "            rdkit_pos[i] = (pt.x, pt.y)\n",
        "    else:\n",
        "        axes[0].text(0.5, 0.5, \"Invalid Molecule\", ha='center')\n",
        "        rdkit_pos = None\n",
        "\n",
        "    # --- å³å›¾ï¼šNetworkX å›¾ç»“æ„ (ä½¿ç”¨ RDKit åæ ‡) ---\n",
        "    G = to_networkx(data, to_undirected=True)\n",
        "\n",
        "    axes[1].set_title(\"NetworkX Graph Topology\\n(Aligned with RDKit Coordinates)\", fontsize=12, fontweight='bold')\n",
        "\n",
        "    if rdkit_pos:\n",
        "        # ä½¿ç”¨è‡ªå®šä¹‰çš„ pos (æ¥è‡ª RDKit) æ›¿ä»£ spring_layout\n",
        "        nx.draw(G, pos=rdkit_pos, ax=axes[1],\n",
        "                with_labels=True,\n",
        "                node_color='lightblue',\n",
        "                node_size=600,\n",
        "                edge_color='gray',\n",
        "                width=2, # å¢åŠ è¾¹å®½\n",
        "                font_weight='bold')\n",
        "\n",
        "        # ç¨å¾®è°ƒæ•´ä¸€ä¸‹åæ ‡è½´èŒƒå›´ï¼Œé˜²æ­¢èŠ‚ç‚¹è´´è¾¹\n",
        "        x_values, y_values = zip(*rdkit_pos.values())\n",
        "        x_margin = (max(x_values) - min(x_values)) * 0.1\n",
        "        y_margin = (max(y_values) - min(y_values)) * 0.1\n",
        "        axes[1].set_xlim(min(x_values) - x_margin, max(x_values) + x_margin)\n",
        "        axes[1].set_ylim(min(y_values) - y_margin, max(y_values) + y_margin)\n",
        "    else:\n",
        "        # å¦‚æœè·å–åæ ‡å¤±è´¥ï¼Œå›é€€åˆ°éšæœºå¸ƒå±€\n",
        "        nx.draw(G, ax=axes[1], with_labels=True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # =========================================\n",
        "    # çŸ©é˜µæ•°æ®å±•ç¤º (Colab è¡¨æ ¼)\n",
        "    # =========================================\n",
        "    print(\"\\n\" + \"=\"*20 + \" 1. èŠ‚ç‚¹ç‰¹å¾çŸ©é˜µ (Node Features X) \" + \"=\"*20)\n",
        "    node_cols = [f\"Feature_{i}\" for i in range(data.x.shape[1])]\n",
        "    df_x = pd.DataFrame(data.x.numpy().astype(int), columns=node_cols)\n",
        "    df_x.index.name = \"Atom_Index\"\n",
        "    display(data_table.DataTable(df_x, num_rows_per_page=20))\n",
        "\n",
        "    print(\"\\n\" + \"=\"*20 + \" 2. é‚»æ¥çŸ©é˜µ (Adjacency Matrix A) \" + \"=\"*20)\n",
        "    adj_dense = to_dense_adj(data.edge_index)[0].numpy().astype(int)\n",
        "    cols_adj = [f\"Atom_{i}\" for i in range(adj_dense.shape[0])]\n",
        "    df_adj = pd.DataFrame(adj_dense, columns=cols_adj, index=cols_adj)\n",
        "    display(data_table.DataTable(df_adj, num_rows_per_page=20))\n",
        "\n",
        "    print(\"\\n\" + \"=\"*20 + \" 3. è¾¹ç‰¹å¾çŸ©é˜µ (Edge Features E) \" + \"=\"*20)\n",
        "    if data.edge_attr is not None and data.edge_attr.size(0) > 0:\n",
        "        edge_cols = [\"Is_Single\", \"Is_Double\", \"Is_Triple\", \"Is_Aromatic\", \"Is_Conjugated\", \"Is_InRing\"]\n",
        "        src, dst = data.edge_index\n",
        "        edge_data = data.edge_attr.numpy().astype(int)\n",
        "\n",
        "        df_edge = pd.DataFrame(edge_data, columns=edge_cols)\n",
        "        df_edge.insert(0, \"Target_Atom\", dst.numpy())\n",
        "        df_edge.insert(0, \"Source_Atom\", src.numpy())\n",
        "\n",
        "        display(data_table.DataTable(df_edge, num_rows_per_page=20))\n",
        "    else:\n",
        "        print(\"è¯¥åˆ†å­æ²¡æœ‰è¾¹æˆ–è¾¹ç‰¹å¾ä¸ºç©ºã€‚\")\n",
        "\n",
        "# è¿è¡Œ\n",
        "if __name__ == \"__main__\":\n",
        "    if 'dataset' in locals():\n",
        "        visualize_and_inspect_aligned_molecule(dataset)\n",
        "    else:\n",
        "        print(\"è¯·å…ˆè¿è¡Œæ•°æ®å¤„ç†ä»£ç ç”Ÿæˆ datasetã€‚\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFT2zZRZa_mM"
      },
      "source": [
        "### æ•°æ®è§£é‡Š"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WId3mTZfXptW"
      },
      "source": [
        "#### 1\\. èŠ‚ç‚¹ç‰¹å¾çŸ©é˜µ `data.x` (ç»´åº¦: 69)\n",
        "\n",
        "è¯¥çŸ©é˜µæ¯ä¸€è¡Œä»£è¡¨ä¸€ä¸ªåŸå­ã€‚ç”±äºå¤šä¸ª One-Hot å‘é‡æ˜¯é¦–å°¾æ‹¼æ¥çš„ï¼Œæˆ‘ä»¬éœ€è¦ç´¯åŠ ç´¢å¼•æ¥å®šä½ç‰¹å¾ã€‚æ€»ç»´åº¦ä¸º **69** (38 + 6 + 9 + 9 + 6 + 1)ã€‚\n",
        "\n",
        "| å…¨å±€ç´¢å¼•èŒƒå›´ | ç‰¹å¾ç±»åˆ« | é•¿åº¦ | å…·ä½“æ¯ä¸€ä½ (Bit) çš„è¯¦ç»†å¯¹åº” |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| **0 - 37** | **åŸå­ç±»å‹**<br>(Atom Type) | 38 | **0-36**: å¯¹åº”ä»¥ä¸‹ 37 ç§å…ƒç´ ï¼š<br>H, Li, Be, B, C, N, O, F, Na, Mg, Al, Si, P, S, Cl, K, Ca, Sc, Ni, Cu, Zn, Ga, Ge, As, Se, Br, Kr, Rb, Sr, Pd, Ag, Cd, In, Sn, Sb, Te, I<br>**37**: å…¶ä»–å…ƒç´  (ä¸åœ¨ä¸Šè¿°åˆ—è¡¨ä¸­) |\n",
        "| **38 - 43** | **è¿æ¥åº¦**<br>(Degree) | 6 | **38**: è¿æ¥åº¦ 0 (å­¤ç«‹åŸå­)<br>**39**: è¿æ¥åº¦ 1<br>**40**: è¿æ¥åº¦ 2<br>**41**: è¿æ¥åº¦ 3<br>**42**: è¿æ¥åº¦ 4<br>**43**: å…¶ä»– (è¿æ¥åº¦ \\> 4) |\n",
        "| **44 - 52** | **æ‚åŒ–ç±»å‹**<br>(Hybridization) | 9 | **44**: UNSPECIFIED (æœªæŒ‡å®š)<br>**45**: S<br>**46**: SP<br>**47**: SP2<br>**48**: SP3<br>**49**: SP2D<br>**50**: SP3D<br>**51**: SP3D2<br>**52**: å…¶ä»– (å« OTHER) |\n",
        "| **53 - 61** | **æ‰‹æ€§æ ‡ç­¾**<br>(Chiral Tag) | 9 | **53**: CHI\\_UNSPECIFIED (æ— /æœªæŒ‡å®š)<br>**54**: CHI\\_CW (é¡ºæ—¶é’ˆ)<br>**55**: CHI\\_CCW (é€†æ—¶é’ˆ)<br>**56**: CHI\\_OTHER<br>**57**: CHI\\_TETRAHEDRAL<br>**58**: CHI\\_ALLENE<br>**59**: CHI\\_SQUAREPLANAR<br>**60**: CHI\\_TRIGONALBIPYRAMIDAL<br>**61**: å…¶ä»– (å« OCTAHEDRAL) |\n",
        "| **62 - 67** | **æ°¢åŸå­æ•°**<br>(Num Hs) | 6 | **62**: 0 ä¸ªæ°¢<br>**63**: 1 ä¸ªæ°¢<br>**64**: 2 ä¸ªæ°¢<br>**65**: 3 ä¸ªæ°¢<br>**66**: 4 ä¸ªæ°¢<br>**67**: å…¶ä»– (æ°¢åŸå­ \\> 4) |\n",
        "| **68** | **èŠ³é¦™æ€§**<br>(Is Aromatic) | 1 | **68**: æ˜¯å¦ä¸ºèŠ³é¦™åŸå­ (1=æ˜¯, 0=å¦) |\n",
        "\n",
        "-----\n",
        "\n",
        "#### 2\\. è¾¹ç‰¹å¾çŸ©é˜µ `data.edge_attr` (ç»´åº¦: 6)\n",
        "\n",
        "è¾¹ç‰¹å¾çŸ©é˜µæ¯ä¸€è¡Œä»£è¡¨ä¸€æ¡åŒ–å­¦é”®ã€‚ç´¢å¼•ä» 0 å¼€å§‹ã€‚\n",
        "\n",
        "| ç´¢å¼•ä½ç½® | ç‰¹å¾åç§° | å«ä¹‰ (å¦‚æœè¯¥ä½ä¸º 1) |\n",
        "| :--- | :--- | :--- |\n",
        "| **0** | **å•é”®** (Single) | è¯¥é”®æ˜¯å•é”® |\n",
        "| **1** | **åŒé”®** (Double) | è¯¥é”®æ˜¯åŒé”® |\n",
        "| **2** | **ä¸‰é”®** (Triple) | è¯¥é”®æ˜¯ä¸‰é”® |\n",
        "| **3** | **èŠ³é¦™é”®** (Aromatic) | è¯¥é”®æ˜¯èŠ³é¦™é”® (å¸¸è§äºè‹¯ç¯) |\n",
        "| **4** | **å…±è½­** (Is Conjugated) | è¯¥é”®å¤„äºå…±è½­ä½“ç³»ä¸­ (å•åŒé”®äº¤æ›¿) |\n",
        "| **5** | **åœ¨ç¯ä¸­** (Is In Ring) | è¯¥é”®æ˜¯ç¯ç»“æ„çš„ä¸€éƒ¨åˆ† |\n",
        "\n",
        "-----\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mi35IhvBPQdy"
      },
      "source": [
        "## **2-GNNæ¨¡å‹æ­å»ºã€è®­ç»ƒåŠè¯„ä¼°**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBhFrCmQSMbE"
      },
      "source": [
        "### **å…ˆåªç”¨è¯•è¯•GATï¼ˆå›¾æ³¨æ„åŠ›ï¼‰ç½‘ç»œ**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKasGXSXOz2U"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.metrics import r2_score\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# è®¾ç½®éšæœºç§å­ä»¥ä¿è¯å¯å¤ç°æ€§\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "seed_everything()\n",
        "\n",
        "# å›¾æ³¨æ„åŠ›ç½‘ç»œ\n",
        "class GATNet(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=16, output_dim=1, heads=2):\n",
        "        super(GATNet, self).__init__()\n",
        "        self.gat1 = GATConv(input_dim, hidden_dim, heads=heads, dropout=0.1)\n",
        "        self.gat2 = GATConv(hidden_dim * heads, hidden_dim, heads=1, dropout=0.1)\n",
        "        self.pool = global_mean_pool  # å¯æ”¹ä¸º max_pool ç­‰\n",
        "\n",
        "        self.linear = torch.nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index, batch, edge_attr=None):\n",
        "        x = self.gat1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = self.gat2(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = self.pool(x, batch)\n",
        "        out = self.linear(x)\n",
        "        return out.squeeze()  # è¾“å‡ºä¸€ç»´é¢„æµ‹å€¼\n",
        "\n",
        "# åŠ è½½æ•°æ®\n",
        "\n",
        "dataset = MolDataset(csv_path='/content/SweetpredDB.csv')\n",
        "\n",
        "# æ•°æ®åˆ’åˆ†\n",
        "train_ratio = 0.8\n",
        "train_size = int(train_ratio * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "# æ¨¡å‹å‡†å¤‡\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = GATNet(input_dim=dataset[0].x.shape[1]).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# è®­ç»ƒå‡½æ•°\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(batch.x, batch.edge_index, batch.batch)\n",
        "        loss = loss_fn(pred, batch.y.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * batch.num_graphs\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "# éªŒè¯å‡½æ•°\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    preds, labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            pred = model(batch.x, batch.edge_index, batch.batch)\n",
        "            preds.append(pred.cpu())\n",
        "            labels.append(batch.y.cpu())\n",
        "    preds = torch.cat(preds)\n",
        "    labels = torch.cat(labels)\n",
        "    mse = F.mse_loss(preds, labels).item()\n",
        "    r2 = r2_score(labels.numpy(), preds.numpy())\n",
        "    return mse, r2\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# æ·»åŠ è¿™ä¸¤ä¸ªåˆ—è¡¨ç”¨äºè®°å½•loss\n",
        "# â³ è®­ç»ƒä¸»å¾ªç¯ + ä¿å­˜ç‰¹å¾\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_val_r2 = -float(\"inf\")\n",
        "best_epoch = 0  # è®°å½•æœ€ä½³æ¨¡å‹çš„epoch\n",
        "\n",
        "for epoch in range(1, 201):\n",
        "    train_loss = train()\n",
        "    val_mse, val_r2 = evaluate(val_loader)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_mse)\n",
        "\n",
        "    if val_r2 > best_val_r2:\n",
        "        best_val_r2 = val_r2\n",
        "        best_epoch = epoch  # æ›´æ–°æœ€ä½³æ¨¡å‹çš„epoch\n",
        "        torch.save(model.state_dict(), \"Best_GAT_Model.pt\")\n",
        "\n",
        "    # ä¿å­˜æœ¬è½®è®­ç»ƒçš„å›¾è¡¨ç¤º + æ ‡ç­¾\n",
        "\n",
        "    if epoch % 1 == 0 or epoch == 1:\n",
        "        print(f\"Epoch {epoch:03d} | Train Loss: {train_loss:.4f} | Val MSE: {val_mse:.4f} | Val R2: {val_r2:.4f}\")\n",
        "\n",
        "print(f\"è®­ç»ƒå®Œæˆ âœ… æœ€ä½³éªŒè¯é›† RÂ²: {best_val_r2:.4f} (åœ¨ç¬¬ {best_epoch} è½®)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-HP1WTodFpV"
      },
      "outputs": [],
      "source": [
        "# ğŸ“ˆ ç»˜åˆ¶å­¦ä¹ æ›²çº¿\n",
        "plt.figure(figsize=(5, 5),dpi=200)\n",
        "\n",
        "# æŒ‡å®š RGB é¢œè‰²ï¼ˆ0~1 å½’ä¸€åŒ–ï¼‰\n",
        "train_color = (75 / 255, 116 / 255, 178 / 255)   # è“è‰²\n",
        "val_color = (219 / 255, 49 / 255, 36 / 255)      # çº¢è‰²\n",
        "\n",
        "plt.plot(train_losses, label='Train Loss', color=train_color)\n",
        "plt.plot(val_losses, label='Validation Loss', color=val_color)\n",
        "\n",
        "# æ ‡è®°æœ€ä½³æ¨¡å‹çš„è¿­ä»£æ¬¡æ•°\n",
        "plt.axvline(x=best_epoch-1, color='black', linestyle='--', label=f'Best Model at Epoch {best_epoch}')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.title('GAT')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"loss_curve.png\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1diy3EydfRb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ç»˜åˆ¶é¢„æµ‹å€¼å’ŒçœŸå®å€¼æ¯”è¾ƒå›¾\n",
        "best_model = torch.load(\"/content/Best_GAT_Model.pt\")\n",
        "model.load_state_dict(best_model)\n",
        "\n",
        "model.eval()\n",
        "preds, labels = [], []\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        batch = batch.to(device)\n",
        "        pred = model(batch.x, batch.edge_index, batch.batch)\n",
        "        preds.append(pred.cpu())\n",
        "        labels.append(batch.y.cpu())\n",
        "\n",
        "preds = torch.cat(preds)\n",
        "labels = torch.cat(labels)\n",
        "\n",
        "\n",
        "# ç»˜åˆ¶é¢„æµ‹å€¼å’ŒçœŸå®å€¼æ¯”è¾ƒå›¾\n",
        "plt.figure(figsize=(5, 5), dpi=200)\n",
        "\n",
        "# ç»˜åˆ¶æ•£ç‚¹å›¾ï¼Œé¢„æµ‹å€¼ç”¨è“è‰²\n",
        "plt.scatter(labels, preds, alpha=0.7, color=(75 / 255, 116 / 255, 178 / 255), label='Predictions')\n",
        "\n",
        "# ç»˜åˆ¶å¯¹è§’çº¿ï¼ŒçœŸå®å€¼ç”¨çº¢è‰²\n",
        "plt.plot([min(labels), max(labels)], [min(labels), max(labels)], 'k--', lw=2, color=(219 / 255, 49 / 255, 36 / 255), label='True Values')\n",
        "\n",
        "# è®¡ç®— R2 å’Œ MSE\n",
        "mse = F.mse_loss(preds, labels).item()\n",
        "r2 = r2_score(labels.numpy(), preds.numpy())\n",
        "\n",
        "# æ·»åŠ æ ‡ç­¾ã€æ ‡é¢˜ä»¥åŠè®¡ç®—çš„ R2 å’Œ MSE å€¼\n",
        "plt.xlabel('True Values')\n",
        "plt.ylabel('Predictions')\n",
        "plt.title(f'True vs Predicted Values (Best Model)\\nMSE: {mse:.4f} | RÂ²: {r2:.4f}')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCBy0f5P2HuO"
      },
      "source": [
        "### **GATå›¾ç¥ç»ç½‘ç»œè®­ç»ƒä¸è¯„ä¼°è¿‡ç¨‹è§£é‡Š**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1zkEmnZ2F-x"
      },
      "source": [
        "\n",
        "\n",
        "æœ¬é¡¹ç›®æ—¨åœ¨åˆ©ç”¨**å›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGATï¼‰**æ¥é¢„æµ‹åˆ†å­çš„ç”œåº¦ï¼ˆlogSwï¼‰ã€‚ä»¥ä¸‹æ˜¯å¯¹æ•´ä¸ªè®­ç»ƒä¸è¯„ä¼°è¿‡ç¨‹çš„è¯¦ç»†è§£é‡Šï¼ŒåŒ…æ‹¬å¦‚ä½•æ„å»ºGATæ¨¡å‹ã€è®­ç»ƒã€éªŒè¯ä»¥åŠæ€§èƒ½è¯„ä¼°ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### ä¸€ã€å›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGATï¼‰ç®€ä»‹\n",
        "\n",
        "å›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGATï¼‰æ˜¯ä¸€ç§åŸºäºå›¾çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œä¸»è¦ç”¨äºå¤„ç†å›¾ç»“æ„æ•°æ®ã€‚ä¸ä¼ ç»Ÿçš„å›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰ä¸åŒï¼ŒGATé‡‡ç”¨äº†**æ³¨æ„åŠ›æœºåˆ¶**æ¥è®¡ç®—èŠ‚ç‚¹ä¹‹é—´çš„ä¿¡æ¯ä¼ é€’æƒé‡ï¼Œå…è®¸æ¨¡å‹æ ¹æ®ä¸åŒé‚»å±…èŠ‚ç‚¹çš„é‡è¦æ€§è‡ªåŠ¨è°ƒæ•´æƒé‡ï¼Œä»è€Œæ›´çµæ´»åœ°è¿›è¡Œå›¾ç»“æ„æ•°æ®çš„å­¦ä¹ ã€‚\n",
        "\n",
        "åœ¨æœ¬é¡¹ç›®ä¸­ï¼ŒGATè¢«ç”¨æ¥å¤„ç†åˆ†å­å›¾æ•°æ®ï¼Œæ¨¡å‹çš„ç›®æ ‡æ˜¯ä»åˆ†å­å›¾ä¸­å­¦ä¹ ç»“æ„ä¿¡æ¯ï¼Œä»¥é¢„æµ‹æ¯ä¸ªåˆ†å­çš„ç”œåº¦å€¼ï¼ˆlogSwï¼‰ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### äºŒã€æ¨¡å‹æ¶æ„\n",
        "\n",
        "æˆ‘ä»¬ä½¿ç”¨äº†ä¸€ä¸ªåŒ…å«ä¸¤å±‚GATå·ç§¯å±‚çš„ç½‘ç»œï¼Œè¯¦ç»†ç»“æ„å¦‚ä¸‹ï¼š\n",
        "\n",
        "- **ç¬¬ä¸€å±‚GATConv**ï¼šæ¥æ”¶åŸå­ç‰¹å¾è¾“å…¥ï¼Œå°†å…¶æ˜ å°„åˆ°ä¸€ä¸ªä¸­é—´çš„éšè—ç»´åº¦ï¼Œä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼ˆ`heads=2`ï¼‰ï¼Œå³æ¯ä¸ªèŠ‚ç‚¹ä¼šæœ‰ä¸¤ä¸ªæ³¨æ„åŠ›å¤´è¿›è¡Œä¿¡æ¯æ±‡èšã€‚è¯¥å±‚çš„è¾“å‡ºä¼šç»è¿‡ReLUæ¿€æ´»å‡½æ•°ï¼ˆ`F.elu`ï¼‰è¿›è¡Œéçº¿æ€§å˜æ¢ã€‚\n",
        "  \n",
        "- **ç¬¬äºŒå±‚GATConv**ï¼šè¿›ä¸€æ­¥å¯¹ç¬¬ä¸€å±‚çš„è¾“å‡ºè¿›è¡Œå¤„ç†ï¼Œä½¿ç”¨ä¸€ä¸ªæ³¨æ„åŠ›å¤´ï¼ˆ`heads=1`ï¼‰ã€‚åŒæ ·ï¼Œè¾“å‡ºä¼šç»è¿‡æ¿€æ´»å‡½æ•°è¿›è¡Œå¤„ç†ã€‚\n",
        "\n",
        "- **æ± åŒ–å±‚**ï¼šä½¿ç”¨`global_mean_pool`è¿›è¡Œå…¨å›¾æ± åŒ–ï¼Œå®ƒå°†å›¾ä¸­æ‰€æœ‰èŠ‚ç‚¹çš„ç‰¹å¾é€šè¿‡å¹³å‡å€¼æ±‡èšæˆä¸€ä¸ªå…¨å±€å›¾è¡¨ç¤ºã€‚\n",
        "\n",
        "- **å…¨è¿æ¥å±‚**ï¼šæœ€åé€šè¿‡ä¸€ä¸ªçº¿æ€§å±‚å°†å›¾è¡¨ç¤ºæ˜ å°„åˆ°é¢„æµ‹ç›®æ ‡ï¼ˆå³ç”œåº¦å€¼ï¼‰ï¼Œè¾“å‡ºæ˜¯ä¸€ä¸ªå•ä¸€çš„æ•°å€¼ã€‚\n",
        "\n",
        "æ¨¡å‹æ¶æ„å¦‚ä¸‹æ‰€ç¤ºï¼š\n",
        "```python\n",
        "class GATNet(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=16, output_dim=1, heads=2):\n",
        "        # å®šä¹‰GATå±‚ã€æ± åŒ–å±‚å’Œå…¨è¿æ¥å±‚\n",
        "        ...\n",
        "    def forward(self, x, edge_index, batch, edge_attr=None):\n",
        "        # å‰å‘ä¼ æ’­\n",
        "        ...\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### ä¸‰ã€æ•°æ®å‡†å¤‡\n",
        "\n",
        "æˆ‘ä»¬ä½¿ç”¨äº†ä¸€ä¸ªåŒ…å«åˆ†å­SMILESå­—ç¬¦ä¸²å’Œç”œåº¦å€¼ï¼ˆlogSwï¼‰çš„æ•°æ®é›†ï¼Œé€šè¿‡ä»¥ä¸‹æ­¥éª¤å‡†å¤‡æ•°æ®ï¼š\n",
        "1. **SMILESè½¬åˆ†å­å›¾**ï¼šå°†SMILESå­—ç¬¦ä¸²è½¬æ¢ä¸ºåˆ†å­å›¾ï¼ˆæ¯ä¸ªåˆ†å­å›¾åŒ…å«åŸå­èŠ‚ç‚¹å’Œé”®çš„è¿æ¥ä¿¡æ¯ï¼‰ã€‚\n",
        "2. **ç‰¹å¾æå–**ï¼šä¸ºæ¯ä¸ªåˆ†å­è®¡ç®—åŸå­ç‰¹å¾å’Œé”®ç‰¹å¾ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºå›¾ç¥ç»ç½‘ç»œèƒ½å¤Ÿå¤„ç†çš„æ ¼å¼ã€‚\n",
        "3. **æ•°æ®åˆ’åˆ†**ï¼šå°†æ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼ˆ80%ç”¨äºè®­ç»ƒï¼Œ20%ç”¨äºéªŒè¯ï¼‰ã€‚\n",
        "\n",
        "é€šè¿‡`DataLoader`åŠ è½½æ•°æ®ï¼Œä»¥æ‰¹æ¬¡å½¢å¼è¿›è¡Œè®­ç»ƒå’ŒéªŒè¯ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### å››ã€è®­ç»ƒè¿‡ç¨‹\n",
        "\n",
        "åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œç½‘ç»œä½¿ç”¨**å‡æ–¹è¯¯å·®æŸå¤±å‡½æ•°ï¼ˆMSELossï¼‰**æ¥ä¼˜åŒ–æ¨¡å‹ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ–é¢„æµ‹å€¼å’ŒçœŸå®å€¼ä¹‹é—´çš„å·®è·ã€‚ä¼˜åŒ–å™¨é€‰æ‹©äº†**Adam**ï¼Œå…¶å…·æœ‰è‡ªé€‚åº”å­¦ä¹ ç‡çš„ç‰¹æ€§ï¼Œæœ‰åŠ©äºåŠ é€Ÿæ”¶æ•›ã€‚\n",
        "\n",
        "è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¯ä¸ªbatchçš„å‰å‘ä¼ æ’­æ­¥éª¤åŒ…æ‹¬ï¼š\n",
        "1. è¾“å…¥åˆ†å­å›¾çš„åŸå­ç‰¹å¾ã€è¾¹ç´¢å¼•å’Œæ‰¹æ¬¡ä¿¡æ¯ã€‚\n",
        "2. é€šè¿‡ä¸¤å±‚GATå·ç§¯å±‚æå–ç‰¹å¾ã€‚\n",
        "3. ä½¿ç”¨æ± åŒ–å±‚å¯¹å›¾è¿›è¡Œæ±‡èšï¼Œå¾—åˆ°å…¨å›¾çš„è¡¨ç¤ºã€‚\n",
        "4. é€šè¿‡å…¨è¿æ¥å±‚è¾“å‡ºé¢„æµ‹å€¼ã€‚\n",
        "\n",
        "åœ¨è®­ç»ƒæ—¶ï¼Œæˆ‘ä»¬è®°å½•äº†æ¯è½®çš„è®­ç»ƒæŸå¤±ï¼ˆMSEï¼‰å’ŒéªŒè¯é›†çš„**å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰**ä»¥åŠ**å†³å®šç³»æ•°ï¼ˆRÂ²ï¼‰**ï¼Œä»¥è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚\n",
        "\n",
        "è®­ç»ƒä»£ç ç‰‡æ®µå¦‚ä¸‹ï¼š\n",
        "```python\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(batch.x, batch.edge_index, batch.batch)\n",
        "        loss = loss_fn(pred, batch.y.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * batch.num_graphs\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### äº”ã€éªŒè¯è¿‡ç¨‹\n",
        "\n",
        "åœ¨æ¯è½®è®­ç»ƒä¹‹åï¼Œæˆ‘ä»¬ä½¿ç”¨éªŒè¯é›†æ¥è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„è¡¨ç°é€šè¿‡**MSEæŸå¤±å’ŒRÂ²åˆ†æ•°**æ¥è¡¡é‡ï¼š\n",
        "- **MSEï¼ˆå‡æ–¹è¯¯å·®ï¼‰**ï¼šè¡¨ç¤ºé¢„æµ‹å€¼å’ŒçœŸå®å€¼ä¹‹é—´çš„å·®è·ï¼Œæ•°å€¼è¶Šå°è¡¨ç¤ºæ¨¡å‹è¶Šç²¾ç¡®ã€‚\n",
        "- **RÂ²åˆ†æ•°**ï¼šè¡¡é‡æ¨¡å‹å¯¹ç›®æ ‡å˜é‡çš„è§£é‡Šèƒ½åŠ›ï¼ŒRÂ²å€¼è¶Šæ¥è¿‘1ï¼Œè¯´æ˜æ¨¡å‹çš„æ‹Ÿåˆæ•ˆæœè¶Šå¥½ã€‚\n",
        "\n",
        "éªŒè¯è¿‡ç¨‹ä»£ç å¦‚ä¸‹ï¼š\n",
        "```python\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    preds, labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            pred = model(batch.x, batch.edge_index, batch.batch)\n",
        "            preds.append(pred.cpu())\n",
        "            labels.append(batch.y.cpu())\n",
        "    preds = torch.cat(preds)\n",
        "    labels = torch.cat(labels)\n",
        "    mse = F.mse_loss(preds, labels).item()\n",
        "    r2 = r2_score(labels.numpy(), preds.numpy())\n",
        "    return mse, r2\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### å…­ã€è®­ç»ƒä¸éªŒè¯çš„è¿­ä»£è¿‡ç¨‹\n",
        "\n",
        "åœ¨æ¯ä¸ªepochçš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬è®°å½•äº†è®­ç»ƒæŸå¤±å’ŒéªŒè¯é›†çš„æ€§èƒ½ï¼Œå…·ä½“çš„è®­ç»ƒè¿‡ç¨‹å¦‚ä¸‹ï¼š\n",
        "\n",
        "1. æ¯è½®è®­ç»ƒåï¼Œæˆ‘ä»¬è¾“å‡ºå½“å‰çš„è®­ç»ƒæŸå¤±ã€éªŒè¯é›†çš„MSEå’ŒRÂ²ã€‚\n",
        "2. å¦‚æœéªŒè¯é›†ä¸Šçš„RÂ²åˆ†æ•°æé«˜ï¼Œæˆ‘ä»¬ä¼šä¿å­˜å½“å‰æœ€å¥½çš„æ¨¡å‹ã€‚\n",
        "\n",
        "è®­ç»ƒä¸»å¾ªç¯å¦‚ä¸‹ï¼š\n",
        "```python\n",
        "for epoch in range(1, 201):\n",
        "    loss = train()\n",
        "    val_mse, val_r2 = evaluate(val_loader)\n",
        "\n",
        "    train_losses.append(loss)\n",
        "    val_losses.append(val_mse)\n",
        "\n",
        "    if val_r2 > best_val_r2:\n",
        "        best_val_r2 = val_r2\n",
        "        torch.save(model.state_dict(), \"best_gat_model.pt\")\n",
        "\n",
        "    if epoch % 1 == 0 or epoch == 1:\n",
        "        print(f\"Epoch {epoch:03d} | Loss: {loss:.4f} | Val MSE: {val_mse:.4f} | Val R2: {val_r2:.4f}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### ä¸ƒã€æœ€ç»ˆç»“æœ\n",
        "\n",
        "åœ¨è®­ç»ƒå®Œæˆåï¼Œæˆ‘ä»¬æ‰“å°å‡º**æœ€ä½³éªŒè¯é›†RÂ²**ï¼Œè¿™è¡¨ç¤ºæˆ‘ä»¬æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šè¾¾åˆ°äº†æœ€ä½³çš„æ‹Ÿåˆæ•ˆæœã€‚æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ä¸­é€šè¿‡ä¸æ–­è°ƒæ•´å‚æ•°å’Œä¼˜åŒ–è¿‡ç¨‹ï¼Œæœ€ç»ˆå¾—åˆ°äº†ä¸€ä¸ªèƒ½å¤Ÿè¾ƒå¥½é¢„æµ‹åˆ†å­ç”œåº¦å€¼çš„æ¨¡å‹ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### å…«ã€æ€»ç»“\n",
        "\n",
        "é€šè¿‡ä¸Šè¿°æ­¥éª¤ï¼Œæˆ‘ä»¬æˆåŠŸåœ°å®ç°äº†ä¸€ä¸ªåŸºäºGATçš„å›¾ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œèƒ½å¤Ÿä»åˆ†å­çš„ç»“æ„ä¿¡æ¯ä¸­å­¦ä¹ åˆ°æœ‰ç”¨çš„ç‰¹å¾ï¼Œå¹¶é¢„æµ‹åˆ†å­çš„ç”œåº¦å€¼ã€‚è®­ç»ƒè¿‡ç¨‹çš„å…³é”®åœ¨äºé€šè¿‡ä¼˜åŒ–GATæ¨¡å‹çš„å‚æ•°ï¼Œä½¿å¾—ç½‘ç»œèƒ½å¤Ÿå­¦ä¹ åˆ°åˆ†å­ç»“æ„å’Œç›®æ ‡æ€§è´¨ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶é€šè¿‡éªŒè¯é›†çš„è¯„ä¼°æ¥ç¡®ä¿æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW9c8pshSTcV"
      },
      "source": [
        "### **æ¥ç€è¯•è¯•GATï¼ˆå›¾æ³¨æ„åŠ›ï¼‰ç½‘ç»œ+MLP+è¾¹ç‰¹å¾**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvJkS5UkR3yz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "# ==========================================\n",
        "# 1. åŸºç¡€è®¾ç½®\n",
        "# ==========================================\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "seed_everything()\n",
        "\n",
        "# æƒé‡åˆå§‹åŒ–å‡½æ•°\n",
        "def init_weight(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.zeros_(m.bias)\n",
        "\n",
        "# ==========================================\n",
        "# 2. ä¿®æ”¹åçš„ MLP æ¨¡å— (æ”¯æŒä¼ å…¥ dropout)\n",
        "# ==========================================\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim=1, dropout=0.4): # é»˜è®¤æ”¹ä¸º 0.4\n",
        "        super(MLP, self).__init__()\n",
        "        # ä½¿ç”¨ nn.Sequentialï¼Œç»“æ„æ¸…æ™°\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),           # â— ä¿®æ”¹ï¼šä½¿ç”¨ä¼ å…¥çš„é«˜ dropout\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),           # â— ä¿®æ”¹ï¼šä½¿ç”¨ä¼ å…¥çš„é«˜ dropout\n",
        "            nn.Linear(hidden_dim // 2, output_dim) # å›å½’è¾“å‡ºå±‚\n",
        "        )\n",
        "\n",
        "        # åº”ç”¨æƒé‡åˆå§‹åŒ–\n",
        "        self.net.apply(init_weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# ==========================================\n",
        "# 3. GAT æ¨¡å‹ (åŒ…å«è¾¹ç‰¹å¾å¤„ç† + å¼ºæ­£åˆ™åŒ–)\n",
        "# ==========================================\n",
        "class GATNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=16, mlp_hidden=16, output_dim=1, heads=2, dropout=0.4, edge_dim=None):\n",
        "        super(GATNet, self).__init__()\n",
        "\n",
        "        # GAT å±‚ 1\n",
        "        # â— ä¿®æ”¹ï¼šdropout è®¾ä¸º 0.4\n",
        "        self.gat1 = GATConv(input_dim, hidden_dim, heads=heads, dropout=dropout, edge_dim=edge_dim)\n",
        "\n",
        "        # GAT å±‚ 2\n",
        "        self.gat2 = GATConv(hidden_dim * heads, hidden_dim, heads=1, dropout=dropout, edge_dim=edge_dim)\n",
        "\n",
        "        # æ± åŒ–å±‚\n",
        "        self.pool = global_mean_pool\n",
        "\n",
        "        # MLP é¢„æµ‹å¤´\n",
        "        # â— ä¿®æ”¹ï¼šå°† dropout ä¼ é€’ç»™ MLP\n",
        "        self.mlp = MLP(input_dim=hidden_dim, hidden_dim=mlp_hidden, output_dim=output_dim, dropout=dropout)\n",
        "\n",
        "    def forward(self, x, edge_index, batch, edge_attr=None):\n",
        "        # 1. GAT æå–ç‰¹å¾\n",
        "        x = self.gat1(x, edge_index, edge_attr=edge_attr)\n",
        "        x = F.elu(x)\n",
        "\n",
        "        x = self.gat2(x, edge_index, edge_attr=edge_attr)\n",
        "        x = F.elu(x)\n",
        "\n",
        "        # 2. å…¨å±€æ± åŒ– (è·å¾—å›¾çº§åˆ«çš„è¡¨ç¤º)\n",
        "        x = self.pool(x, batch)\n",
        "\n",
        "        # 3. MLP å›å½’é¢„æµ‹\n",
        "        out = self.mlp(x)\n",
        "        return out.squeeze() # ç§»é™¤å¤šä½™ç»´åº¦\n",
        "\n",
        "    def extract_graph_embeddings(self, x, edge_index, batch, edge_attr=None):\n",
        "        \"\"\"ç”¨äº t-SNE å¯è§†åŒ–çš„ç‰¹å¾æå–å‡½æ•°\"\"\"\n",
        "        x = self.gat1(x, edge_index, edge_attr=edge_attr)\n",
        "        x = F.elu(x)\n",
        "        x = self.gat2(x, edge_index, edge_attr=edge_attr)\n",
        "        x = F.elu(x)\n",
        "        pooled = self.pool(x, batch)\n",
        "        return pooled\n",
        "\n",
        "# ==========================================\n",
        "# 4. æ•°æ®åŠ è½½ä¸è®­ç»ƒæµç¨‹\n",
        "# ==========================================\n",
        "\n",
        "# æ£€æŸ¥ dataset æ˜¯å¦å­˜åœ¨\n",
        "if 'dataset' not in locals():\n",
        "    dataset = MolDataset(csv_path='/content/SweetpredDB.csv')\n",
        "\n",
        "# åˆ’åˆ†æ•°æ®é›†\n",
        "train_ratio = 0.8\n",
        "train_size = int(train_ratio * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "# è®¾å¤‡è®¾ç½®\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# è·å–ç»´åº¦ä¿¡æ¯\n",
        "input_dim = dataset[0].x.shape[1]\n",
        "if len(dataset) > 0 and dataset[0].edge_attr is not None:\n",
        "    edge_dim = dataset[0].edge_attr.shape[1]\n",
        "    print(f\"âœ… æ£€æµ‹åˆ°è¾¹ç‰¹å¾ç»´åº¦: {edge_dim}\")\n",
        "else:\n",
        "    edge_dim = None\n",
        "    print(\"âŒ æœªæ£€æµ‹åˆ°è¾¹ç‰¹å¾\")\n",
        "\n",
        "# åˆå§‹åŒ–æ¨¡å‹\n",
        "# â— ç­–ç•¥è°ƒæ•´ï¼š\n",
        "# 1. Dropout æé«˜åˆ° 0.4 (Strong Regularization)\n",
        "# 2. hidden_dim ä¿æŒè¾ƒå° (16)ï¼Œé¿å…å‚æ•°è¿‡å¤š\n",
        "model = GATNet(\n",
        "    input_dim=input_dim,\n",
        "    hidden_dim=16,\n",
        "    mlp_hidden=128,\n",
        "    edge_dim=edge_dim,\n",
        "    dropout=0.4          # <--- å…³é”®ä¿®æ”¹ï¼šé«˜ Dropout\n",
        ").to(device)\n",
        "\n",
        "# â— ç­–ç•¥è°ƒæ•´ï¼šå¢å¤§ Weight Decay\n",
        "# ä» 1e-4 å¢åŠ åˆ° 1e-3ï¼Œæƒ©ç½šè¿‡å¤§çš„æƒé‡ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=2e-3)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# è®­ç»ƒå‡½æ•°\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(batch.x, batch.edge_index, batch.batch, edge_attr=batch.edge_attr)\n",
        "        loss = loss_fn(pred, batch.y.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * batch.num_graphs\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "# éªŒè¯å‡½æ•°\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    preds, labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            pred = model(batch.x, batch.edge_index, batch.batch, edge_attr=batch.edge_attr)\n",
        "            preds.append(pred.cpu())\n",
        "            labels.append(batch.y.cpu())\n",
        "    preds = torch.cat(preds)\n",
        "    labels = torch.cat(labels)\n",
        "    mse = F.mse_loss(preds, labels).item()\n",
        "    r2 = r2_score(labels.numpy(), preds.numpy())\n",
        "    return mse, r2\n",
        "\n",
        "# æå–ç‰¹å¾å‡½æ•°\n",
        "def extract_global_features(loader):\n",
        "    model.eval()\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            pooled = model.extract_graph_embeddings(batch.x, batch.edge_index, batch.batch, edge_attr=batch.edge_attr)\n",
        "            all_features.append(pooled.cpu())\n",
        "            all_labels.append(batch.y.cpu())\n",
        "    all_features = torch.cat(all_features).numpy()\n",
        "    all_labels = torch.cat(all_labels).numpy()\n",
        "    return all_features, all_labels\n",
        "\n",
        "# ä¿å­˜ç›®å½•\n",
        "save_dir = \"mol_global_features\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# è®­ç»ƒå¾ªç¯\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_val_r2 = -float(\"inf\")\n",
        "best_epoch = 0\n",
        "\n",
        "print(\"ğŸš€ å¼€å§‹è®­ç»ƒ GAT (Edge Features + Strong Regularization) ...\")\n",
        "print(\"é…ç½®: Dropout=0.4, Weight_Decay=1e-3\")\n",
        "\n",
        "for epoch in range(1, 201):\n",
        "    train_loss = train()\n",
        "    val_mse, val_r2 = evaluate(val_loader)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_mse)\n",
        "\n",
        "    if val_r2 > best_val_r2:\n",
        "        best_val_r2 = val_r2\n",
        "        best_epoch = epoch\n",
        "        torch.save(model.state_dict(), \"Best_GATEdge+MLP_Model.pt\")\n",
        "\n",
        "    # ä¿å­˜ç‰¹å¾\n",
        "    global_feats, labels = extract_global_features(train_loader)\n",
        "    np.save(os.path.join(save_dir, f\"features_epoch_{epoch:03d}.npy\"), global_feats)\n",
        "    np.save(os.path.join(save_dir, f\"labels_epoch_{epoch:03d}.npy\"), labels)\n",
        "\n",
        "    if epoch % 10 == 0 or epoch == 1:\n",
        "        print(f\"Epoch {epoch:03d} | Train Loss: {train_loss:.4f} | Val MSE: {val_mse:.4f} | Val R2: {val_r2:.4f}\")\n",
        "\n",
        "print(f\"\\nâœ… è®­ç»ƒå®Œæˆã€‚æœ€ä½³éªŒè¯é›† RÂ²: {best_val_r2:.4f} (åœ¨ç¬¬ {best_epoch} è½®)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2M3YDVfWcv3N"
      },
      "outputs": [],
      "source": [
        "# ğŸ“ˆ ç»˜åˆ¶å­¦ä¹ æ›²çº¿\n",
        "plt.figure(figsize=(5, 5),dpi=200)\n",
        "\n",
        "# æŒ‡å®š RGB é¢œè‰²ï¼ˆ0~1 å½’ä¸€åŒ–ï¼‰\n",
        "train_color = (75 / 255, 116 / 255, 178 / 255)   # è“è‰²\n",
        "val_color = (219 / 255, 49 / 255, 36 / 255)      # çº¢è‰²\n",
        "\n",
        "plt.plot(train_losses, label='Train Loss', color=train_color)\n",
        "plt.plot(val_losses, label='Validation Loss', color=val_color)\n",
        "\n",
        "# æ ‡è®°æœ€ä½³æ¨¡å‹çš„è¿­ä»£æ¬¡æ•°\n",
        "plt.axvline(x=best_epoch-1, color='black', linestyle='--', label=f'Best Model at Epoch {best_epoch}')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.title('GATEdge + MLP')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "# plt.savefig(\"loss_curve.png\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEQimYm_cxF3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. åŠ è½½æœ€ä½³æ¨¡å‹æƒé‡\n",
        "# ç¡®ä¿æ–‡ä»¶è·¯å¾„æ­£ç¡®\n",
        "best_model_path = \"Best_GATEdge+MLP_Model.pt\"\n",
        "if os.path.exists(best_model_path):\n",
        "    model.load_state_dict(torch.load(best_model_path))\n",
        "    print(\"âœ… æˆåŠŸåŠ è½½æœ€ä½³æ¨¡å‹æƒé‡\")\n",
        "else:\n",
        "    print(\"âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„\")\n",
        "\n",
        "model.eval()\n",
        "preds, labels = [], []\n",
        "\n",
        "# 2. æ¨ç† (æ³¨æ„åŠ ä¸Š edge_attr)\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        # â—â—â— å…³é”®ä¿®æ­£ï¼šå¿…é¡»ä¼ å…¥ edge_attr â—â—â—\n",
        "        pred = model(batch.x, batch.edge_index, batch.batch, edge_attr=batch.edge_attr)\n",
        "\n",
        "        preds.append(pred.cpu())\n",
        "        labels.append(batch.y.cpu())\n",
        "\n",
        "preds = torch.cat(preds)\n",
        "labels = torch.cat(labels)\n",
        "\n",
        "# 3. ç»˜å›¾\n",
        "plt.figure(figsize=(4, 4), dpi=300)\n",
        "\n",
        "# ç»˜åˆ¶æ•£ç‚¹å›¾ (è“è‰²)\n",
        "plt.scatter(labels, preds, alpha=0.6, s=20,\n",
        "            color=(75 / 255, 116 / 255, 178 / 255), label='Predictions')\n",
        "\n",
        "# ç»˜åˆ¶å¯¹è§’çº¿ (çº¢è‰²)\n",
        "min_val = min(labels.min(), preds.min())\n",
        "max_val = max(labels.max(), preds.max())\n",
        "plt.plot([min_val, max_val], [min_val, max_val], '--', lw=2,\n",
        "         color=(219 / 255, 49 / 255, 36 / 255), label='Perfect Prediction')\n",
        "\n",
        "# è®¡ç®— R2 å’Œ MSE\n",
        "mse = F.mse_loss(preds, labels).item()\n",
        "r2 = r2_score(labels.numpy(), preds.numpy())\n",
        "\n",
        "# è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾\n",
        "plt.xlabel('True Sweetness (logSw)')\n",
        "plt.ylabel('Predicted Sweetness')\n",
        "plt.title(f'True vs Predicted Values (Best Model)\\nWith Edge Features\\nMSE: {mse:.4f} | RÂ²: {r2:.4f}')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi8AFdXj3wpB"
      },
      "source": [
        "### **GATæ¨¡å‹ä¸­åŠ å…¥MLPæ¨¡å—ä¸è¾¹ç‰¹å¾çš„ä½œç”¨**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxCIbAvX3vd4"
      },
      "source": [
        "\n",
        "\n",
        "åœ¨å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰çš„è®¾è®¡ä¸­ï¼Œå¦‚ä½•æœ‰æ•ˆåœ°æ•æ‰å›¾ä¸­èŠ‚ç‚¹ä¹‹é—´çš„å¤æ‚å…³ç³»ï¼Œä»¥åŠå¦‚ä½•åœ¨æ¨¡å‹ä¸­èå…¥æ›´å¤šçš„ç»“æ„ä¿¡æ¯ï¼ˆå¦‚è¾¹çš„ç‰¹å¾ï¼‰ï¼Œæ˜¯éå¸¸å…³é”®çš„ã€‚ä¸ºäº†æé«˜æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ï¼Œæˆ‘ä»¬å¯¹**GATç½‘ç»œ**è¿›è¡Œäº†æ‰©å±•ï¼ŒåŠ å…¥äº†**MLPæ¨¡å—**å’Œ**è¾¹ç‰¹å¾ï¼ˆedge attrï¼‰**ã€‚åœ¨æœ¬é¡¹ç›®ä¸­ï¼Œè¿™äº›æ”¹è¿›æœ‰åŠ©äºæå‡æ¨¡å‹çš„è¡¨ç°ã€‚ä¸‹é¢å°†é‡ç‚¹è§£é‡Š**ä¸ºä»€ä¹ˆåŠ MLPæ¨¡å—ï¼Œè¾¹ç‰¹å¾å¦‚ä½•å¸®åŠ©æå‡æ¨¡å‹ï¼Œä»¥åŠGATä¸­ä¿¡æ¯ä¼ é€’çš„è¿‡ç¨‹å’Œå¯å­¦ä¹ çš„å‚æ•°**ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### ä¸€ã€ä¸ºä½•åŠ MLPæ¨¡å—ï¼Ÿ\n",
        "\n",
        "**MLPï¼ˆå¤šå±‚æ„ŸçŸ¥æœºï¼‰**æ˜¯æ·±åº¦å­¦ä¹ ä¸­ä¸€ç§å¸¸ç”¨çš„å…¨è¿æ¥å±‚ç½‘ç»œï¼Œå®ƒé€šè¿‡å°†å›¾ç¥ç»ç½‘ç»œçš„è¾“å‡ºè¿›è¡Œè¿›ä¸€æ­¥çš„éçº¿æ€§å˜æ¢ï¼Œä»è€ŒåŠ å¼ºæ¨¡å‹çš„æ‹Ÿåˆèƒ½åŠ›ã€‚åœ¨æœ¬æ¨¡å‹ä¸­ï¼ŒGATè¾“å‡ºçš„æ˜¯ç»è¿‡æ± åŒ–ï¼ˆ`global_mean_pool`ï¼‰åå¾—åˆ°çš„åˆ†å­çº§åˆ«çš„å›¾è¡¨ç¤ºï¼ˆä¸€ä¸ªå…¨å±€çš„å‘é‡ï¼‰ã€‚è¿™äº›è¡¨ç¤ºæœ¬èº«ä»ç„¶æ˜¯**ä½ç»´çš„ã€ç®€å•çš„**ï¼Œè¿˜éœ€è¦é€šè¿‡MLPè¿›ä¸€æ­¥**å­¦ä¹ å’Œè½¬åŒ–**ï¼Œä»¥ä¾¿è¾“å‡ºæ›´ç²¾ç¡®çš„é¢„æµ‹ç»“æœï¼ˆå¦‚ç”œåº¦ï¼‰ã€‚\n",
        "\n",
        "åŠ å…¥MLPçš„å¥½å¤„æ˜¯ï¼š\n",
        "- **éçº¿æ€§æ˜ å°„**ï¼šGATè™½ç„¶é€šè¿‡å›¾å·ç§¯æ“ä½œèƒ½å¤Ÿå­¦ä¹ åˆ°å›¾çš„ç»“æ„ä¿¡æ¯ï¼Œä½†å¦‚æœæ²¡æœ‰MLPå±‚ï¼Œå®ƒçš„è¾“å‡ºå¯èƒ½åªæ˜¯ç®€å•çš„çº¿æ€§å˜æ¢ã€‚MLPé€šè¿‡æ›´å¤šçš„éçº¿æ€§å±‚å¸®åŠ©æ¨¡å‹å­¦ä¹ æ›´å¤æ‚çš„ç‰¹å¾ã€‚\n",
        "- **æå‡è¡¨è¾¾èƒ½åŠ›**ï¼šMLPé€šè¿‡å¤šå±‚ç½‘ç»œç»“æ„èƒ½å¤Ÿæ•æ‰æ›´å¤šçš„å¤æ‚ç‰¹å¾ï¼Œå°¤å…¶æ˜¯åœ¨å¤šä»»åŠ¡å­¦ä¹ ã€å›å½’ä»»åŠ¡ç­‰åœºæ™¯ä¸‹ï¼ŒMLPèƒ½å¤Ÿåœ¨å±€éƒ¨å›¾è¡¨ç¤ºçš„åŸºç¡€ä¸Šè¿›è¡Œè¿›ä¸€æ­¥çš„ç‰¹å¾æç‚¼ã€‚\n",
        "\n",
        "**ä¸ºä»€ä¹ˆMLPåœ¨GATä¹‹ååŠ **ï¼š\n",
        "- GATèƒ½å¤Ÿæå–æ¯ä¸ªèŠ‚ç‚¹çš„ä¿¡æ¯å¹¶åœ¨å›¾ä¸­è¿›è¡Œä¼ æ’­ï¼Œä½†å¾—åˆ°çš„è¡¨ç¤ºæ˜¯èŠ‚ç‚¹çº§çš„ï¼Œå¯¹äºåˆ†å­æ¥è¯´ï¼Œæ¨¡å‹éœ€è¦å¯¹æ‰€æœ‰èŠ‚ç‚¹è¿›è¡Œæ±‡èšå¹¶è¾“å‡ºä¸€ä¸ªæ•´ä½“çš„åˆ†å­çº§åˆ«çš„è¡¨ç¤ºï¼ŒMLPèƒ½å¤Ÿåœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œæ›´åŠ ç²¾ç»†çš„ç‰¹å¾å­¦ä¹ ï¼Œæœ€ç»ˆå¾—åˆ°ä¸€ä¸ªæ›´å¥½çš„é¢„æµ‹ç»“æœã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### äºŒã€ä¸ºä½•ä½¿ç”¨è¾¹ç‰¹å¾ï¼ˆedge_attrï¼‰ï¼Ÿ\n",
        "\n",
        "åœ¨åŸå§‹çš„GATæ¨¡å‹ä¸­ï¼Œæ¨¡å‹é€šè¿‡èŠ‚ç‚¹é—´çš„é‚»æ¥çŸ©é˜µæ¥è¿›è¡Œä¿¡æ¯ä¼ é€’ã€‚ä½†æ˜¯ï¼Œ**è¾¹ç‰¹å¾ï¼ˆedge_attrï¼‰**æä¾›äº†æ›´å¤šçš„æœ‰ç”¨ä¿¡æ¯ï¼Œå¦‚**é”®çš„ç±»å‹**ï¼ˆå•é”®ã€åŒé”®ã€èŠ³é¦™é”®ç­‰ï¼‰ã€**æ˜¯å¦å…±è½­**ç­‰ï¼Œè¿™äº›å¯¹äºæè¿°åˆ†å­çš„ç»“æ„å’ŒåŒ–å­¦æ€§è´¨è‡³å…³é‡è¦ã€‚ä¾‹å¦‚ï¼ŒèŠ³é¦™é”®åœ¨åˆ†å­çš„ç¨³å®šæ€§ã€ååº”æ€§ç­‰æ–¹é¢æœ‰ç€ç‹¬ç‰¹çš„å½±å“ï¼Œä»…ä¾é åŸå­èŠ‚ç‚¹çš„ä¿¡æ¯å¯èƒ½æ— æ³•å®Œå…¨æ•æ‰åˆ°è¿™ä¸€ç‚¹ã€‚\n",
        "\n",
        "ä½¿ç”¨è¾¹ç‰¹å¾çš„å¥½å¤„ï¼š\n",
        "- **å¢å¼ºä¿¡æ¯ä¼ é€’çš„çµæ´»æ€§**ï¼šè¾¹ç‰¹å¾å¯ä»¥å‘Šè¯‰GATç½‘ç»œ**ä¸åŒç±»å‹çš„é”®**å¯¹èŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»æœ‰ä½•ç§å½±å“ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ä¸åŒè¾¹ç±»å‹å¯¹åˆ†å­æ€§è´¨çš„å½±å“ï¼Œä»è€Œä¼˜åŒ–ä¿¡æ¯ä¼ é€’çš„æƒé‡ã€‚\n",
        "- **æé«˜æ¨¡å‹è¡¨ç°**ï¼šè¾¹ç‰¹å¾ä¸ä»…èƒ½è®©æ¨¡å‹æ›´å¥½åœ°å­¦ä¹ å›¾çš„ç»“æ„ï¼Œè¿˜èƒ½å¸®åŠ©æ¨¡å‹æ•æ‰åˆ°åˆ†å­ä¸­ç‰¹å®šçš„åŒ–å­¦æ€§è´¨ï¼Œè¿›è€Œæé«˜é¢„æµ‹ç²¾åº¦ã€‚\n",
        "\n",
        "åœ¨æœ¬æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡`edge_attr`å°†è¿™äº›ä¿¡æ¯ä¼ é€’ç»™GATå·ç§¯å±‚ï¼Œå¹¶åœ¨æ¯æ¬¡å›¾å·ç§¯æ“ä½œæ—¶ï¼Œè®©æ¨¡å‹è€ƒè™‘è¾¹çš„ç‰¹å¾ã€‚è¿™ç§æ”¹è¿›å¤§å¤§æé«˜äº†æ¨¡å‹å¯¹äºå¤æ‚åŒ–å­¦ç»“æ„çš„ç†è§£èƒ½åŠ›ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### ä¸‰ã€GATæ¨¡å‹ä¸­çš„ä¿¡æ¯ä¼ é€’ä¸å¯å­¦ä¹ å‚æ•°\n",
        "\n",
        "GATæ¨¡å‹é€šè¿‡**æ³¨æ„åŠ›æœºåˆ¶**æ¥è¿›è¡Œä¿¡æ¯ä¼ é€’ï¼Œæ¯ä¸ªèŠ‚ç‚¹åœ¨ä¸é‚»å±…èŠ‚ç‚¹äº¤æ¢ä¿¡æ¯æ—¶ï¼Œå¹¶ä¸æ˜¯å‡åŒ€åœ°è¿›è¡Œï¼Œè€Œæ˜¯æ ¹æ®æ¯ä¸ªé‚»å±…èŠ‚ç‚¹çš„é‡è¦æ€§æ¥åŠ¨æ€åœ°åˆ†é…æƒé‡ã€‚å…·ä½“è¿‡ç¨‹å¦‚ä¸‹ï¼š\n",
        "\n",
        "1. **èŠ‚ç‚¹è¡¨ç¤ºè®¡ç®—**ï¼šåœ¨GATä¸­ï¼Œæ¯ä¸ªèŠ‚ç‚¹çš„è¡¨ç¤ºæ˜¯é€šè¿‡å…¶é‚»å±…èŠ‚ç‚¹çš„è¡¨ç¤ºåŠ æƒæ±‚å’Œå¾—åˆ°çš„ã€‚å…·ä½“æ¥è¯´ï¼Œæ¯ä¸ªèŠ‚ç‚¹ä¼šå¯¹å®ƒçš„é‚»å±…èŠ‚ç‚¹ä½¿ç”¨**æ³¨æ„åŠ›æƒé‡**è¿›è¡ŒåŠ æƒï¼Œå¹¶å°†è¿™äº›åŠ æƒåçš„ä¿¡æ¯èšåˆæˆè¯¥èŠ‚ç‚¹çš„æ–°è¡¨ç¤ºã€‚è¿™äº›æƒé‡æ˜¯ç”±**æ³¨æ„åŠ›æœºåˆ¶**å­¦ä¹ å¾—å‡ºçš„ï¼Œè€Œä¸æ˜¯å›ºå®šçš„ã€‚\n",
        "\n",
        "2. **æ³¨æ„åŠ›æœºåˆ¶**ï¼šGATçš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºå®ƒçš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ƒèƒ½å¤Ÿé€šè¿‡**è‡ªé€‚åº”çš„æ–¹å¼**å¯¹é‚»å±…èŠ‚ç‚¹è¿›è¡ŒåŠ æƒã€‚æ¯ä¸ªèŠ‚ç‚¹çš„æ³¨æ„åŠ›ç³»æ•°ï¼ˆå³æƒé‡ï¼‰æ˜¯**å¯å­¦ä¹ çš„**ï¼Œè¿™äº›ç³»æ•°ä¼šéšç€è®­ç»ƒé€æ­¥è°ƒæ•´ï¼Œä»¥ä¾¿è®©æ¨¡å‹èƒ½å¤Ÿèšç„¦äºå¯¹æœ€ç»ˆä»»åŠ¡ï¼ˆå¦‚ç”œåº¦é¢„æµ‹ï¼‰æœ‰æ›´å¤§å½±å“çš„é‚»å±…èŠ‚ç‚¹ã€‚\n",
        "\n",
        "3. **æ¯å±‚çš„å¯å­¦ä¹ å‚æ•°**ï¼šåœ¨æ¯ä¸€å±‚GATä¸­ï¼Œ**æƒé‡çŸ©é˜µ**ï¼ˆå³GATçš„å‚æ•°ï¼‰å’Œ**æ³¨æ„åŠ›ç³»æ•°**ï¼ˆç”¨äºåŠ æƒé‚»å±…èŠ‚ç‚¹çš„ä¿¡æ¯ï¼‰æ˜¯å¯å­¦ä¹ çš„ã€‚è¿™æ„å‘³ç€ï¼ŒGATä¸­çš„ä¿¡æ¯ä¼ é€’è¿‡ç¨‹å¹¶ä¸æ˜¯å›ºå®šçš„ï¼Œè€Œæ˜¯**åŠ¨æ€è°ƒæ•´çš„**ï¼Œç½‘ç»œå¯ä»¥é€šè¿‡åå‘ä¼ æ’­æ¥ä¼˜åŒ–è¿™äº›å‚æ•°ï¼Œæœ€ç»ˆè®©æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°å­¦ä¹ åˆ°èŠ‚ç‚¹å’Œå›¾ç»“æ„ä¹‹é—´çš„å…³ç³»ã€‚\n",
        "\n",
        "4. **æ¯ä¸€å±‚çš„GATæ˜¯å¦æœ‰MLP**ï¼šGATå±‚æœ¬èº«å¹¶ä¸åŒ…æ‹¬MLPï¼Œä½†å®ƒé€šè¿‡æ³¨æ„åŠ›æœºåˆ¶å®ç°äº†ä¿¡æ¯ä¼ é€’ã€‚å®ƒçš„æœ¬è´¨æ˜¯åŸºäºèŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»æ¥è¿›è¡Œä¿¡æ¯èšåˆï¼Œè€Œä¸æ˜¯ç®€å•çš„çº¿æ€§ç»„åˆã€‚å› æ­¤ï¼Œåœ¨GATå±‚ä¹‹ååŠ å…¥MLPæ˜¯ä¸€ç§å¢å¼ºè¡¨è¾¾èƒ½åŠ›çš„æ–¹å¼ï¼Œä½¿å¾—ç½‘ç»œèƒ½å¤Ÿåœ¨å›¾å·ç§¯åè¿›ä¸€æ­¥æ•æ‰éçº¿æ€§å…³ç³»ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### å››ã€æ€»ç»“\n",
        "\n",
        "- **åŠ å…¥MLPæ¨¡å—**æ˜¯ä¸ºäº†é€šè¿‡å¤šå±‚æ„ŸçŸ¥æœºå¢å¼ºæ¨¡å‹çš„éçº¿æ€§è¡¨è¾¾èƒ½åŠ›ï¼Œè¿›ä¸€æ­¥ç²¾ç»†åŒ–åˆ†å­è¡¨ç¤ºçš„å­¦ä¹ ã€‚\n",
        "- **è¾¹ç‰¹å¾ï¼ˆedge_attrï¼‰**çš„å¼•å…¥ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨å›¾å·ç§¯æ—¶è€ƒè™‘ä¸åŒç±»å‹çš„åŒ–å­¦é”®ï¼Œä»è€Œæ›´å¥½åœ°æ•æ‰åˆ†å­çš„åŒ–å­¦ç»“æ„ä¿¡æ¯ï¼Œæé«˜äº†æ¨¡å‹çš„è¡¨ç°ã€‚\n",
        "- **GATä¸­çš„ä¿¡æ¯ä¼ é€’**é€šè¿‡å¯å­¦ä¹ çš„æ³¨æ„åŠ›æœºåˆ¶åŠ¨æ€è°ƒæ•´é‚»å±…èŠ‚ç‚¹ä¹‹é—´çš„åŠ æƒï¼Œç¡®ä¿ä¿¡æ¯ä¼ é€’è¿‡ç¨‹æ›´åŠ çµæ´»ï¼Œå¹¶é€šè¿‡åå‘ä¼ æ’­ä¼˜åŒ–æ³¨æ„åŠ›æƒé‡å’Œæƒé‡çŸ©é˜µï¼Œæå‡äº†æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›å’Œé¢„æµ‹ç²¾åº¦ã€‚\n",
        "\n",
        "æœ€ç»ˆï¼ŒGATä¸MLPç»“åˆï¼Œä»¥åŠä½¿ç”¨è¾¹ç‰¹å¾ï¼Œæœ‰æ•ˆåœ°æå‡äº†æ¨¡å‹çš„é¢„æµ‹æ€§èƒ½ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†åˆ†å­å›¾ç»“æ„ï¼Œå¹¶é¢„æµ‹åˆ†å­çš„ç”œåº¦ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN3qYfF3aEOT"
      },
      "source": [
        "### **é™ç»´å¯è§†åŒ–ä¸åŒè¿­ä»£åˆ†å­å…¨å±€ç‰¹å¾çš„å˜åŒ–**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wH644LBbiS4"
      },
      "source": [
        "#### t-sneé™ç»´å¯è§†åŒ–"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsHgJ7gIUdsA"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "epoch = 170  # æƒ³çœ‹å“ªä¸€è½®å°±æ”¹å“ªä¸ªç¼–å·\n",
        "features = np.load(f\"mol_global_features/features_epoch_{epoch:03d}.npy\")\n",
        "labels = np.load(f\"mol_global_features/labels_epoch_{epoch:03d}.npy\")\n",
        "\n",
        "# æ‰§è¡Œ t-SNE é™ç»´\n",
        "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
        "embeds_2d = tsne.fit_transform(features)\n",
        "\n",
        "# è‡ªå®šä¹‰ RGB é¢œè‰²ï¼ˆå½’ä¸€åŒ–ä¸º0~1ï¼‰\n",
        "high_color = (219 / 255, 49 / 255, 36 / 255)   # é«˜ç”œ â†’ çº¢è‰²\n",
        "low_color = (75 / 255, 116 / 255, 178 / 255)   # ä½ç”œ â†’ è“è‰²\n",
        "\n",
        "# ç»˜å›¾\n",
        "plt.figure(figsize=(5, 5),dpi=200)\n",
        "plt.scatter(embeds_2d[labels > 3, 0], embeds_2d[labels > 3, 1], c=[high_color], label='High Sweetness (>3)', alpha=0.7)\n",
        "plt.scatter(embeds_2d[labels <= 3, 0], embeds_2d[labels <= 3, 1], c=[low_color], label='Low Sweetness (â‰¤3)', alpha=0.7)\n",
        "\n",
        "plt.legend()\n",
        "plt.title(f\"t-SNE of Molecule Representations (Epoch {epoch})\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3gqDBXybk2m"
      },
      "source": [
        "#### t-sneé™ç»´å¯è§†åŒ–â†’gif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgG8834vVJoN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# è®¾ç½®è·¯å¾„å’Œå‚æ•°\n",
        "feature_dir = \"mol_global_features\"\n",
        "output_dir = \"tsne_images\"\n",
        "gif_path = \"tsne_evolution.gif\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# è‡ªå®šä¹‰ RGB é¢œè‰²ï¼ˆå½’ä¸€åŒ–ï¼‰\n",
        "high_color = (219 / 255, 49 / 255, 36 / 255)   # çº¢è‰²\n",
        "low_color = (75 / 255, 116 / 255, 178 / 255)   # è“è‰²\n",
        "\n",
        "# è·å–æ‰€æœ‰ epoch æ–‡ä»¶ï¼Œå¹¶æ¯éš” 5 è½®é‡‡æ ·ä¸€æ¬¡\n",
        "all_epochs = sorted([int(f.split(\"_\")[-1].split(\".\")[0]) for f in os.listdir(feature_dir) if f.startswith(\"features\")])\n",
        "epochs = [e for e in all_epochs if e % 5 == 0 or e == all_epochs[-1]]  # æ¯5è½®ä¸€ä¸ªå›¾ï¼Œä¿ç•™æœ€åä¸€è½®\n",
        "\n",
        "print(f\"å°†å¤„ç† {len(epochs)} ä¸ª epoch çš„ t-SNE å¯è§†åŒ–å›¾åƒ...\")\n",
        "\n",
        "# t-SNE å›¾ç”Ÿæˆï¼ˆæ·»åŠ  tqdm è¿›åº¦æ¡ï¼‰\n",
        "for epoch in tqdm(epochs, desc=\"Running t-SNE and saving images\"):\n",
        "    features = np.load(f\"{feature_dir}/features_epoch_{epoch:03d}.npy\")\n",
        "    labels = np.load(f\"{feature_dir}/labels_epoch_{epoch:03d}.npy\")\n",
        "\n",
        "    tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
        "    embeds_2d = tsne.fit_transform(features)\n",
        "\n",
        "    # å¯è§†åŒ–\n",
        "    plt.figure(figsize=(5, 5),dpi=200)\n",
        "    plt.scatter(\n",
        "        embeds_2d[labels > 3, 0], embeds_2d[labels > 3, 1],\n",
        "        c=[high_color], label='High Sweetness (>3)', alpha=0.7\n",
        "    )\n",
        "    plt.scatter(\n",
        "        embeds_2d[labels <= 3, 0], embeds_2d[labels <= 3, 1],\n",
        "        c=[low_color], label='Low Sweetness (â‰¤3)', alpha=0.7\n",
        "    )\n",
        "    plt.legend()\n",
        "    plt.title(f\"t-SNE of Molecule Representations\\nEpoch {epoch}\")\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(output_dir, f\"tsne_epoch_{epoch:03d}.png\")\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "print(\"âœ… æ‰€æœ‰ t-SNE å›¾åƒå·²ç”Ÿæˆ\")\n",
        "\n",
        "# ç”ŸæˆGIF\n",
        "print(\"ğŸ“½ï¸ æ­£åœ¨ç”ŸæˆåŠ¨å›¾...\")\n",
        "image_files = [os.path.join(output_dir, f\"tsne_epoch_{epoch:03d}.png\") for epoch in epochs]\n",
        "images = []\n",
        "for f in tqdm(image_files, desc=\"Loading images for GIF\"):\n",
        "    images.append(Image.open(f))\n",
        "\n",
        "images[0].save(gif_path, save_all=True, append_images=images[1:], duration=500, loop=0)\n",
        "\n",
        "print(f\"âœ… åŠ¨å›¾å·²ä¿å­˜ä¸ºï¼š{gif_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwgLq4nP4RwN"
      },
      "source": [
        "### **t-SNEå¯è§†åŒ–ä¸åˆ†å­è¡¨ç¤ºå­¦ä¹ çš„åŸç†**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsE470Qe4Qrx"
      },
      "source": [
        "\n",
        "\n",
        "åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œå°¤å…¶æ˜¯å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰ç­‰æ¨¡å‹ç”¨äºåˆ†å­è¡¨ç¤ºå­¦ä¹ æ—¶ï¼Œæ¨¡å‹çš„ç›®æ ‡æ˜¯å°†é«˜ç»´çš„åˆ†å­ç‰¹å¾æ˜ å°„åˆ°ä¸€ä¸ªä½ç»´ç©ºé—´ä¸­ï¼Œä»¥ä¾¿èƒ½å¤Ÿæ›´å¥½åœ°è¿›è¡Œé¢„æµ‹æˆ–åˆ†ç±»ä»»åŠ¡ã€‚t-SNEï¼ˆt-åˆ†å¸ƒéšæœºé‚»åŸŸåµŒå…¥ï¼‰æ˜¯ä¸€ç§å¸¸ç”¨çš„é™ç»´æŠ€æœ¯ï¼Œç”¨äºå°†é«˜ç»´æ•°æ®æ˜ å°„åˆ°2ç»´æˆ–3ç»´ç©ºé—´ï¼Œå¹¶ä¸”èƒ½å¤Ÿä¿ç•™æ•°æ®ç‚¹ä¹‹é—´çš„ç›¸å¯¹è·ç¦»å’Œå±€éƒ¨ç»“æ„ã€‚åœ¨æœ¬é¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨t-SNEå¯¹æ¯ä¸ªepochè®­ç»ƒè¿‡ç¨‹ä¸­æå–çš„åˆ†å­ç‰¹å¾è¿›è¡Œå¯è§†åŒ–ï¼Œä»è€Œè§‚å¯Ÿæ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­åˆ†å­è¡¨ç¤ºçš„å˜åŒ–ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### ä¸€ã€t-SNEå¯è§†åŒ–\n",
        "\n",
        "t-SNEé€šè¿‡ä»¥ä¸‹æ–¹å¼å¸®åŠ©æˆ‘ä»¬ç†è§£æ¨¡å‹è®­ç»ƒçš„è¿‡ç¨‹ï¼š\n",
        "1. **é™ç»´**ï¼št-SNEå°†é«˜ç»´çš„åˆ†å­è¡¨ç¤ºé™ç»´ä¸ºäºŒç»´ï¼ˆ2Dï¼‰ç©ºé—´ï¼Œä½¿æˆ‘ä»¬å¯ä»¥åœ¨å¹³é¢ä¸Šç›´è§‚åœ°è§‚å¯Ÿåˆ†å­é—´çš„å…³ç³»ã€‚é™ç»´åï¼Œæ•°æ®ç‚¹çš„ä½ç½®ä¿ç•™äº†å®ƒä»¬åœ¨é«˜ç»´ç©ºé—´ä¸­çš„ç›¸å¯¹å…³ç³»ã€‚\n",
        "2. **èšç±»**ï¼št-SNEå¯ä»¥é€šè¿‡å¯è§†åŒ–æ˜¾ç¤ºå“ªäº›æ•°æ®ç‚¹ï¼ˆå³åˆ†å­è¡¨ç¤ºï¼‰åœ¨ä½ç»´ç©ºé—´ä¸­æ›´é è¿‘ï¼Œä»è€Œå¸®åŠ©æˆ‘ä»¬ç†è§£å“ªäº›åˆ†å­åœ¨æ¨¡å‹ä¸­è¢«è®¤ä¸ºæ˜¯ç›¸ä¼¼çš„ã€‚\n",
        "\n",
        "åœ¨æ¯ä¸ªepochç”Ÿæˆçš„t-SNEå›¾ä¸­ï¼Œæˆ‘ä»¬å°†â€œé«˜ç”œåº¦â€ï¼ˆ`label > 3`ï¼‰å’Œâ€œä½ç”œåº¦â€ï¼ˆ`label â‰¤ 3`ï¼‰çš„åˆ†å­ä½¿ç”¨ä¸åŒçš„é¢œè‰²åŒºåˆ†å¼€æ¥ã€‚è¿™è®©æˆ‘ä»¬èƒ½å¤Ÿè§‚å¯Ÿåˆ°éšç€è®­ç»ƒè¿‡ç¨‹çš„æ¨è¿›ï¼Œé«˜ç”œåº¦å’Œä½ç”œåº¦çš„åˆ†å­æ˜¯å¦åœ¨ç‰¹å¾ç©ºé—´ä¸­é€æ¸åˆ†å¼€ï¼Œä»è€Œå¸®åŠ©æˆ‘ä»¬åˆ¤æ–­æ¨¡å‹æ˜¯å¦æˆåŠŸåœ°å­¦ä¹ åˆ°äº†åˆ†å­ç»“æ„ä¸ç”œåº¦ä¹‹é—´çš„å…³ç³»ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### äºŒã€è®­ç»ƒè¿‡ç¨‹ä¸­é«˜ç”œåº¦å’Œä½ç”œåº¦åˆ†å­çš„åˆ†ç¦»\n",
        "\n",
        "éšç€epochæ•°çš„å¢åŠ ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°åœ¨t-SNEå›¾ä¸­ï¼Œé«˜ç”œåº¦å’Œä½ç”œåº¦çš„åˆ†å­å¼€å§‹åœ¨ç‰¹å¾ç©ºé—´ä¸­**é€æ¸åˆ†ç¦»**ã€‚è¿™ä¸€ç°è±¡åæ˜ äº†æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€æ¸å­¦ä¹ åˆ°æ›´æœ‰æ•ˆçš„åˆ†å­è¡¨ç¤ºï¼Œä»è€Œèƒ½å¤Ÿåœ¨ç‰¹å¾ç©ºé—´ä¸­å°†ä¸åŒç±»å‹çš„åˆ†å­ï¼ˆé«˜ç”œåº¦å’Œä½ç”œåº¦ï¼‰åŒºåˆ†å¼€æ¥ã€‚å…·ä½“æ¥è¯´ï¼š\n",
        "1. **åˆæœŸè®­ç»ƒé˜¶æ®µ**ï¼šåœ¨è®­ç»ƒçš„åˆæœŸï¼Œæ¨¡å‹å¯èƒ½è¿˜æ²¡æœ‰å®Œå…¨æŒæ¡å¦‚ä½•åŒºåˆ†ä¸åŒç±»å‹çš„åˆ†å­ï¼Œå› æ­¤é«˜ç”œåº¦å’Œä½ç”œåº¦çš„åˆ†å­å¯èƒ½åˆ†å¸ƒè¾ƒä¸ºæ··ä¹±ï¼Œæˆ–è€…å®ƒä»¬çš„è¡¨ç¤ºåœ¨ç‰¹å¾ç©ºé—´ä¸­æ²¡æœ‰æ˜æ˜¾çš„åŒºåˆ†ã€‚\n",
        "2. **è®­ç»ƒä¸­æœŸåŠåæœŸ**ï¼šéšç€è®­ç»ƒçš„æ·±å…¥ï¼Œæ¨¡å‹é€šè¿‡ä¼˜åŒ–å‚æ•°é€æ¸å­¦ä¹ åˆ°ä¸åŒç±»å‹åˆ†å­ä¹‹é—´çš„ç‰¹å¾å·®å¼‚ï¼Œå°¤å…¶æ˜¯é€šè¿‡å›¾å·ç§¯å±‚å’ŒMLPå±‚çš„éçº¿æ€§å˜æ¢ï¼Œæ¨¡å‹èƒ½å¤Ÿé€æ¸å°†å…·æœ‰ä¸åŒæ€§è´¨ï¼ˆå¦‚ç”œåº¦ï¼‰çš„åˆ†å­æ˜ å°„åˆ°ç‰¹å¾ç©ºé—´ä¸­çš„ä¸åŒåŒºåŸŸã€‚\n",
        "3. **æœ€ç»ˆé˜¶æ®µ**ï¼šåœ¨è®­ç»ƒçš„åæœŸï¼Œé«˜ç”œåº¦å’Œä½ç”œåº¦çš„åˆ†å­å¼€å§‹æ˜æ˜¾åˆ†ç¦»ï¼Œè¿™è¡¨æ˜æ¨¡å‹å·²ç»å­¦ä¼šäº†å¦‚ä½•åœ¨ç‰¹å¾ç©ºé—´ä¸­åŒºåˆ†è¿™äº›åˆ†å­ï¼Œè¯´æ˜æ¨¡å‹å·²ç»å¾ˆå¥½åœ°å­¦ä¹ åˆ°äº†ç”œåº¦é¢„æµ‹ä»»åŠ¡ä¸­çš„æ¨¡å¼å’Œè§„å¾‹ã€‚\n",
        "\n",
        "è¿™ç§åˆ†ç¦»ç°è±¡æ˜¯**è¡¨ç¤ºå­¦ä¹ ï¼ˆRepresentation Learningï¼‰**çš„ä¸€ä¸ªé‡è¦æŒ‡æ ‡ï¼Œè¡¨æ˜æ¨¡å‹åœ¨ä½ç»´ç©ºé—´ä¸­æå–äº†æœ‰æ•ˆçš„ã€åŒºåˆ†ä¸åŒæ ‡ç­¾ï¼ˆé«˜ç”œåº¦å’Œä½ç”œåº¦ï¼‰çš„ç‰¹å¾ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### ä¸‰ã€t-SNEå’Œè¡¨ç¤ºå­¦ä¹ çš„åŸç†\n",
        "\n",
        "t-SNEçš„å·¥ä½œåŸç†åŸºäºä»¥ä¸‹å‡ ä¸ªå…³é”®æ­¥éª¤ï¼š\n",
        "1. **å±€éƒ¨ç»“æ„ä¿æŒ**ï¼št-SNEé€šè¿‡è®¡ç®—æ¯å¯¹æ•°æ®ç‚¹ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œå¹¶è¯•å›¾åœ¨ä½ç»´ç©ºé—´ä¸­ä¿æŒè¿™äº›ç›¸ä¼¼åº¦ã€‚è¿™æ„å‘³ç€ï¼Œç›¸ä¼¼çš„åˆ†å­åœ¨é«˜ç»´ç©ºé—´ä¸­ç›¸äº’æ¥è¿‘ï¼Œt-SNEä¼šå°½é‡å°†å®ƒä»¬æ˜ å°„åˆ°ä½ç»´ç©ºé—´ä¸­çš„ç›¸å¯¹æ¥è¿‘ä½ç½®ã€‚\n",
        "2. **å…¨å±€ç»“æ„å˜æ¢**ï¼šå°½ç®¡t-SNEå¼ºè°ƒä¿æŒå±€éƒ¨ç»“æ„ï¼Œä½†å®ƒä¹Ÿä¼šå¯¹å…¨å±€ç»“æ„è¿›è¡Œä¸€å®šçš„å˜æ¢ï¼Œä½¿å¾—æ•°æ®ç‚¹çš„åˆ†å¸ƒæ›´ç¬¦åˆä½ç»´ç©ºé—´çš„æ€§è´¨ã€‚æœ€ç»ˆï¼Œt-SNEçš„ç›®æ ‡æ˜¯å°½å¯èƒ½è®©æ¯ä¸ªæ•°æ®ç‚¹åœ¨ä½ç»´ç©ºé—´ä¸­çš„è¡¨ç¤ºä¿ç•™å…¶åœ¨é«˜ç»´ç©ºé—´ä¸­çš„ç›¸å¯¹ä½ç½®å…³ç³»ã€‚\n",
        "\n",
        "åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰ä¼šé€šè¿‡å›¾å·ç§¯å±‚å¯¹å›¾ä¸­çš„èŠ‚ç‚¹è¿›è¡Œä¿¡æ¯ä¼ é€’ï¼Œé€æ­¥ä»å±€éƒ¨çš„åŸå­ä¿¡æ¯æ¨å¯¼å‡ºåˆ†å­çš„å…¨å±€è¡¨ç¤ºã€‚å½“æˆ‘ä»¬å°†è¿™äº›é«˜ç»´çš„åˆ†å­è¡¨ç¤ºè¾“å…¥åˆ°t-SNEä¸­æ—¶ï¼Œt-SNEä¼šæ ¹æ®æ•°æ®ç‚¹é—´çš„ç›¸ä¼¼åº¦å°†è¿™äº›è¡¨ç¤ºæ˜ å°„åˆ°ä½ç»´ç©ºé—´ä¸­ã€‚å¦‚æœæ¨¡å‹å­¦ä¹ å¾—å½“ï¼Œæ ‡ç­¾ç›¸åŒçš„åˆ†å­ä¼šè¢«æ˜ å°„åˆ°ä½ç»´ç©ºé—´çš„ç›¸é‚»åŒºåŸŸï¼Œè€Œä¸åŒæ ‡ç­¾çš„åˆ†å­åˆ™ä¼šè¢«æ˜ å°„åˆ°è¿œç¦»çš„ä½ç½®ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### å››ã€æ€»ç»“\n",
        "\n",
        "é€šè¿‡å¯¹è®­ç»ƒè¿‡ç¨‹ä¸­æ¯ä¸ªepochç”Ÿæˆçš„t-SNEå›¾è¿›è¡Œå¯è§†åŒ–ï¼Œæˆ‘ä»¬å¯ä»¥ç›´è§‚åœ°è§‚å¯Ÿåˆ°æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„è¿›æ­¥ï¼Œç‰¹åˆ«æ˜¯**é«˜ç”œåº¦å’Œä½ç”œåº¦çš„åˆ†å­é€æ¸åˆ†ç¦»**ï¼Œè¿™ä¸€ç°è±¡è¡¨æ˜æ¨¡å‹å·²ç»å­¦ä¼šäº†å¦‚ä½•æ ¹æ®åˆ†å­çš„ç»“æ„ç‰¹å¾æ¥é¢„æµ‹ç”œåº¦å€¼ã€‚è¿™ç§åˆ†ç¦»ç°è±¡åæ˜ äº†å›¾ç¥ç»ç½‘ç»œåœ¨è¿›è¡Œè¡¨ç¤ºå­¦ä¹ æ—¶ï¼Œé€šè¿‡å›¾å·ç§¯å±‚çš„è®­ç»ƒå’ŒMLPæ¨¡å—çš„è¿›ä¸€æ­¥éçº¿æ€§å˜æ¢ï¼ŒæˆåŠŸåœ°å°†å…·æœ‰ä¸åŒæ ‡ç­¾çš„åˆ†å­æ˜ å°„åˆ°ç‰¹å¾ç©ºé—´ä¸­çš„ä¸åŒåŒºåŸŸã€‚\n",
        "\n",
        "t-SNEçš„é™ç»´è¿‡ç¨‹å¸®åŠ©æˆ‘ä»¬éªŒè¯äº†æ¨¡å‹çš„å­¦ä¹ æ•ˆæœï¼Œè¯æ˜äº†éšç€è®­ç»ƒçš„è¿›è¡Œï¼Œåˆ†å­ä¹‹é—´çš„ç‰¹å¾å·®å¼‚é€æ¸å˜å¾—æ›´åŠ æ˜æ˜¾ï¼Œä»è€Œæé«˜äº†é¢„æµ‹å‡†ç¡®æ€§ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLYnonaUbl7f"
      },
      "source": [
        "#### PCAé™ç»´å¯è§†åŒ–â†’gif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjqFP4jPZGMb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# è®¾ç½®è·¯å¾„å’Œå‚æ•°\n",
        "feature_dir = \"mol_global_features\"          # ç‰¹å¾ç›®å½•ä¿æŒåŸæ ·\n",
        "output_dir = \"pca_images\"              # è¾“å‡ºå›¾åƒæ–‡ä»¶å¤¹\n",
        "gif_path = \"pca_evolution.gif\"         # è¾“å‡ºåŠ¨å›¾åç§°\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# è‡ªå®šä¹‰ RGB é¢œè‰²ï¼ˆå½’ä¸€åŒ–ï¼‰\n",
        "high_color = (219 / 255, 49 / 255, 36 / 255)   # çº¢è‰²\n",
        "low_color = (75 / 255, 116 / 255, 178 / 255)   # è“è‰²\n",
        "\n",
        "# è·å–æ‰€æœ‰ epoch æ–‡ä»¶ï¼Œå¹¶æ¯éš” 5 è½®é‡‡æ ·ä¸€æ¬¡\n",
        "all_epochs = sorted([\n",
        "    int(f.split(\"_\")[-1].split(\".\")[0])\n",
        "    for f in os.listdir(feature_dir)\n",
        "    if f.startswith(\"features\")\n",
        "])\n",
        "epochs = [e for e in all_epochs if e % 5 == 0 or e == all_epochs[-1]]  # æ¯5è½®ä¸€ä¸ªå›¾ï¼Œä¿ç•™æœ€åä¸€è½®\n",
        "\n",
        "print(f\"å°†å¤„ç† {len(epochs)} ä¸ª epoch çš„ PCA å¯è§†åŒ–å›¾åƒ...\")\n",
        "\n",
        "# PCA å›¾ç”Ÿæˆï¼ˆæ·»åŠ  tqdm è¿›åº¦æ¡ï¼‰\n",
        "for epoch in tqdm(epochs, desc=\"Running PCA and saving images\"):\n",
        "    features = np.load(f\"{feature_dir}/features_epoch_{epoch:03d}.npy\")\n",
        "    labels = np.load(f\"{feature_dir}/labels_epoch_{epoch:03d}.npy\")\n",
        "\n",
        "    pca = PCA(n_components=2)\n",
        "    embeds_2d = pca.fit_transform(features)\n",
        "\n",
        "    # å¯è§†åŒ–\n",
        "    plt.figure(figsize=(5, 5), dpi=200)\n",
        "    plt.scatter(\n",
        "        embeds_2d[labels > 3, 0], embeds_2d[labels > 3, 1],\n",
        "        c=[high_color], label='High Sweetness (>3)', alpha=0.7\n",
        "    )\n",
        "    plt.scatter(\n",
        "        embeds_2d[labels <= 3, 0], embeds_2d[labels <= 3, 1],\n",
        "        c=[low_color], label='Low Sweetness (â‰¤3)', alpha=0.7\n",
        "    )\n",
        "    plt.legend()\n",
        "    plt.title(f\"PCA of Molecule Representations\\nEpoch {epoch}\")\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(output_dir, f\"pca_epoch_{epoch:03d}.png\")\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "print(\"âœ… æ‰€æœ‰ PCA å›¾åƒå·²ç”Ÿæˆ\")\n",
        "\n",
        "# ç”ŸæˆGIF\n",
        "print(\"ğŸ“½ï¸ æ­£åœ¨ç”ŸæˆåŠ¨å›¾...\")\n",
        "image_files = [os.path.join(output_dir, f\"pca_epoch_{epoch:03d}.png\") for epoch in epochs]\n",
        "images = []\n",
        "for f in tqdm(image_files, desc=\"Loading images for GIF\"):\n",
        "    images.append(Image.open(f))\n",
        "\n",
        "images[0].save(gif_path, save_all=True, append_images=images[1:], duration=500, loop=0)\n",
        "\n",
        "print(f\"âœ… åŠ¨å›¾å·²ä¿å­˜ä¸ºï¼š{gif_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZU6VEDFPS4P"
      },
      "source": [
        "## **3-ç”¨è®­ç»ƒå¥½çš„GNNæ¨¡å‹é¢„æµ‹æ–°åŒ–åˆç‰©çš„ç”œåº¦(æ¨¡å‹æ¨ç†)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEyBo4pBmI6h"
      },
      "source": [
        "### **å•ä¸ªé¢„æµ‹**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeSp7-k_kkAu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from rdkit import Chem\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np\n",
        "\n",
        "# 1. ç¡®ä¿è®¾å¤‡æ­£ç¡®\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 2. åˆå§‹åŒ–æ¨¡å‹\n",
        "# â—â—â— å¿…é¡»ä¸è®­ç»ƒæ—¶çš„è¶…å‚æ•°å®Œå…¨ä¸€è‡´ â—â—â—\n",
        "# æ ¹æ®ä¸Šä¸€è½®è®­ç»ƒä»£ç  (Strategy B): hidden_dim=16, mlp_hidden=128, heads=2 (é»˜è®¤), edge_dim=6\n",
        "model = GATNet(\n",
        "    input_dim=69,        # èŠ‚ç‚¹ç‰¹å¾ç»´åº¦\n",
        "    hidden_dim=16,       # è®­ç»ƒæ—¶ç”¨çš„ 16\n",
        "    mlp_hidden=128,      # è®­ç»ƒæ—¶ç”¨çš„ 128\n",
        "    output_dim=1,\n",
        "    heads=2,             # è®­ç»ƒæ—¶é»˜è®¤æ˜¯ 2\n",
        "    dropout=0.4,         # ä¿æŒä¸€è‡´ (è™½ç„¶ eval æ¨¡å¼ä¸‹ä¸èµ·ä½œç”¨)\n",
        "    edge_dim=6           # â—â— å…³é”®ï¼šå¿…é¡»æŒ‡å®šè¾¹ç‰¹å¾ç»´åº¦\n",
        ").to(device)\n",
        "\n",
        "# 3. åŠ è½½æœ€ä½³æ¨¡å‹æƒé‡\n",
        "# è¯·ç¡®ä¿æ–‡ä»¶åä¸åˆšæ‰ä¿å­˜çš„ä¸€è‡´ (Best_GATEdge+MLP_Model.pt)\n",
        "model_path = \"Best_GATEdge+MLP_Model.pt\"\n",
        "try:\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.eval()\n",
        "    print(\"âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ åŠ è½½æƒé‡å¤±è´¥: {e}\")\n",
        "    print(\"è¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶è·¯å¾„æˆ–è¶…å‚æ•°è®¾ç½®æ˜¯å¦ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ã€‚\")\n",
        "\n",
        "# è¾…åŠ©å‡½æ•°ï¼šSMILESè½¬åŒ–ä¸ºç‰¹å¾\n",
        "def smiles_to_features(smiles, featurizer):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        raise ValueError(f\"æ— æ³•è§£æSMILES: {smiles}\")\n",
        "\n",
        "    features = featurizer(mol)\n",
        "\n",
        "    # è½¬æ¢ä¸º Tensor\n",
        "    x = torch.tensor(features['x'], dtype=torch.float32).to(device)\n",
        "    edge_index = features['edge_index'].to(device)\n",
        "\n",
        "    # å¤„ç†è¾¹ç‰¹å¾\n",
        "    if len(features['edge_attr']) > 0:\n",
        "        edge_attr = torch.tensor(features['edge_attr'], dtype=torch.float32).to(device)\n",
        "    else:\n",
        "        # å¦‚æœæ²¡æœ‰è¾¹ï¼ˆå¦‚å•ä¸ªç¦»å­ï¼‰ï¼Œç”Ÿæˆç©ºçš„ tensor\n",
        "        edge_attr = torch.empty((0, 6), dtype=torch.float32).to(device)\n",
        "\n",
        "    # â—â— å…³é”®ä¿®æ”¹ï¼šç”Ÿæˆ batch å‘é‡ â—â—\n",
        "    # å¯¹äºå•ä¸ªåˆ†å­é¢„æµ‹ï¼Œbatch æ˜¯ä¸€ä¸ªé•¿åº¦ä¸ºèŠ‚ç‚¹æ•°çš„å…¨ 0 å‘é‡\n",
        "    # è¿™å‘Šè¯‰ pool å±‚ï¼šç”±äºè¿™é‡Œåªæœ‰ä¸€ä¸ªå›¾ï¼Œæ‰€æœ‰èŠ‚ç‚¹éƒ½å±äº index 0\n",
        "    batch = torch.zeros(x.shape[0], dtype=torch.long).to(device)\n",
        "\n",
        "    return x, edge_index, batch, edge_attr\n",
        "\n",
        "# ä¸»å‡½æ•°ï¼šé¢„æµ‹ç”œåº¦\n",
        "def predict_sweetness(smiles, model, featurizer):\n",
        "    try:\n",
        "        # è·å–æ•°æ®\n",
        "        x, edge_index, batch, edge_attr = smiles_to_features(smiles, featurizer)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # â—â— å…³é”®ï¼šä¼ å…¥æ‰€æœ‰å‚æ•°ï¼ŒåŒ…æ‹¬ edge_attr â—â—\n",
        "            pred = model(x, edge_index, batch, edge_attr=edge_attr)\n",
        "\n",
        "        return pred.item()\n",
        "    except Exception as e:\n",
        "        print(f\"é¢„æµ‹è¿‡ç¨‹å‡ºé”™: {e}\")\n",
        "        return None\n",
        "\n",
        "# ç”¨æˆ·è¾“å…¥æ–°çš„SMILES (Rebaudioside A, ç”œèŠç³–è‹·A)\n",
        "new_smiles = \"CO[C@H]1[C@H](O[C@H]2CC[C@]3(C)[C@H]4CC[C@]5(C)[C@@H]([C@H](C)CCC[C@H](C)CO)[C@@H](O)[C@H](O)[C@H]5[C@]4(O)CC[C@H]3[C@H]2O)OC[C@@H](O)[C@@H]1O\"\n",
        "\n",
        "# ç¡®ä¿ç‰¹å¾æå–å™¨å·²å®šä¹‰\n",
        "if 'featurizer' not in locals():\n",
        "    featurizer = MoleculeFeaturizer()\n",
        "\n",
        "# é¢„æµ‹ç”œåº¦\n",
        "print(f\"\\næ­£åœ¨é¢„æµ‹åˆ†å­: {new_smiles[:30]}...\")\n",
        "predicted_sweetness = predict_sweetness(new_smiles, model, featurizer)\n",
        "\n",
        "if predicted_sweetness is not None:\n",
        "    print(\"=\"*40)\n",
        "    print(f\"é¢„æµ‹ç»“æœ (logSw): {predicted_sweetness:.4f}\")\n",
        "    # åæ¨å¤§æ¦‚çš„ç›¸å¯¹ç”œåº¦ (å‡è®¾ logSw æ˜¯ log10(ç›¸å¯¹è”—ç³–ç”œåº¦))\n",
        "    # æ³¨æ„ï¼šè¿™å–å†³äºä½ åŸå§‹æ•°æ®çš„å•ä½ï¼Œå¦‚æœ logSw æ˜¯ log10(SW)ï¼Œé‚£ä¹ˆï¼š\n",
        "    estimated_sw = 10 ** predicted_sweetness\n",
        "    print(f\"ä¼°ç®—ç›¸å¯¹ç”œåº¦ (SW): {estimated_sw:.2f}\")\n",
        "    print(\"=\"*40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmMm3czRmL6X"
      },
      "source": [
        "### **æ‰¹é‡é¢„æµ‹**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ai5TWF-tlVI-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from tqdm import tqdm  # å¯¼å…¥tqdm\n",
        "import numpy as np\n",
        "\n",
        "# 1. è®¾ç½®è®¾å¤‡\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 2. åˆå§‹åŒ–æ¨¡å‹\n",
        "# â—â—â— å¿…é¡»ä¸è®­ç»ƒæ—¶çš„è¶…å‚æ•°å®Œå…¨ä¸€è‡´ (Strategy B) â—â—â—\n",
        "model = GATNet(\n",
        "    input_dim=69,        # èŠ‚ç‚¹ç‰¹å¾ç»´åº¦\n",
        "    hidden_dim=16,       # è®­ç»ƒæ—¶ç”¨çš„ 16\n",
        "    mlp_hidden=128,      # è®­ç»ƒæ—¶ç”¨çš„ 128\n",
        "    output_dim=1,\n",
        "    heads=2,             # è®­ç»ƒæ—¶é»˜è®¤æ˜¯ 2\n",
        "    dropout=0.4,         # ä¿æŒä¸€è‡´\n",
        "    edge_dim=6           # â—â— å…³é”®ï¼šå¿…é¡»æŒ‡å®šè¾¹ç‰¹å¾ç»´åº¦\n",
        ").to(device)\n",
        "\n",
        "# 3. åŠ è½½æœ€ä½³æ¨¡å‹æƒé‡\n",
        "model_path = \"/content/Best_GATEdge+MLP_Model.pt\"\n",
        "try:\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.eval()\n",
        "    print(\"âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ\")\n",
        "except RuntimeError as e:\n",
        "    print(f\"âŒ åŠ è½½æƒé‡å¤±è´¥: {e}\")\n",
        "    print(\"è¯·æ£€æŸ¥ GATNet åˆå§‹åŒ–å‚æ•°æ˜¯å¦ä¸è®­ç»ƒä»£ç å®Œå…¨ä¸€è‡´ (hidden_dim=16, mlp_hidden=128, heads=2).\")\n",
        "    exit()\n",
        "\n",
        "# è¾…åŠ©å‡½æ•°ï¼šSMILESè½¬åŒ–ä¸ºç‰¹å¾ Tensor\n",
        "def smiles_to_features(smiles, featurizer):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return None, None, None, None # è¿”å›ç©ºä»¥ç¤ºé”™è¯¯\n",
        "\n",
        "    features = featurizer(mol)\n",
        "\n",
        "    # è½¬æ¢ä¸º Tensor å¹¶ç§»åŠ¨åˆ°è®¾å¤‡\n",
        "    x = torch.tensor(features['x'], dtype=torch.float32).to(device)\n",
        "    edge_index = features['edge_index'].to(device)\n",
        "\n",
        "    # å¤„ç†è¾¹ç‰¹å¾\n",
        "    if len(features['edge_attr']) > 0:\n",
        "        edge_attr = torch.tensor(features['edge_attr'], dtype=torch.float32).to(device)\n",
        "    else:\n",
        "        edge_attr = torch.empty((0, 6), dtype=torch.float32).to(device)\n",
        "\n",
        "    # â—â— å…³é”®ä¿®å¤ï¼šç”Ÿæˆ batch å‘é‡ â—â—\n",
        "    # å•ä¸ªåˆ†å­é¢„æµ‹æ—¶ï¼Œbatch æ˜¯å…¨ 0 å‘é‡ï¼Œé•¿åº¦ç­‰äºåŸå­æ•°\n",
        "    batch = torch.zeros(x.shape[0], dtype=torch.long).to(device)\n",
        "\n",
        "    return x, edge_index, batch, edge_attr\n",
        "\n",
        "# ä¸»å‡½æ•°ï¼šé¢„æµ‹ç”œåº¦\n",
        "def predict_sweetness(smiles, model, featurizer):\n",
        "    try:\n",
        "        x, edge_index, batch, edge_attr = smiles_to_features(smiles, featurizer)\n",
        "\n",
        "        if x is None: # è§£æå¤±è´¥\n",
        "            return None\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # â—â— å…³é”®ï¼šä¼ å…¥æ‰€æœ‰å‚æ•°ï¼ŒåŒ…æ‹¬ edge_attr â—â—\n",
        "            pred = model(x, edge_index, batch, edge_attr=edge_attr)\n",
        "        return pred.item()\n",
        "    except Exception as e:\n",
        "        # print(f\"é¢„æµ‹å‡ºé”™ ({smiles}): {e}\") # å¯é€‰ï¼šæ‰“å°å…·ä½“é”™è¯¯\n",
        "        return None\n",
        "\n",
        "# ==========================================\n",
        "# æ‰¹é‡å¤„ç† CSV æµç¨‹\n",
        "# ==========================================\n",
        "\n",
        "# åŠ è½½åŒ…å«SMILESçš„CSVæ–‡ä»¶\n",
        "csv_path = \"/content/SweetpredDB.csv\" # ç¡®ä¿æ–‡ä»¶è·¯å¾„æ­£ç¡®\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(f\"æˆåŠŸè¯»å– CSVï¼Œå…± {len(df)} è¡Œæ•°æ®\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"âŒ æœªæ‰¾åˆ°æ–‡ä»¶: {csv_path}\")\n",
        "    exit()\n",
        "\n",
        "# ç¡®ä¿åˆ—åæ­£ç¡® (æœ‰äº›æ•°æ®é›†åˆ—åå¯èƒ½æ˜¯ 'SMILES' æˆ– 'smiles')\n",
        "if 'smiles' not in df.columns:\n",
        "    # å°è¯•æŸ¥æ‰¾å¯èƒ½æ˜¯ smiles çš„åˆ—\n",
        "    possible_cols = [col for col in df.columns if 'smiles' in col.lower()]\n",
        "    if possible_cols:\n",
        "        smiles_col = possible_cols[0]\n",
        "        print(f\"è­¦å‘Š: æœªæ‰¾åˆ° 'smiles' åˆ—ï¼Œå°†ä½¿ç”¨ '{smiles_col}' åˆ—ä»£æ›¿\")\n",
        "    else:\n",
        "        print(\"âŒ CSVæ–‡ä»¶å¿…é¡»åŒ…å« 'smiles' åˆ—ï¼\")\n",
        "        exit()\n",
        "else:\n",
        "    smiles_col = 'smiles'\n",
        "\n",
        "# ç¡®ä¿ç‰¹å¾æå–å™¨å·²å®šä¹‰\n",
        "if 'MoleculeFeaturizer' not in locals():\n",
        "    print(\"âŒ é”™è¯¯: MoleculeFeaturizer æœªå®šä¹‰ï¼Œè¯·å…ˆè¿è¡Œå®šä¹‰è¯¥ç±»çš„ä»£ç å—ã€‚\")\n",
        "else:\n",
        "    featurizer = MoleculeFeaturizer()\n",
        "\n",
        "    # ç”¨äºä¿å­˜é¢„æµ‹ç»“æœ\n",
        "    predictions = []\n",
        "    valid_indices = [] # è®°å½•é¢„æµ‹æˆåŠŸçš„è¡Œç´¢å¼•\n",
        "\n",
        "    print(\"å¼€å§‹æ‰¹é‡é¢„æµ‹...\")\n",
        "\n",
        "    # æ‰¹é‡é¢„æµ‹ï¼Œå¹¶ä¸”æ·»åŠ è¿›åº¦æ¡\n",
        "    # ä½¿ç”¨ tqdm åŒ…è£…è¿­ä»£å™¨\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Predicting\"):\n",
        "        smiles = row[smiles_col]\n",
        "\n",
        "        # æ’é™¤ç©ºå€¼\n",
        "        if pd.isna(smiles):\n",
        "            predictions.append(None)\n",
        "            continue\n",
        "\n",
        "        pred_val = predict_sweetness(smiles, model, featurizer)\n",
        "        predictions.append(pred_val)\n",
        "\n",
        "    # å°†é¢„æµ‹ç»“æœæ·»åŠ åˆ°åŸå§‹ DataFrame ä¸­\n",
        "    df['Predicted_logSw'] = predictions\n",
        "\n",
        "    # æ‰“å°å‰å‡ è¡ŒæŸ¥çœ‹ç»“æœ\n",
        "    print(\"\\né¢„æµ‹å®Œæˆï¼å‰ 5 è¡Œç»“æœï¼š\")\n",
        "    print(df[[smiles_col, 'Predicted_logSw']].head())\n",
        "\n",
        "    # ä¿å­˜é¢„æµ‹ç»“æœåˆ°CSVæ–‡ä»¶\n",
        "    output_csv = \"/content/prediction_result.csv\"\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"\\nâœ… å®Œæ•´ç»“æœå·²ä¿å­˜åˆ° {output_csv}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfEujnBuPYKZ"
      },
      "source": [
        "## **4-åŸºäºæ¢¯åº¦çš„GNNæ¨¡å‹å¯è§£é‡Šæ€§åˆ†æ**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hj5Guwg-nvei"
      },
      "outputs": [],
      "source": [
        "!pip install matplotlib==3.7.3#å®‰è£…åä¼šæ˜¾ç¤ºé‡å¯ï¼Œé‡å¯åï¼Œéœ€è¦é‡æ–°è¿è¡Œä¸€éæ‰€æœ‰å‰é¢çš„ä»£ç ï¼šï¼ˆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_OxRXtXnop2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit.Chem.Draw import SimilarityMaps, rdMolDraw2D\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.loader import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. ç¡®ä¿è®¾å¤‡æ­£ç¡®\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 2. åˆå§‹åŒ–æ¨¡å‹ (å‚æ•°ä¿æŒ Strategy B)\n",
        "model = GATNet(\n",
        "    input_dim=69,\n",
        "    hidden_dim=16,\n",
        "    mlp_hidden=128,\n",
        "    output_dim=1,\n",
        "    heads=2,\n",
        "    dropout=0.4,\n",
        "    edge_dim=6\n",
        ").to(device)\n",
        "\n",
        "def visualize_grad_heatmap(model, val_dataset, device, num_samples=10):\n",
        "    # éšæœºé€‰æ‹©æ ·æœ¬\n",
        "    indices = np.random.choice(len(val_dataset), num_samples, replace=False)\n",
        "    subset = torch.utils.data.Subset(val_dataset, indices)\n",
        "    loader = DataLoader(subset, batch_size=1, shuffle=False)\n",
        "\n",
        "    # è‡ªå®šä¹‰é¢œè‰²æ˜ å°„\n",
        "    color_blue = (75 / 255, 116 / 255, 178 / 255)\n",
        "    color_red = (219 / 255, 49 / 255, 36 / 255)\n",
        "    custom_cmap = LinearSegmentedColormap.from_list(\n",
        "        \"custom_cmap\", [color_blue, \"white\", color_red]\n",
        "    )\n",
        "\n",
        "    model.eval()\n",
        "    print(f\"æ­£åœ¨ç”Ÿæˆ {num_samples} å¼ çƒ­åŠ›å›¾...\")\n",
        "\n",
        "    for batch_idx, data in enumerate(tqdm(loader, desc=\"Generating heatmaps\")):\n",
        "        data = data.to(device)\n",
        "\n",
        "        input_x = data.x.clone().detach().requires_grad_(True)\n",
        "        pred = model(input_x, data.edge_index, data.batch, edge_attr=data.edge_attr)\n",
        "\n",
        "        model.zero_grad()\n",
        "        pred.backward()\n",
        "\n",
        "        # è·å–æ¢¯åº¦\n",
        "        grads = input_x.grad.abs().sum(dim=1).cpu().numpy()\n",
        "\n",
        "        # å½’ä¸€åŒ–\n",
        "        if grads.max() - grads.min() > 0:\n",
        "            grads = (grads - grads.min()) / (grads.max() - grads.min())\n",
        "\n",
        "        # â—â—â— å…³é”®ä¿®å¤ 1ï¼šè½¬æ¢ä¸º Python åˆ—è¡¨ â—â—â—\n",
        "        # è¿™ä¸€æ­¥è§£å†³äº† \"The truth value of an array...\" é”™è¯¯\n",
        "        weights_list = grads.tolist()\n",
        "\n",
        "        smiles = data.smiles[0] if isinstance(data.smiles, list) else data.smiles\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "        if mol:\n",
        "            try:\n",
        "                AllChem.Compute2DCoords(mol)\n",
        "\n",
        "                # åˆ›å»º RDKit ç»˜å›¾å¯¹è±¡\n",
        "                d = rdMolDraw2D.MolDraw2DCairo(400, 400)\n",
        "\n",
        "                # â—â—â— å…³é”®ä¿®å¤ 2ï¼šä¼ å…¥ weights_list è€Œä¸æ˜¯ grads æ•°ç»„ â—â—â—\n",
        "                SimilarityMaps.GetSimilarityMapFromWeights(\n",
        "                    mol,\n",
        "                    weights=weights_list,  # è¿™é‡Œä¼ å…¥ list\n",
        "                    colorMap=custom_cmap,\n",
        "                    contourLines=10,\n",
        "                    draw2d=d\n",
        "                )\n",
        "\n",
        "                d.FinishDrawing()\n",
        "                save_name = f\"heatmap_{batch_idx}.png\"\n",
        "                d.WriteDrawingText(save_name)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"ç»˜åˆ¶åˆ†å­ {smiles[:10]}... æ—¶å‡ºé”™: {e}\")\n",
        "                continue\n",
        "\n",
        "    print(f\"âœ… çƒ­åŠ›å›¾ç”Ÿæˆå®Œæ¯•ï¼Œå›¾ç‰‡å·²ä¿å­˜åœ¨å½“å‰ç›®å½•ä¸‹ã€‚\")\n",
        "\n",
        "# ä½¿ç”¨ç¤ºä¾‹\n",
        "try:\n",
        "    model.load_state_dict(torch.load(\"/content/Best_GATEdge+MLP_Model.pt\", map_location=device))\n",
        "    print(\"âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ\")\n",
        "\n",
        "    if 'val_dataset' in locals():\n",
        "        visualize_grad_heatmap(model, val_dataset, device, num_samples=5)\n",
        "    else:\n",
        "        print(\"âŒ val_dataset æœªå®šä¹‰\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ è¿è¡Œå‡ºé”™: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKfLmxyG4wDd"
      },
      "source": [
        "### **å¯è§†åŒ–æ¢¯åº¦çƒ­åŠ›å›¾è§£é‡Š**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0yp-Pz54sDf"
      },
      "source": [
        "\n",
        "\n",
        "åœ¨åˆ†å­å±æ€§é¢„æµ‹çš„ä»»åŠ¡ä¸­ï¼Œå°¤å…¶æ˜¯é€šè¿‡å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰è¿›è¡Œå­¦ä¹ æ—¶ï¼Œæˆ‘ä»¬å¸¸å¸¸å¸Œæœ›ç†è§£æ¨¡å‹æ˜¯å¦‚ä½•æ ¹æ®è¾“å…¥æ•°æ®ï¼ˆä¾‹å¦‚åˆ†å­çš„ç»“æ„ï¼‰è¿›è¡Œå†³ç­–çš„ã€‚æ¢¯åº¦çƒ­åŠ›å›¾æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„å·¥å…·ï¼Œå®ƒå¸®åŠ©æˆ‘ä»¬äº†è§£æ¨¡å‹æ˜¯å¦‚ä½•â€œå…³æ³¨â€åˆ†å­ä¸­çš„ä¸åŒéƒ¨åˆ†ï¼Œå°¤å…¶æ˜¯åœ¨é¢„æµ‹è¿‡ç¨‹ä¸­ï¼Œå“ªäº›éƒ¨åˆ†çš„ç‰¹å¾å¯¹æœ€ç»ˆé¢„æµ‹å½±å“æœ€å¤§ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è¯¦ç»†è§£é‡Š**æ¢¯åº¦çƒ­åŠ›å›¾**çš„å·¥ä½œåŸç†ï¼Œ**ä¸ºä½•è¦ä½¿ç”¨æ¢¯åº¦çƒ­åŠ›å›¾**ï¼Œä»¥åŠå¦‚ä½•åœ¨æœ¬é¡¹ç›®ä¸­ç»“åˆå›¾ç¥ç»ç½‘ç»œå’ŒåŒ–å­¦çŸ¥è¯†ç”Ÿæˆçƒ­åŠ›å›¾ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### ä¸€ã€æ¢¯åº¦çƒ­åŠ›å›¾çš„åŸç†\n",
        "\n",
        "**æ¢¯åº¦çƒ­åŠ›å›¾**é€šè¿‡è®¡ç®—æ¨¡å‹è¾“å‡ºå¯¹è¾“å…¥ç‰¹å¾çš„æ¢¯åº¦ï¼Œæ¥æ­ç¤ºæ¨¡å‹å¯¹äºæ¯ä¸ªç‰¹å¾çš„é‡è¦æ€§ã€‚åœ¨æœ¬é¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬å…³æ³¨çš„æ˜¯å›¾ç¥ç»ç½‘ç»œï¼ˆGATNetï¼‰åœ¨å¯¹åˆ†å­è¿›è¡Œé¢„æµ‹æ—¶ï¼Œå“ªäº›**åŸå­ç‰¹å¾**å¯¹æœ€ç»ˆé¢„æµ‹ï¼ˆä¾‹å¦‚ç”œåº¦é¢„æµ‹ï¼‰å½±å“æœ€å¤§ã€‚\n",
        "\n",
        "1. **æ¢¯åº¦è®¡ç®—**ï¼šæ¨¡å‹é€šè¿‡åå‘ä¼ æ’­è®¡ç®—æ¯ä¸ªåŸå­ç‰¹å¾çš„æ¢¯åº¦ã€‚æ¢¯åº¦æ˜¯æŒ‡**æ¨¡å‹è¾“å‡ºï¼ˆä¾‹å¦‚é¢„æµ‹çš„ç”œåº¦å€¼ï¼‰**å¯¹è¾“å…¥ç‰¹å¾ï¼ˆå¦‚åŸå­ç‰¹å¾ï¼‰çš„å˜åŒ–ç‡ã€‚å¯¹äºä¸€ä¸ªç‰¹å®šçš„åˆ†å­ï¼Œæ¢¯åº¦å€¼è¾ƒå¤§çš„åŸå­è¯´æ˜æ¨¡å‹è®¤ä¸ºè¿™äº›åŸå­å¯¹é¢„æµ‹ç»“æœçš„è´¡çŒ®è¾ƒå¤§ã€‚\n",
        "2. **å½’ä¸€åŒ–**ï¼šä¸ºäº†æ›´å¥½åœ°å¯è§†åŒ–æ¢¯åº¦ï¼Œè®¡ç®—å‡ºçš„æ¢¯åº¦å€¼è¢«å½’ä¸€åŒ–å¤„ç†ã€‚å½’ä¸€åŒ–åï¼Œæ¢¯åº¦å€¼è¢«ç¼©æ”¾åˆ°[0, 1]çš„èŒƒå›´å†…ï¼Œä»è€Œä¾¿äºå¯è§†åŒ–ã€‚\n",
        "3. **çƒ­åŠ›å›¾ç»˜åˆ¶**ï¼šåŸºäºå½’ä¸€åŒ–åçš„æ¢¯åº¦å€¼ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶æ˜ å°„åˆ°åˆ†å­çš„2Dç»“æ„å›¾ä¸­ï¼Œå½¢æˆä¸€ä¸ª**çƒ­åŠ›å›¾**ï¼Œé€šè¿‡é¢œè‰²çš„å˜åŒ–æ¥è¡¨ç¤ºæ¯ä¸ªåŸå­çš„é‡è¦æ€§ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### äºŒã€æ¨¡å‹ä¸­çš„æ¢¯åº¦è®¡ç®—\n",
        "\n",
        "æœ¬é¡¹ç›®çš„ç›®æ ‡æ˜¯é€šè¿‡è®­ç»ƒå¾—åˆ°çš„**GATNet**æ¨¡å‹é¢„æµ‹åˆ†å­çš„ç”œåº¦ï¼ˆ`logSw`ï¼‰ã€‚åœ¨æ¨¡å‹çš„**å‰å‘ä¼ æ’­**è¿‡ç¨‹ä¸­ï¼ŒGATç½‘ç»œé¦–å…ˆé€šè¿‡å›¾å·ç§¯å±‚ï¼ˆGATConvï¼‰æå–åŸå­å’Œåˆ†å­ä¹‹é—´çš„å…³ç³»ä¿¡æ¯ï¼Œç„¶åé€šè¿‡æ± åŒ–å±‚å’ŒMLPå¤´éƒ¨è¿›è¡Œé¢„æµ‹ã€‚æˆ‘ä»¬å¸Œæœ›é€šè¿‡**æ¢¯åº¦åå‘ä¼ æ’­**æ¥äº†è§£å“ªäº›åŸå­ç‰¹å¾å¯¹é¢„æµ‹ç»“æœå½±å“æœ€å¤§ã€‚\n",
        "\n",
        "å…·ä½“æµç¨‹å¦‚ä¸‹ï¼š\n",
        "1. **å‰å‘ä¼ æ’­**ï¼šæ¨¡å‹æ ¹æ®è¾“å…¥çš„åŸå­ç‰¹å¾ï¼ˆ`data.x`ï¼‰å’Œå›¾ç»“æ„ï¼ˆ`data.edge_index`ï¼‰ï¼Œè®¡ç®—é¢„æµ‹å€¼ï¼ˆ`pred`ï¼‰ã€‚\n",
        "2. **åå‘ä¼ æ’­**ï¼šåœ¨é¢„æµ‹å®Œæˆåï¼Œæˆ‘ä»¬è®¡ç®—**æŸå¤±å‡½æ•°çš„æ¢¯åº¦**ã€‚æ¢¯åº¦åæ˜ äº†æ¨¡å‹è¾“å‡ºï¼ˆé¢„æµ‹å€¼ï¼‰å¯¹è¾“å…¥ç‰¹å¾ï¼ˆåŸå­ç‰¹å¾ï¼‰çš„çµæ•åº¦ï¼Œå³å“ªäº›åŸå­å¯¹é¢„æµ‹ç»“æœè´¡çŒ®æ›´å¤§ã€‚\n",
        "3. **æ¢¯åº¦çš„å½’ä¸€åŒ–**ï¼šä¸ºäº†ä¾¿äºå¯è§†åŒ–ï¼Œæ¢¯åº¦å€¼è¢«å½’ä¸€åŒ–åˆ°[0, 1]çš„èŒƒå›´å†…ã€‚å½’ä¸€åŒ–æœ‰åŠ©äºå°†ä¸åŒåˆ†å­çš„æ¢¯åº¦è¿›è¡Œç»Ÿä¸€çš„å°ºåº¦æ¯”è¾ƒï¼Œä½¿å¾—æˆ‘ä»¬å¯ä»¥ç›´æ¥è§‚å¯Ÿå“ªäº›åŸå­å¯¹äºé¢„æµ‹ç»“æœå½±å“è¾ƒå¤§ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### ä¸‰ã€ç»“åˆåˆ†å­å¯è§†åŒ–ç»˜åˆ¶çƒ­åŠ›å›¾\n",
        "\n",
        "åœ¨è¿›è¡Œæ¢¯åº¦è®¡ç®—åï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶ä¸åˆ†å­çš„ç»“æ„è¿›è¡Œå¯¹æ¯”ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†æ¢¯åº¦å€¼æ˜ å°„åˆ°**åˆ†å­çš„äºŒç»´ç»“æ„å›¾**ä¸­ï¼Œå¹¶ä½¿ç”¨é¢œè‰²æ¥è¡¨ç¤ºæ¯ä¸ªåŸå­çš„è´¡çŒ®ã€‚\n",
        "\n",
        "1. **åˆ†å­ç»“æ„ç»˜åˆ¶**ï¼šé€šè¿‡ä½¿ç”¨`RDKit`åº“çš„`Compute2DCoords`å‡½æ•°ï¼Œç”Ÿæˆæ¯ä¸ªåˆ†å­çš„äºŒç»´åæ ‡ã€‚è¿™æ ·ï¼Œåˆ†å­å°±å¯ä»¥åœ¨å¹³é¢ä¸Šå¯è§†åŒ–ã€‚\n",
        "2. **çƒ­åŠ›å›¾ç”Ÿæˆ**ï¼šé€šè¿‡`SimilarityMaps.GetSimilarityMapFromWeights`å‡½æ•°ï¼Œæˆ‘ä»¬å°†å½’ä¸€åŒ–åçš„æ¢¯åº¦å€¼æ˜ å°„åˆ°åˆ†å­ç»“æ„çš„æ¯ä¸ªåŸå­ä¸Šã€‚çƒ­åŠ›å›¾ä¸­çš„é¢œè‰²ä»**ç™½è‰²**ï¼ˆè¡¨ç¤ºè¾ƒå°çš„æ¢¯åº¦ï¼‰åˆ°**çº¢è‰²**ï¼ˆè¡¨ç¤ºè¾ƒå¤§çš„æ¢¯åº¦ï¼‰ï¼Œé€šè¿‡è¿™ç§æ–¹å¼ç›´è§‚åœ°è¡¨ç¤ºäº†æ¯ä¸ªåŸå­åœ¨æœ€ç»ˆé¢„æµ‹ä¸­çš„é‡è¦æ€§ã€‚\n",
        "\n",
        "åœ¨çƒ­åŠ›å›¾ä¸­ï¼š\n",
        "- **çº¢è‰²**åŒºåŸŸè¡¨ç¤ºè¯¥ä½ç½®çš„åŸå­å¯¹äºé¢„æµ‹ç»“æœæœ‰è¾ƒå¤§çš„è´¡çŒ®ã€‚\n",
        "- **ç™½è‰²**åŒºåŸŸè¡¨ç¤ºè¯¥ä½ç½®çš„åŸå­å¯¹é¢„æµ‹ç»“æœçš„è´¡çŒ®è¾ƒå°ã€‚\n",
        "\n",
        "è¿™ç§å¯è§†åŒ–ä¸ä»…å¸®åŠ©æˆ‘ä»¬ç†è§£æ¨¡å‹æ˜¯å¦‚ä½•åšå‡ºé¢„æµ‹çš„ï¼Œè¿˜èƒ½æ­ç¤ºåˆ†å­ç»“æ„ä¸å…¶é¢„æµ‹æ€§è´¨ä¹‹é—´çš„å…³ç³»ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### å››ã€æ¨¡å‹ä¸åŒ–å­¦çŸ¥è¯†çš„ç»“åˆ\n",
        "\n",
        "- **å›¾ç¥ç»ç½‘ç»œä¸åˆ†å­ç»“æ„**ï¼šåœ¨åˆ†å­æ•°æ®ä¸­ï¼ŒåŸå­å’Œå®ƒä»¬ä¹‹é—´çš„é”®å¯ä»¥é€šè¿‡å›¾çš„èŠ‚ç‚¹å’Œè¾¹æ¥è¡¨ç¤ºã€‚GATNetä½œä¸ºå›¾ç¥ç»ç½‘ç»œçš„ä¸€ç§ï¼Œé€šè¿‡å›¾å·ç§¯å±‚ï¼ˆGATConvï¼‰å­¦ä¹ åŸå­èŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œé¢„æµ‹ã€‚åœ¨è¯¥æ¨¡å‹ä¸­ï¼Œè¾¹ç‰¹å¾ï¼ˆå¦‚åŒ–å­¦é”®ç±»å‹ã€èŠ³é¦™æ€§ç­‰ï¼‰å¯¹é¢„æµ‹ç»“æœçš„å½±å“è¢«æœ‰æ•ˆåœ°å­¦ä¹ ã€‚\n",
        "  \n",
        "- **æ¢¯åº¦çƒ­åŠ›å›¾ä¸åŒ–å­¦è§£é‡Š**ï¼šé€šè¿‡æ¢¯åº¦çƒ­åŠ›å›¾ï¼Œæˆ‘ä»¬å¯ä»¥å°†åˆ†å­ç‰¹å¾å’Œæ¨¡å‹è¾“å‡ºä¹‹é—´çš„å…³ç³»å¯è§†åŒ–ã€‚ä¾‹å¦‚ï¼Œåœ¨é¢„æµ‹åˆ†å­çš„ç”œåº¦æ—¶ï¼Œæ¨¡å‹å¯èƒ½ä¼šç‰¹åˆ«å…³æ³¨æŸäº›é‡è¦çš„åŒ–å­¦åŸºå›¢ï¼ˆå¦‚ç¾ŸåŸºã€çƒ¯çƒƒåŸºå›¢ç­‰ï¼‰ï¼Œè¿™äº›åŸºå›¢çš„ç»“æ„å¯¹åˆ†å­çš„ç”œåº¦æœ‰æ˜¾è‘—å½±å“ã€‚é€šè¿‡çƒ­åŠ›å›¾ï¼Œæˆ‘ä»¬å¯ä»¥è¯†åˆ«è¿™äº›å…³é”®åŒºåŸŸï¼Œä»è€Œä¸ºåˆ†å­è®¾è®¡æä¾›åŒ–å­¦æŒ‡å¯¼ã€‚\n",
        "\n",
        "- **åˆ†å­è®¾è®¡ä¸ä¼˜åŒ–**ï¼šé€šè¿‡åˆ†ææ¢¯åº¦çƒ­åŠ›å›¾ï¼Œæˆ‘ä»¬ä¸ä»…èƒ½å¤Ÿè§£é‡Šæ¨¡å‹çš„é¢„æµ‹è¡Œä¸ºï¼Œè¿˜èƒ½å¤Ÿ**æŒ‡å¯¼åˆ†å­è®¾è®¡**ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæŸäº›ç‰¹å®šçš„åŸå­ä½ç½®å¯¹ç”œåº¦é¢„æµ‹æœ‰è¾ƒå¤§å½±å“ï¼Œé‚£ä¹ˆå¯ä»¥é€šè¿‡ä¼˜åŒ–è¿™äº›ä½ç½®çš„åŒ–å­¦åŸºå›¢æ¥æ”¹è¿›åˆ†å­çš„ç”œåº¦ç‰¹æ€§ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "#### äº”ã€æ€»ç»“\n",
        "\n",
        "é€šè¿‡æ¢¯åº¦çƒ­åŠ›å›¾çš„å¯è§†åŒ–ï¼Œæˆ‘ä»¬å¯ä»¥æ·±å…¥äº†è§£æ¨¡å‹åœ¨è¿›è¡Œç”œåº¦é¢„æµ‹æ—¶å¦‚ä½•å…³æ³¨åˆ†å­ç»“æ„çš„ä¸åŒéƒ¨åˆ†ã€‚å…·ä½“è€Œè¨€ï¼š\n",
        "- **æ¢¯åº¦çƒ­åŠ›å›¾**é€šè¿‡è®¡ç®—æ¯ä¸ªåŸå­å¯¹é¢„æµ‹ç»“æœçš„è´¡çŒ®ï¼Œå¸®åŠ©æˆ‘ä»¬ç†è§£å“ªäº›éƒ¨åˆ†çš„åˆ†å­ç»“æ„å¯¹æœ€ç»ˆé¢„æµ‹æœ€ä¸ºå…³é”®ã€‚\n",
        "- ç»“åˆ**å›¾ç¥ç»ç½‘ç»œ**ï¼ˆGATNetï¼‰çš„å›¾å·ç§¯æ“ä½œï¼Œæˆ‘ä»¬èƒ½å¤Ÿå­¦ä¹ åˆ°åˆ†å­ä¹‹é—´å¤æ‚çš„ç»“æ„å…³ç³»ã€‚\n",
        "- ä½¿ç”¨**RDKit**è¿›è¡Œåˆ†å­å¯è§†åŒ–ï¼Œå°†æ¢¯åº¦ä¿¡æ¯æ˜ å°„åˆ°åˆ†å­çš„äºŒç»´ç»“æ„å›¾ä¸Šï¼Œä½¿å¾—æˆ‘ä»¬èƒ½å¤Ÿç›´è§‚åœ°çœ‹åˆ°é«˜è´¡çŒ®åŒºåŸŸï¼Œè¿›è€Œä¸ºåˆ†å­è®¾è®¡å’Œä¼˜åŒ–æä¾›æŒ‡å¯¼ã€‚\n",
        "\n",
        "è¿™ç§å¯è§†åŒ–æ–¹æ³•ä¸ä»…æå‡äº†æˆ‘ä»¬å¯¹æ¨¡å‹è¡Œä¸ºçš„ç†è§£ï¼Œè¿˜ä¸ºåŒ–å­¦é¢†åŸŸçš„åˆ†å­ä¼˜åŒ–å’Œè®¾è®¡æä¾›äº†é‡è¦çš„å·¥å…·ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5-åˆšæ‰æ˜¯å›å½’ä»»åŠ¡ï¼Œæˆ‘ä»¬å†è¯•è¯•åˆ†ç±»ä»»åŠ¡å§**"
      ],
      "metadata": {
        "id": "fM3Z4MVku8bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import rdchem\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import os\n",
        "from scipy.sparse import coo_matrix\n",
        "\n",
        "# ==========================================\n",
        "# 1. é…ç½®ä¸é‡ç½®\n",
        "# ==========================================\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "seed_everything()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ç»˜å›¾è®¾ç½®\n",
        "plt.rcParams['figure.dpi'] = 150\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "# ==========================================\n",
        "# 2. ç‰¹å¾æå–å™¨ (ä¿æŒä¸å˜ï¼Œç”¨äºç”Ÿæˆå›¾æ•°æ®)\n",
        "# ==========================================\n",
        "def one_hot_encoding(value, choices):\n",
        "    encoding = [0] * (len(choices) + 1)\n",
        "    index = choices.index(value) if value in choices else -1\n",
        "    encoding[index] = 1\n",
        "    return encoding\n",
        "\n",
        "class MoleculeFeaturizer(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def _atom_featurizer(self, atom):\n",
        "        # 37ç§å…ƒç´  + 1 other\n",
        "        atomic_numer = [1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 28, 29,\n",
        "                        30, 31, 32, 33, 34, 35, 36, 37, 38, 46, 47, 48, 49, 50, 51, 52, 53]\n",
        "        atom_type = one_hot_encoding(atom.GetAtomicNum(), atomic_numer)\n",
        "\n",
        "        degree = one_hot_encoding(atom.GetTotalDegree(), list(range(5)))\n",
        "        hybrid = one_hot_encoding(int(atom.GetHybridization()), list(range(len(Chem.HybridizationType.names)-1)))\n",
        "        chiral = one_hot_encoding(atom.GetChiralTag(), list(range(len(Chem.ChiralType.names)-1)))\n",
        "        num_hs = one_hot_encoding(atom.GetTotalNumHs(), list(range(5)))\n",
        "        aromatic = [1 if atom.GetIsAromatic() else 0]\n",
        "\n",
        "        return atom_type + degree + hybrid + chiral + num_hs + aromatic\n",
        "\n",
        "    def _bond_featurizer(self, bond):\n",
        "        bond_type = bond.GetBondType()\n",
        "        bt = [\n",
        "            int(bond_type == rdchem.BondType.SINGLE),\n",
        "            int(bond_type == rdchem.BondType.DOUBLE),\n",
        "            int(bond_type == rdchem.BondType.TRIPLE),\n",
        "            int(bond_type == rdchem.BondType.AROMATIC)\n",
        "        ]\n",
        "        conj = [int(bond.GetIsConjugated()), int(bond.IsInRing())]\n",
        "        return bt + conj\n",
        "\n",
        "    def __call__(self, mol):\n",
        "        # èŠ‚ç‚¹ç‰¹å¾\n",
        "        atom_features = [self._atom_featurizer(atom) for atom in mol.GetAtoms()]\n",
        "        x = torch.tensor(atom_features, dtype=torch.float32)\n",
        "\n",
        "        # è¾¹ç‰¹å¾ä¸ç´¢å¼•\n",
        "        adj = Chem.GetAdjacencyMatrix(mol)\n",
        "        coo_adj = coo_matrix(adj)\n",
        "        row, col = coo_adj.row, coo_adj.col\n",
        "        edge_index = torch.tensor([row, col], dtype=torch.long)\n",
        "\n",
        "        bond_features = []\n",
        "        for i, j in zip(row, col):\n",
        "            bond = mol.GetBondBetweenAtoms(int(i), int(j))\n",
        "            bond_features.append(self._bond_featurizer(bond))\n",
        "\n",
        "        if len(bond_features) > 0:\n",
        "            edge_attr = torch.tensor(bond_features, dtype=torch.float32)\n",
        "        else:\n",
        "            edge_attr = torch.empty((0, 6), dtype=torch.float32)\n",
        "\n",
        "        return {'x': x, 'edge_index': edge_index, 'edge_attr': edge_attr}\n",
        "\n",
        "# ==========================================\n",
        "# 3. æ•°æ®é›†å¤„ç† (è½¬ä¸ºåˆ†ç±»ä»»åŠ¡)\n",
        "# ==========================================\n",
        "class MolClassificationDataset:\n",
        "    def __init__(self, csv_path, threshold=3.0):\n",
        "        self.csv_path = csv_path\n",
        "        self.threshold = threshold # é˜ˆå€¼ï¼š>3 ä¸ºé«˜ç”œ(1)ï¼Œ<=3 ä¸ºä½ç”œ(0)\n",
        "        self.featurizer = MoleculeFeaturizer()\n",
        "        self.data_list = []\n",
        "        self._process()\n",
        "\n",
        "    def _process(self):\n",
        "        df = pd.read_csv(self.csv_path)\n",
        "        print(f\"åŸå§‹æ•°æ®é‡: {len(df)}\")\n",
        "\n",
        "        valid_cnt = 0\n",
        "        high_cnt = 0\n",
        "\n",
        "        for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing\"):\n",
        "            mol = Chem.MolFromSmiles(row['Smiles'])\n",
        "            if mol is None: continue\n",
        "\n",
        "            try:\n",
        "                feats = self.featurizer(mol)\n",
        "                data = Data(x=feats['x'], edge_index=feats['edge_index'], edge_attr=feats['edge_attr'])\n",
        "\n",
        "                # â— å…³é”®ï¼šè½¬æ¢ä¸ºåˆ†ç±»æ ‡ç­¾ â—\n",
        "                raw_val = row['logSw']\n",
        "                label = 1 if raw_val > self.threshold else 0\n",
        "\n",
        "                if label == 1: high_cnt += 1\n",
        "\n",
        "                data.y = torch.tensor([label], dtype=torch.long) # åˆ†ç±»ä»»åŠ¡ç”¨ Long ç±»å‹\n",
        "                data.smiles = row['Smiles']\n",
        "\n",
        "                self.data_list.append(data)\n",
        "                valid_cnt += 1\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        print(f\"å¤„ç†å®Œæˆã€‚æœ‰æ•ˆæ ·æœ¬: {valid_cnt}\")\n",
        "        print(f\"ç±»åˆ«åˆ†å¸ƒ -> é«˜ç”œ(1): {high_cnt}, ä½ç”œ(0): {valid_cnt - high_cnt}\")\n",
        "\n",
        "    def __len__(self): return len(self.data_list)\n",
        "    def __getitem__(self, idx): return self.data_list[idx]\n",
        "\n",
        "# åŠ è½½æ•°æ®\n",
        "dataset_cls = MolClassificationDataset(csv_path='/content/SweetpredDB.csv', threshold=3.0)\n",
        "\n",
        "# åˆ’åˆ†æ•°æ®é›† (8:1:1)\n",
        "train_size = int(0.8 * len(dataset_cls))\n",
        "val_size = int(0.1 * len(dataset_cls))\n",
        "test_size = len(dataset_cls) - train_size - val_size\n",
        "train_ds, val_ds, test_ds = torch.utils.data.random_split(dataset_cls, [train_size, val_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=32)\n",
        "test_loader = DataLoader(test_ds, batch_size=32)\n",
        "\n",
        "# ==========================================\n",
        "# 4. GAT åˆ†ç±»æ¨¡å‹å®šä¹‰\n",
        "# ==========================================\n",
        "class GATClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, heads=2, edge_dim=6, dropout=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        # GAT å±‚ (å¸¦è¾¹ç‰¹å¾)\n",
        "        self.gat1 = GATConv(input_dim, hidden_dim, heads=heads, dropout=dropout, edge_dim=edge_dim)\n",
        "        self.gat2 = GATConv(hidden_dim * heads, hidden_dim, heads=1, dropout=dropout, edge_dim=edge_dim)\n",
        "\n",
        "        # åˆ†ç±» MLP å¤´\n",
        "        # äºŒåˆ†ç±»ä»»åŠ¡ï¼šè¾“å‡ºç»´åº¦å¯ä»¥æ˜¯ 2 (CrossEntropy) æˆ– 1 (BCEWithLogits)\n",
        "        # è¿™é‡Œä½¿ç”¨ 2ï¼Œå¯¹åº” softmax è¾“å‡ºä¸¤ä¸ªç±»åˆ«çš„æ¦‚ç‡\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(32, 2)  # è¾“å‡º [logits_class_0, logits_class_1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, batch, edge_attr):\n",
        "        x = self.gat1(x, edge_index, edge_attr=edge_attr)\n",
        "        x = F.elu(x)\n",
        "        x = self.gat2(x, edge_index, edge_attr=edge_attr)\n",
        "        x = F.elu(x)\n",
        "\n",
        "        # å…¨å±€æ± åŒ–\n",
        "        x = global_mean_pool(x, batch)\n",
        "\n",
        "        # MLP åˆ†ç±»\n",
        "        logits = self.mlp(x)\n",
        "        return logits\n",
        "\n",
        "# åˆå§‹åŒ–æ¨¡å‹\n",
        "input_dim = dataset_cls[0].x.shape[1] # 69\n",
        "model = GATClassifier(input_dim=input_dim, hidden_dim=16, heads=2, edge_dim=6, dropout=0.4).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-3)\n",
        "criterion = nn.CrossEntropyLoss() # è‡ªåŠ¨å¤„ç† softmax\n",
        "\n",
        "# ==========================================\n",
        "# 5. è®­ç»ƒä¸è¯„ä¼°æµç¨‹\n",
        "# ==========================================\n",
        "def train_epoch():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch.x, batch.edge_index, batch.batch, batch.edge_attr)\n",
        "        loss = criterion(out, batch.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * batch.num_graphs\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += (pred == batch.y).sum().item()\n",
        "        total += batch.num_graphs\n",
        "    return total_loss / total, correct / total\n",
        "\n",
        "def eval_epoch(loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    preds_all, labels_all, probs_all = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            out = model(batch.x, batch.edge_index, batch.batch, batch.edge_attr)\n",
        "            loss = criterion(out, batch.y)\n",
        "\n",
        "            total_loss += loss.item() * batch.num_graphs\n",
        "            pred = out.argmax(dim=1)\n",
        "            prob = F.softmax(out, dim=1)[:, 1] # è·å–â€œé«˜ç”œâ€ç±»çš„æ¦‚ç‡\n",
        "\n",
        "            correct += (pred == batch.y).sum().item()\n",
        "            total += batch.num_graphs\n",
        "\n",
        "            preds_all.extend(pred.cpu().numpy())\n",
        "            labels_all.extend(batch.y.cpu().numpy())\n",
        "            probs_all.extend(prob.cpu().numpy())\n",
        "\n",
        "    return total_loss / total, correct / total, labels_all, preds_all, probs_all\n",
        "\n",
        "# --- å¼€å§‹è®­ç»ƒ ---\n",
        "epochs = 100\n",
        "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "best_val_acc = 0\n",
        "\n",
        "print(\"ğŸš€ å¼€å§‹åˆ†ç±»ä»»åŠ¡è®­ç»ƒ...\")\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    t_loss, t_acc = train_epoch()\n",
        "    v_loss, v_acc, _, _, _ = eval_epoch(val_loader)\n",
        "\n",
        "    history['train_loss'].append(t_loss)\n",
        "    history['train_acc'].append(t_acc)\n",
        "    history['val_loss'].append(v_loss)\n",
        "    history['val_acc'].append(v_acc)\n",
        "\n",
        "    if v_acc > best_val_acc:\n",
        "        best_val_acc = v_acc\n",
        "        torch.save(model.state_dict(), \"Best_GAT_Classifier.pt\")\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch:03d} | Train Loss: {t_loss:.4f} Acc: {t_acc:.4f} | Val Loss: {v_loss:.4f} Acc: {v_acc:.4f}\")\n",
        "\n",
        "# ==========================================\n",
        "# 6. å¯è§†åŒ–è¯„ä¼°ç»“æœ\n",
        "# ==========================================\n",
        "# åŠ è½½æœ€ä½³æ¨¡å‹å¹¶åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°\n",
        "model.load_state_dict(torch.load(\"Best_GAT_Classifier.pt\"))\n",
        "test_loss, test_acc, y_true, y_pred, y_prob = eval_epoch(test_loader)\n",
        "\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(f\"æœ€ç»ˆæµ‹è¯•é›†å‡†ç¡®ç‡: {test_acc:.4f}\")\n",
        "print(\"=\"*30)\n",
        "print(\"\\nåˆ†ç±»æŠ¥å‘Š:\")\n",
        "print(classification_report(y_true, y_pred, target_names=['Low Sweetness', 'High Sweetness']))\n",
        "\n",
        "# --- ç»˜å›¾ ---\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "# 1. æŸå¤±æ›²çº¿\n",
        "axes[0,0].plot(history['train_loss'], label='Train Loss', color='#4c72b0')\n",
        "axes[0,0].plot(history['val_loss'], label='Val Loss', color='#c44e52', linestyle='--')\n",
        "axes[0,0].set_title('Loss Curve')\n",
        "axes[0,0].legend()\n",
        "\n",
        "# 2. å‡†ç¡®ç‡æ›²çº¿\n",
        "axes[0,1].plot(history['train_acc'], label='Train Acc', color='#55a868')\n",
        "axes[0,1].plot(history['val_acc'], label='Val Acc', color='#8172b3', linestyle='--')\n",
        "axes[0,1].set_title('Accuracy Curve')\n",
        "axes[0,1].legend()\n",
        "\n",
        "# 3. æ··æ·†çŸ©é˜µ\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1,0],\n",
        "            xticklabels=['Low', 'High'], yticklabels=['Low', 'High'])\n",
        "axes[1,0].set_xlabel('Predicted')\n",
        "axes[1,0].set_ylabel('Actual')\n",
        "axes[1,0].set_title('Confusion Matrix (Test Set)')\n",
        "\n",
        "# 4. ROC æ›²çº¿\n",
        "fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "axes[1,1].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "axes[1,1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "axes[1,1].set_xlim([0.0, 1.0])\n",
        "axes[1,1].set_ylim([0.0, 1.05])\n",
        "axes[1,1].set_xlabel('False Positive Rate')\n",
        "axes[1,1].set_ylabel('True Positive Rate')\n",
        "axes[1,1].set_title('ROC Curve')\n",
        "axes[1,1].legend(loc=\"lower right\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3mbLON0EvB7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¿™æ®µä»£ç å±•ç¤ºäº†ä¸€ä¸ªåŸºäºå›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGATï¼‰çš„**äºŒåˆ†ç±»æ¨¡å‹**ï¼Œç”¨äºé¢„æµ‹åˆ†å­æ˜¯â€œé«˜ç”œâ€è¿˜æ˜¯â€œä½ç”œâ€ã€‚\n",
        "\n",
        "ä»¥ä¸‹æ˜¯é’ˆå¯¹ä»£ç é€»è¾‘ã€åˆ†ç±»å®ç°ç»†èŠ‚ä»¥åŠä¸å›å½’ä»»åŠ¡åŒºåˆ«çš„è¯¦ç»†è§£é‡Šã€‚\n",
        "\n",
        "\n",
        "#### 1\\. GATClassifier æ¨¡å‹æ¶æ„ï¼šå¦‚ä½•å®ç°åˆ†ç±»ï¼Ÿ\n",
        "\n",
        "è¿™ä¸ªæ¨¡å‹çš„æ ¸å¿ƒç»“æ„ä¸å›å½’æ¨¡å‹éå¸¸ç›¸ä¼¼ï¼Œ**æœ€å…³é”®çš„åŒºåˆ«åœ¨äºæœ€åä¸€å±‚ MLP çš„è¾“å‡ºç»´åº¦**ã€‚\n",
        "\n",
        "  * **å›å½’ä»»åŠ¡ (Regression)**ï¼š\n",
        "\n",
        "      * ç›®æ ‡æ˜¯é¢„æµ‹ä¸€ä¸ªè¿ç»­çš„å®æ•°å€¼ï¼ˆå¦‚ç”œåº¦å€¼ `logSw`ï¼‰ã€‚\n",
        "      * è¾“å‡ºå±‚é€šå¸¸æ˜¯ `nn.Linear(hidden_dim, 1)`ã€‚\n",
        "      * è¾“å‡ºç»“æœç›´æ¥å°±æ˜¯é¢„æµ‹å€¼ï¼ˆä¾‹å¦‚ 3.45ï¼‰ã€‚\n",
        "\n",
        "  * **åˆ†ç±»ä»»åŠ¡ (Classification)**ï¼š\n",
        "\n",
        "      * ç›®æ ‡æ˜¯é¢„æµ‹æ ·æœ¬å±äºå“ªä¸€ä¸ªç±»åˆ«ï¼ˆ0: ä½ç”œ, 1: é«˜ç”œï¼‰ã€‚\n",
        "      * **ä»£ç å®ç°**ï¼š\n",
        "        ```python\n",
        "        nn.Linear(32, 2)  # è¾“å‡ºç»´åº¦ä¸º 2\n",
        "        ```\n",
        "      * **å«ä¹‰**ï¼šè¾“å‡ºä¸€ä¸ªå½¢çŠ¶ä¸º `[Batch_Size, 2]` çš„å¼ é‡ã€‚å¯¹äºæ¯ä¸€ä¸ªåˆ†å­ï¼Œæ¨¡å‹è¾“å‡ºä¸¤ä¸ªåˆ†æ•°ï¼ˆLogitsï¼‰ï¼š\n",
        "          * ç¬¬ 0 ä¸ªæ•°å­—ï¼šåˆ†å­å±äºâ€œä½ç”œâ€ç±»åˆ«çš„å¾—åˆ†ã€‚\n",
        "          * ç¬¬ 1 ä¸ªæ•°å­—ï¼šåˆ†å­å±äºâ€œé«˜ç”œâ€ç±»åˆ«çš„å¾—åˆ†ã€‚\n",
        "\n",
        "-----\n",
        "\n",
        "#### 2\\. `criterion` æ˜¯ä»€ä¹ˆï¼Ÿ\n",
        "\n",
        "åœ¨ PyTorch çš„åˆ†ç±»ä»»åŠ¡è®­ç»ƒå¾ªç¯ä¸­ï¼Œ`criterion` é€šå¸¸ä»£è¡¨**æŸå¤±å‡½æ•° (Loss Function)**ã€‚\n",
        "\n",
        "  * **åœ¨æœ¬ä»£ç çš„ä¸Šä¸‹æ–‡ä¸­**ï¼š`criterion` æŒ‡çš„æ˜¯ **`nn.CrossEntropyLoss()`**ï¼ˆäº¤å‰ç†µæŸå¤±ï¼‰ã€‚\n",
        "  * **å®ƒçš„ä½œç”¨**ï¼š\n",
        "    1.  å®ƒæ¥æ”¶æ¨¡å‹çš„åŸå§‹è¾“å‡º `out`ï¼ˆåŒ…å«ä¸¤ä¸ªåˆ†æ•°çš„ Logitsï¼‰ã€‚\n",
        "    2.  å®ƒæ¥æ”¶çœŸå®çš„æ ‡ç­¾ `batch.y`ï¼ˆ0 æˆ– 1ï¼‰ã€‚\n",
        "    3.  å®ƒå†…éƒ¨ä¼šè‡ªåŠ¨å…ˆå¯¹ `out` åš Softmax æ“ä½œï¼Œè®¡ç®—å‡ºæ¦‚ç‡åˆ†å¸ƒï¼Œç„¶åè®¡ç®—é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒä¸çœŸå®æ ‡ç­¾ä¹‹é—´çš„è·ç¦»ï¼ˆæŸå¤±ï¼‰ã€‚\n",
        "  * **ä¸å›å½’çš„åŒºåˆ«**ï¼šå›å½’ä»»åŠ¡é€šå¸¸ä½¿ç”¨ `nn.MSELoss()`ï¼ˆå‡æ–¹è¯¯å·®æŸå¤±ï¼‰ã€‚\n",
        "\n",
        "-----\n",
        "\n",
        "#### 3\\. `out.argmax(dim=1)` æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ\n",
        "\n",
        "è¿™è¡Œä»£ç ç”¨äº**è·å–æœ€ç»ˆçš„é¢„æµ‹ç±»åˆ«æ ‡ç­¾**ï¼ˆç¡¬åˆ†ç±»ï¼‰ã€‚\n",
        "\n",
        "  * **`out` çš„æ•°æ®æ ·å­**ï¼šå‡è®¾ä¸€ä¸ª Batch æœ‰ 3 ä¸ªåˆ†å­ï¼Œæ¨¡å‹è¾“å‡ºå¦‚ä¸‹ï¼š\n",
        "    ```text\n",
        "    [[2.1, 0.5],   # åˆ†å­1: ä½ç”œåˆ†æ›´é«˜ -> é¢„æµ‹ 0\n",
        "     [-1.0, 3.2],  # åˆ†å­2: é«˜ç”œåˆ†æ›´é«˜ -> é¢„æµ‹ 1\n",
        "     [0.8, 0.9]]   # åˆ†å­3: é«˜ç”œåˆ†ç¨é«˜ -> é¢„æµ‹ 1\n",
        "    ```\n",
        "  * **`argmax(dim=1)`**ï¼š\n",
        "      * `dim=1` è¡¨ç¤ºåœ¨â€œåˆ—â€çš„æ–¹å‘ï¼ˆç±»åˆ«åˆ†æ•°ï¼‰ä¸Šè¿›è¡Œæ¯”è¾ƒã€‚\n",
        "      * å®ƒä¼šè¿”å›**æœ€å¤§å€¼çš„ç´¢å¼•**ã€‚\n",
        "  * **ç»“æœ**ï¼š\n",
        "      * åˆ†å­1ï¼š2.1 \\> 0.5ï¼Œæœ€å¤§å€¼ç´¢å¼•æ˜¯ **0**ã€‚\n",
        "      * åˆ†å­2ï¼š3.2 \\> -1.0ï¼Œæœ€å¤§å€¼ç´¢å¼•æ˜¯ **1**ã€‚\n",
        "      * åˆ†å­3ï¼š0.9 \\> 0.8ï¼Œæœ€å¤§å€¼ç´¢å¼•æ˜¯ **1**ã€‚\n",
        "      * æœ€ç»ˆå¾—åˆ° `pred = [0, 1, 1]`ã€‚\n",
        "\n",
        "-----\n",
        "\n",
        "#### 4\\. `prob = F.softmax(out, dim=1)[:, 1]` æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ\n",
        "\n",
        "è¿™è¡Œä»£ç ç”¨äº**è·å–åˆ†å­å±äºâ€œé«˜ç”œâ€ç±»åˆ«çš„æ¦‚ç‡**ï¼ˆè½¯åˆ†ç±»ï¼‰ï¼Œé€šå¸¸ç”¨äºç»˜åˆ¶ ROC æ›²çº¿æˆ–è®¡ç®— AUCã€‚\n",
        "\n",
        "1.  **`F.softmax(out, dim=1)`**ï¼š\n",
        "\n",
        "      * æ¨¡å‹çš„åŸå§‹è¾“å‡ºï¼ˆLogitsï¼‰èŒƒå›´æ˜¯ $(-\\infty, +\\infty)$ï¼Œä¸ç›´è§‚ã€‚\n",
        "      * Softmax å°†è¿™äº›åˆ†æ•°å‹ç¼©åˆ° $(0, 1)$ ä¹‹é—´ï¼Œå¹¶ä¸”ä¸¤ä¸ªç±»åˆ«çš„æ¦‚ç‡ä¹‹å’Œä¸º 1ã€‚\n",
        "      * *ç¤ºä¾‹å˜æ¢*ï¼š`[2.1, 0.5]` -\\> Softmax -\\> `[0.83, 0.17]`ï¼ˆå³ 83% æ˜¯ä½ç”œï¼Œ17% æ˜¯é«˜ç”œï¼‰ã€‚\n",
        "\n",
        "2.  **`[:, 1]`**ï¼š\n",
        "\n",
        "      * è¿™æ˜¯ä¸€ä¸ªåˆ‡ç‰‡æ“ä½œã€‚\n",
        "      * `:` è¡¨ç¤ºå–æ‰€æœ‰æ ·æœ¬ï¼ˆè¡Œï¼‰ã€‚\n",
        "      * `1` è¡¨ç¤ºåªå–ç¬¬ 1 åˆ—çš„æ•°æ®ï¼ˆå³**ç±»åˆ« 1 / é«˜ç”œ**çš„æ¦‚ç‡ï¼‰ã€‚\n",
        "      * *ç»“æœ*ï¼šæˆ‘ä»¬åªå…³å¿ƒæ¨¡å‹è®¤ä¸ºå®ƒæ˜¯â€œé«˜ç”œâ€çš„æ¦‚ç‡æ˜¯å¤šå°‘ã€‚\n",
        "\n",
        "-----\n",
        "\n",
        "#### 5\\. æ€»ç»“ï¼šåˆ†ç±» vs å›å½’ çš„ä»£ç å·®å¼‚å¯¹ç…§è¡¨\n",
        "\n",
        "| ç‰¹æ€§ | å›å½’ä»»åŠ¡ (Regression) | åˆ†ç±»ä»»åŠ¡ (Classification) |\n",
        "| :--- | :--- | :--- |\n",
        "| **MLP è¾“å‡ºå±‚** | `nn.Linear(..., 1)` | `nn.Linear(..., 2)` (äºŒåˆ†ç±») |\n",
        "| **è¾“å‡ºå«ä¹‰** | å…·ä½“çš„æ•°å€¼ (å¦‚ç”œåº¦å€¼ 4.5) | å±äºå„ç±»åˆ«çš„â€œå¾—åˆ†â€ (Logits) |\n",
        "| **æ ‡ç­¾æ•°æ®ç±»å‹** | `torch.float32` (æµ®ç‚¹æ•°) | `torch.long` (æ•´æ•°ç´¢å¼• 0, 1) |\n",
        "| **æŸå¤±å‡½æ•°** | `MSELoss` / `L1Loss` | `CrossEntropyLoss` |\n",
        "| **è·å–é¢„æµ‹ç»“æœ** | ç›´æ¥å–è¾“å‡ºå€¼ `out` | `out.argmax(dim=1)` (å–åˆ†æ•°æœ€é«˜çš„ç±»åˆ«) |\n",
        "| **è¯„ä¼°æŒ‡æ ‡** | MSE, RMSE, RÂ² | Accuracy, AUC, F1-score, Confusion Matrix |"
      ],
      "metadata": {
        "id": "7usQlkOizsQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **å°åˆ†å­ä»»åŠ¡â€”â€”åŸºäºGNNçš„è¯ç‰©è¯ç‰©ç›¸äº’ä½œç”¨é¢„æµ‹-å›¾çº§åˆ«ä»»åŠ¡**"
      ],
      "metadata": {
        "id": "FaWefAtTuDK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data, Batch\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import rdchem\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from scipy.sparse import coo_matrix\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    roc_curve,\n",
        "    precision_recall_curve,\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# ==========================================\n",
        "# 1. åˆ†å­ç‰¹å¾æå–å™¨ (Featurizer)\n",
        "# ==========================================\n",
        "# è¾…åŠ©å‡½æ•°ï¼šOne-hotç¼–ç \n",
        "def one_hot_encoding(value, choices):\n",
        "    encoding = [0] * (len(choices) + 1)\n",
        "    index = choices.index(value) if value in choices else -1\n",
        "    encoding[index] = 1\n",
        "    return encoding\n",
        "\n",
        "class MoleculeFeaturizer(object):\n",
        "    \"\"\"\n",
        "    å°†RDKitåˆ†å­å¯¹è±¡è½¬æ¢ä¸ºPyGå›¾æ•°æ® (Dataå¯¹è±¡)\n",
        "    åŒ…å«èŠ‚ç‚¹ç‰¹å¾(69ç»´) å’Œ è¾¹ç‰¹å¾(6ç»´)\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def _atom_featurizer(self, atom):\n",
        "        # 37ç§åŸå­ç±»å‹ + 1ç§å…¶ä»–\n",
        "        atomic_numer = [1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 28, 29,\n",
        "                        30, 31, 32, 33, 34, 35, 36, 37, 38, 46, 47, 48, 49, 50, 51, 52, 53]\n",
        "        atom_type = one_hot_encoding(atom.GetAtomicNum(), atomic_numer)\n",
        "\n",
        "        degree = one_hot_encoding(atom.GetTotalDegree(), list(range(5)))\n",
        "        hybrid = one_hot_encoding(int(atom.GetHybridization()), list(range(len(Chem.HybridizationType.names)-1)))\n",
        "        chiral = one_hot_encoding(atom.GetChiralTag(), list(range(len(Chem.ChiralType.names)-1)))\n",
        "        num_hs = one_hot_encoding(atom.GetTotalNumHs(), list(range(5)))\n",
        "        aromatic = [1 if atom.GetIsAromatic() else 0]\n",
        "\n",
        "        return atom_type + degree + hybrid + chiral + num_hs + aromatic\n",
        "\n",
        "    def _bond_featurizer(self, bond):\n",
        "        bond_type = bond.GetBondType()\n",
        "        bt = [\n",
        "            int(bond_type == rdchem.BondType.SINGLE),\n",
        "            int(bond_type == rdchem.BondType.DOUBLE),\n",
        "            int(bond_type == rdchem.BondType.TRIPLE),\n",
        "            int(bond_type == rdchem.BondType.AROMATIC)\n",
        "        ]\n",
        "        conj = [int(bond.GetIsConjugated()), int(bond.IsInRing())]\n",
        "        return bt + conj\n",
        "\n",
        "    def __call__(self, mol):\n",
        "        # 1. èŠ‚ç‚¹ç‰¹å¾ (Node Features)\n",
        "        atom_features = [self._atom_featurizer(atom) for atom in mol.GetAtoms()]\n",
        "        x = torch.tensor(atom_features, dtype=torch.float32)\n",
        "\n",
        "        # 2. è¾¹ç´¢å¼•ä¸è¾¹ç‰¹å¾ (Edge Index & Attributes)\n",
        "        adj = Chem.GetAdjacencyMatrix(mol)\n",
        "        coo_adj = coo_matrix(adj)\n",
        "        row, col = coo_adj.row, coo_adj.col\n",
        "        edge_index = torch.tensor([row, col], dtype=torch.long)\n",
        "\n",
        "        bond_features = []\n",
        "        for i, j in zip(row, col):\n",
        "            bond = mol.GetBondBetweenAtoms(int(i), int(j))\n",
        "            bond_features.append(self._bond_featurizer(bond))\n",
        "\n",
        "        if len(bond_features) > 0:\n",
        "            edge_attr = torch.tensor(bond_features, dtype=torch.float32)\n",
        "        else:\n",
        "            # å¦‚æœæ²¡æœ‰è¾¹ï¼Œæä¾›ç©ºçš„å ä½ç¬¦\n",
        "            edge_attr = torch.empty((0, 6), dtype=torch.float32)\n",
        "\n",
        "        return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "\n",
        "# ==========================================\n",
        "# 2. DDI æ•°æ®é›†ä¸ DataLoader\n",
        "# ==========================================\n",
        "class DDIDataset:\n",
        "    def __init__(self, csv_path, sample_ratio=0.1, seed=42):\n",
        "        self.data_list = []\n",
        "        self.featurizer = MoleculeFeaturizer()\n",
        "\n",
        "        print(f\"æ­£åœ¨åŠ è½½å¹¶å¤„ç†æ•°æ®: {csv_path} ...\")\n",
        "        df = pd.read_csv(csv_path)\n",
        "\n",
        "        # â­â­â­ åªéšæœºé€‰å–éƒ¨åˆ†æ•°æ®\n",
        "        df = df.sample(frac=sample_ratio, random_state=seed).reset_index(drop=True)\n",
        "        print(f\"âš ï¸ å·²æŠ½å– {sample_ratio*100:.0f}% æ ·æœ¬ç”¨äºè®­ç»ƒï¼Œå…± {len(df)} æ¡æ•°æ®\")\n",
        "\n",
        "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing DDI Pairs\"):\n",
        "            s1, s2, label = row['smiles_1'], row['smiles_2'], row['label']\n",
        "\n",
        "            mol1 = Chem.MolFromSmiles(s1)\n",
        "            mol2 = Chem.MolFromSmiles(s2)\n",
        "\n",
        "            if mol1 is None or mol2 is None:\n",
        "                continue\n",
        "\n",
        "            data1 = self.featurizer(mol1)\n",
        "            data2 = self.featurizer(mol2)\n",
        "            y = torch.tensor([label], dtype=torch.float32)\n",
        "\n",
        "            self.data_list.append((data1, data2, y))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data_list[idx]\n",
        "\n",
        "# è‡ªå®šä¹‰ Collate å‡½æ•°ï¼šç”¨äºå°†æˆå¯¹çš„å›¾æ‰“åŒ…æˆ Batch\n",
        "def collate_ddi_pairs(batch):\n",
        "    data1_list = [item[0] for item in batch]\n",
        "    data2_list = [item[1] for item in batch]\n",
        "    labels = [item[2] for item in batch]\n",
        "\n",
        "    # å°†å›¾åˆ—è¡¨è½¬æ¢ä¸ºPyGçš„å¤§å›¾Batch\n",
        "    batch1 = Batch.from_data_list(data1_list)\n",
        "    batch2 = Batch.from_data_list(data2_list)\n",
        "    labels = torch.stack(labels)\n",
        "\n",
        "    return batch1, batch2, labels\n",
        "\n",
        "# ==========================================\n",
        "# 3. GAT Siamese æ¨¡å‹æ¶æ„\n",
        "# ==========================================\n",
        "class GATEncoder(nn.Module):\n",
        "    \"\"\"å…±äº«æƒé‡çš„å›¾ç¼–ç å™¨\"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim, heads=2, edge_dim=6, dropout=0.2):\n",
        "        super().__init__()\n",
        "        # ç¬¬ä¸€å±‚ GAT\n",
        "        self.gat1 = GATConv(input_dim, hidden_dim, heads=heads, dropout=dropout, edge_dim=edge_dim)\n",
        "        # ç¬¬äºŒå±‚ GAT\n",
        "        self.gat2 = GATConv(hidden_dim * heads, hidden_dim, heads=1, dropout=dropout, edge_dim=edge_dim)\n",
        "\n",
        "    def forward(self, x, edge_index, batch, edge_attr):\n",
        "        x = self.gat1(x, edge_index, edge_attr=edge_attr)\n",
        "        x = F.elu(x)\n",
        "        x = self.gat2(x, edge_index, edge_attr=edge_attr)\n",
        "        x = F.elu(x)\n",
        "        # å…¨å±€æ± åŒ–å¾—åˆ°å›¾åµŒå…¥\n",
        "        x = global_mean_pool(x, batch)\n",
        "        return x\n",
        "\n",
        "class DDIPredictor(nn.Module):\n",
        "    \"\"\"DDI é¢„æµ‹ä¸»æ¨¡å‹\"\"\"\n",
        "    def __init__(self, input_dim=69, hidden_dim=64, heads=2, edge_dim=6):\n",
        "        super().__init__()\n",
        "        # ç¼–ç å™¨ (ç”¨äºæå–åˆ†å­ç‰¹å¾)\n",
        "        self.encoder = GATEncoder(input_dim, hidden_dim, heads, edge_dim)\n",
        "\n",
        "        # é¢„æµ‹å¤´ (MLP)\n",
        "        # è¾“å…¥ç»´åº¦æ˜¯ hidden_dim * 2ï¼Œå› ä¸ºæ‹¼æ¥äº†ä¸¤ä¸ªè¯ç‰©çš„ç‰¹å¾\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, 1)  # äºŒåˆ†ç±»è¾“å‡ºä¸€ä¸ª Logit\n",
        "        )\n",
        "\n",
        "    def forward(self, batch1, batch2):\n",
        "        # åˆ†åˆ«ç¼–ç ä¸¤ä¸ªè¯ç‰©\n",
        "        emb1 = self.encoder(batch1.x, batch1.edge_index, batch1.batch, batch1.edge_attr)\n",
        "        emb2 = self.encoder(batch2.x, batch2.edge_index, batch2.batch, batch2.edge_attr)\n",
        "\n",
        "        # æ‹¼æ¥ç‰¹å¾\n",
        "        combined = torch.cat([emb1, emb2], dim=1)\n",
        "\n",
        "        # é¢„æµ‹\n",
        "        logits = self.mlp(combined)\n",
        "        return logits\n",
        "\n",
        "# ==========================================\n",
        "# 4. è¯„ä¼°å‡½æ•°\n",
        "# ==========================================\n",
        "def evaluate(model, loader, device, return_details=False):\n",
        "    \"\"\"\n",
        "    return_details=False: åªè¿”å› acc, auc\n",
        "    return_details=True:  è¿”å› acc, auc, y_true, y_scores\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for b1, b2, y in loader:\n",
        "            b1, b2, y = b1.to(device), b2.to(device), y.to(device)\n",
        "            logits = model(b1, b2)\n",
        "            probs = torch.sigmoid(logits)  # [B,1]\n",
        "\n",
        "            # å±•å¹³åå†æ”¶é›†ï¼Œé˜²æ­¢å¤šä¸€ç»´\n",
        "            all_preds.extend(probs.cpu().view(-1).numpy())\n",
        "            all_labels.extend(y.cpu().view(-1).numpy())\n",
        "\n",
        "    # è®¡ç®—æŒ‡æ ‡\n",
        "    y_true = np.array(all_labels)\n",
        "    y_scores = np.array(all_preds)\n",
        "    y_pred_cls = (y_scores > 0.5).astype(int)\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred_cls)\n",
        "    try:\n",
        "        auc = roc_auc_score(y_true, y_scores)\n",
        "    except:\n",
        "        auc = 0.5  # é˜²æ­¢å•ç±»åˆ«æŠ¥é”™\n",
        "\n",
        "    if return_details:\n",
        "        return acc, auc, y_true, y_scores\n",
        "    else:\n",
        "        return acc, auc\n",
        "\n",
        "# ==========================================\n",
        "# 5. è®­ç»ƒä¸ç»˜å›¾è„šæœ¬\n",
        "# ==========================================\n",
        "def train_ddi_model():\n",
        "    # è®¾ç½®è®¾å¤‡\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # 1. åŠ è½½æ•°æ®é›†\n",
        "    dataset = DDIDataset('DDI_balanced.csv')\n",
        "\n",
        "    # 2. åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›† (8:2)\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    test_size = len(dataset) - train_size\n",
        "    train_ds, test_ds = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "    # 3. åˆ›å»º DataLoader (æ³¨æ„ä½¿ç”¨è‡ªå®šä¹‰çš„ collate_fn)\n",
        "    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, collate_fn=collate_ddi_pairs)\n",
        "    test_loader = DataLoader(test_ds, batch_size=64, shuffle=False, collate_fn=collate_ddi_pairs)\n",
        "\n",
        "    # 4. åˆå§‹åŒ–æ¨¡å‹\n",
        "    model = DDIPredictor(input_dim=69, hidden_dim=64).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.BCEWithLogitsLoss()  # ç»“åˆäº† Sigmoid å’Œ BCELossï¼Œæ•°å€¼æ›´ç¨³å®š\n",
        "\n",
        "    # 5. è®­ç»ƒå¾ªç¯\n",
        "    epochs = 20\n",
        "    print(\"å¼€å§‹è®­ç»ƒ...\")\n",
        "\n",
        "    train_losses = []\n",
        "    test_accs = []\n",
        "    test_aucs = []\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for b1, b2, y in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\"):\n",
        "            b1, b2, y = b1.to(device), b2.to(device), y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(b1, b2)\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        train_losses.append(avg_loss)\n",
        "\n",
        "        # æ¯ä¸ª Epoch è¿›è¡Œè¯„ä¼°\n",
        "        acc, auc = evaluate(model, test_loader, device)\n",
        "        test_accs.append(acc)\n",
        "        test_aucs.append(auc)\n",
        "\n",
        "        print(f\"Epoch {epoch}: Train Loss = {avg_loss:.4f}, Test Acc = {acc:.4f}, Test AUC = {auc:.4f}\")\n",
        "\n",
        "    # 6. è®­ç»ƒå®Œæˆåå†åšä¸€æ¬¡è¯¦ç»†è¯„ä¼°ï¼ˆç”¨äºç”»ROC/PRæ›²çº¿ï¼‰\n",
        "    final_acc, final_auc, y_true, y_scores = evaluate(model, test_loader, device, return_details=True)\n",
        "    ap = average_precision_score(y_true, y_scores)\n",
        "    print(f\"Final Test Acc = {final_acc:.4f}, AUC = {final_auc:.4f}, AP = {ap:.4f}\")\n",
        "\n",
        "    # 7. ç»˜åˆ¶è®­ç»ƒè¿‡ç¨‹æ›²çº¿\n",
        "    epochs_range = range(1, epochs + 1)\n",
        "\n",
        "    # (1) Loss æ›²çº¿\n",
        "    plt.figure()\n",
        "    plt.plot(epochs_range, train_losses, marker='o')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Train Loss\")\n",
        "    plt.title(\"Training Loss Curve\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"loss_curve.png\", dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # (2) æµ‹è¯•é›† Acc & AUC æ›²çº¿\n",
        "    plt.figure()\n",
        "    plt.plot(epochs_range, test_accs, marker='o', label=\"Test Accuracy\")\n",
        "    plt.plot(epochs_range, test_aucs, marker='s', label=\"Test AUC\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Metric Value\")\n",
        "    plt.title(\"Test Accuracy & AUC over Epochs\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"metrics_curve.png\", dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # (3) ROC & PR æ›²çº¿\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f\"ROC (AUC={final_auc:.3f})\")\n",
        "    plt.plot([0, 1], [0, 1], linestyle=\"--\", label=\"Random\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"ROC Curve\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"roc_curve.png\", dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(recall, precision, label=f\"PR (AP={ap:.3f})\")\n",
        "    plt.xlabel(\"Recall\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.title(\"Precision-Recall Curve\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"pr_curve.png\", dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # 8. ä¿å­˜æ¨¡å‹\n",
        "    torch.save(model.state_dict(), \"DDI_GAT_Model.pt\")\n",
        "    print(\"æ¨¡å‹å·²ä¿å­˜ä¸º DDI_GAT_Model.pt\")\n",
        "    print(\"Loss æ›²çº¿å·²ä¿å­˜ä¸º loss_curve.png\")\n",
        "    print(\"Acc/AUC æ›²çº¿å·²ä¿å­˜ä¸º metrics_curve.png\")\n",
        "    print(\"ROC æ›²çº¿å·²ä¿å­˜ä¸º roc_curve.png\")\n",
        "    print(\"PR æ›²çº¿å·²ä¿å­˜ä¸º pr_curve.png\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # ç¡®ä¿å½“å‰ç›®å½•ä¸‹æœ‰ 'DDI_balanced.csv'\n",
        "    if os.path.exists('DDI_balanced.csv'):\n",
        "        train_ddi_model()\n",
        "    else:\n",
        "        print(\"æœªæ‰¾åˆ° DDI_balanced.csv æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®å¹³è¡¡ä»£ç ã€‚\")\n"
      ],
      "metadata": {
        "id": "3uc6uxfM0vG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **å°åˆ†å­ä»»åŠ¡â€”â€”åŸºäºGNNçš„R/S E/Zé¢„æµ‹-èŠ‚ç‚¹å’Œè¾¹çº§åˆ«ä»»åŠ¡**"
      ],
      "metadata": {
        "id": "VNaefqfn7vPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GATConv\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import rdchem\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from scipy.sparse import coo_matrix\n",
        "\n",
        "# 1. åŸºç¡€é…ç½®\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "seed_everything()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "# 2. è¾…åŠ©å‡½æ•°\n",
        "def one_hot_encoding(value, choices):\n",
        "    encoding = [0] * (len(choices) + 1)\n",
        "    index = choices.index(value) if value in choices else -1\n",
        "    encoding[index] = 1\n",
        "    return encoding\n",
        "\n",
        "# 3. ç‰¹å¾æå–å™¨\n",
        "class RS_Featurizer(object):\n",
        "    def __call__(self, mol):\n",
        "        labels, mask = [], []\n",
        "        chiral_centers = Chem.FindMolChiralCenters(mol, includeUnassigned=False)\n",
        "        center_dict = {idx: type for idx, type in chiral_centers}\n",
        "\n",
        "        for atom in mol.GetAtoms():\n",
        "            idx = atom.GetIdx()\n",
        "            if idx in center_dict:\n",
        "                stereo = center_dict[idx]\n",
        "                if stereo == 'R': labels.append(0); mask.append(1)\n",
        "                elif stereo == 'S': labels.append(1); mask.append(1)\n",
        "                else: labels.append(2); mask.append(0)\n",
        "            else:\n",
        "                labels.append(2); mask.append(0)\n",
        "\n",
        "        atom_features = []\n",
        "        for atom in mol.GetAtoms():\n",
        "            f = one_hot_encoding(atom.GetAtomicNum(), [1, 5, 6, 7, 8, 9, 15, 16, 17, 35, 53]) + \\\n",
        "                one_hot_encoding(atom.GetTotalDegree(), [0, 1, 2, 3, 4]) + \\\n",
        "                one_hot_encoding(int(atom.GetHybridization()), [2, 3, 4]) + \\\n",
        "                one_hot_encoding(atom.GetTotalNumHs(), [0, 1, 2, 3, 4])\n",
        "            atom_features.append(f)\n",
        "\n",
        "        x = torch.tensor(atom_features, dtype=torch.float32)\n",
        "        y = torch.tensor(labels, dtype=torch.long)\n",
        "        train_mask = torch.tensor(mask, dtype=torch.bool)\n",
        "\n",
        "        adj = Chem.GetAdjacencyMatrix(mol)\n",
        "        coo_adj = coo_matrix(adj)\n",
        "        edge_index = torch.tensor([coo_adj.row, coo_adj.col], dtype=torch.long)\n",
        "\n",
        "        bond_feats = []\n",
        "        for i, j in zip(coo_adj.row, coo_adj.col):\n",
        "            bond = mol.GetBondBetweenAtoms(int(i), int(j))\n",
        "            bt = bond.GetBondType()\n",
        "            f = [int(bt == t) for t in [rdchem.BondType.SINGLE, rdchem.BondType.DOUBLE,\n",
        "                                        rdchem.BondType.TRIPLE, rdchem.BondType.AROMATIC]]\n",
        "            bond_feats.append(f)\n",
        "        edge_attr = torch.tensor(bond_feats, dtype=torch.float32)\n",
        "\n",
        "        return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y, train_mask=train_mask)\n",
        "\n",
        "class EZ_Featurizer(object):\n",
        "    def __call__(self, mol):\n",
        "        atom_features = []\n",
        "        for atom in mol.GetAtoms():\n",
        "             f = one_hot_encoding(atom.GetAtomicNum(), [1, 6, 7, 8, 9, 15, 16, 17]) + \\\n",
        "                 one_hot_encoding(atom.GetTotalDegree(), [0, 1, 2, 3])\n",
        "             atom_features.append(f)\n",
        "        x = torch.tensor(atom_features, dtype=torch.float32)\n",
        "\n",
        "        adj = Chem.GetAdjacencyMatrix(mol)\n",
        "        coo_adj = coo_matrix(adj)\n",
        "        edge_index = torch.tensor([coo_adj.row, coo_adj.col], dtype=torch.long)\n",
        "\n",
        "        bond_feats, labels, mask = [], [], []\n",
        "\n",
        "        for i, j in zip(coo_adj.row, coo_adj.col):\n",
        "            bond = mol.GetBondBetweenAtoms(int(i), int(j))\n",
        "            bt = bond.GetBondType()\n",
        "            f = [int(bt == t) for t in [rdchem.BondType.SINGLE, rdchem.BondType.DOUBLE,\n",
        "                                        rdchem.BondType.TRIPLE, rdchem.BondType.AROMATIC]]\n",
        "            bond_feats.append(f)\n",
        "\n",
        "            stereo = bond.GetStereo()\n",
        "            if stereo == rdchem.BondStereo.STEREOE: labels.append(0); mask.append(1)\n",
        "            elif stereo == rdchem.BondStereo.STEREOZ: labels.append(1); mask.append(1)\n",
        "            else: labels.append(2); mask.append(0)\n",
        "\n",
        "        edge_attr = torch.tensor(bond_feats, dtype=torch.float32)\n",
        "        y = torch.tensor(labels, dtype=torch.long)\n",
        "        train_mask = torch.tensor(mask, dtype=torch.bool)\n",
        "\n",
        "        return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y, train_mask=train_mask)\n",
        "\n",
        "class MultiTaskDataset:\n",
        "    def __init__(self, csv_path, mode='RS'):\n",
        "        self.data_list = []\n",
        "        if mode == 'RS': self.featurizer = RS_Featurizer()\n",
        "        else: self.featurizer = EZ_Featurizer()\n",
        "        df = pd.read_csv(csv_path)\n",
        "        for _, row in tqdm(df.iterrows(), total=len(df), desc=f\"Processing {mode}\"):\n",
        "            mol = Chem.MolFromSmiles(row['Smiles'])\n",
        "            if mol is None: continue\n",
        "            data = self.featurizer(mol)\n",
        "            if data.train_mask.sum() > 0:\n",
        "                self.data_list.append(data)\n",
        "    def __len__(self): return len(self.data_list)\n",
        "    def __getitem__(self, idx): return self.data_list[idx]\n",
        "\n",
        "# 4. æ¨¡å‹\n",
        "class GAT_TaskModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, edge_dim, task_type='node'):\n",
        "        super().__init__()\n",
        "        self.task_type = task_type\n",
        "        self.gat1 = GATConv(input_dim, hidden_dim, heads=2, edge_dim=edge_dim)\n",
        "        self.gat2 = GATConv(hidden_dim * 2, hidden_dim, heads=1, edge_dim=edge_dim)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim if task_type=='node' else hidden_dim*2, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        x = self.gat1(x, edge_index, edge_attr=edge_attr)\n",
        "        x = F.elu(x)\n",
        "        x = self.gat2(x, edge_index, edge_attr=edge_attr)\n",
        "        x = F.elu(x)\n",
        "\n",
        "        if self.task_type == 'node':\n",
        "            return self.classifier(x)\n",
        "        elif self.task_type == 'edge':\n",
        "            row, col = edge_index\n",
        "            edge_features = torch.cat([x[row], x[col]], dim=1)\n",
        "            return self.classifier(edge_features)\n",
        "\n",
        "# 5. è®­ç»ƒä¸è¯„ä¼°\n",
        "def train_task(loader, model, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
        "        mask = batch.train_mask\n",
        "        if mask.sum() == 0: continue\n",
        "        loss = criterion(out[mask], batch.y[mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def eval_task_probs(loader, model):\n",
        "    model.eval()\n",
        "    y_true, y_probs = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
        "            mask = batch.train_mask\n",
        "            if mask.sum() == 0: continue\n",
        "\n",
        "            # Get probabilities for class 1\n",
        "            probs = F.softmax(out[mask], dim=1)[:, 1]\n",
        "\n",
        "            y_true.extend(batch.y[mask].cpu().numpy())\n",
        "            y_probs.extend(probs.cpu().numpy())\n",
        "    return np.array(y_true), np.array(y_probs)\n",
        "\n",
        "def run_task(task_name, dataset, task_type, edge_dim):\n",
        "    print(f\"\\nRunning {task_name} Task...\")\n",
        "    if len(dataset) == 0:\n",
        "        print(\"No data found.\")\n",
        "        return\n",
        "\n",
        "    train_data, test_data = train_test_split(dataset.data_list, test_size=0.2, random_state=42)\n",
        "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_data, batch_size=32)\n",
        "\n",
        "    model = GAT_TaskModel(input_dim=dataset[0].x.shape[1], hidden_dim=32,\n",
        "                          edge_dim=edge_dim, task_type=task_type).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_losses = []\n",
        "    for epoch in range(1, 21):\n",
        "        loss = train_task(train_loader, model, optimizer, criterion)\n",
        "        train_losses.append(loss)\n",
        "        if epoch % 10 == 0: print(f\"Epoch {epoch}: Loss {loss:.4f}\")\n",
        "\n",
        "    y_true, y_probs = eval_task_probs(test_loader, model)\n",
        "    y_pred = (y_probs > 0.5).astype(int)\n",
        "\n",
        "    # Plotting\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "    # 1. Loss Curve\n",
        "    axes[0].plot(train_losses, label='Train Loss')\n",
        "    axes[0].set_title(f'{task_name} - Loss Curve')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].legend()\n",
        "\n",
        "    # 2. Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1])\n",
        "    axes[1].set_title(f'{task_name} - Confusion Matrix')\n",
        "    axes[1].set_xlabel('Predicted')\n",
        "    axes[1].set_ylabel('True')\n",
        "\n",
        "    # 3. ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    axes[2].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    axes[2].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    axes[2].set_xlim([0.0, 1.0])\n",
        "    axes[2].set_ylim([0.0, 1.05])\n",
        "    axes[2].set_xlabel('False Positive Rate')\n",
        "    axes[2].set_ylabel('True Positive Rate')\n",
        "    axes[2].set_title(f'{task_name} - ROC Curve')\n",
        "    axes[2].legend(loc=\"lower right\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"{task_name} Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "\n",
        "# Main execution\n",
        "csv_file = '/content/SweetpredDB.csv'\n",
        "dataset_rs = MultiTaskDataset(csv_file, mode='RS')\n",
        "run_task('R/S Chirality', dataset_rs, 'node', 4)\n",
        "\n",
        "dataset_ez = MultiTaskDataset(csv_file, mode='EZ')\n",
        "run_task('E/Z Isomerism', dataset_ez, 'edge', 4)"
      ],
      "metadata": {
        "id": "94DpO1NB79hs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "X7AN78JLc32N",
        "6QIYUh0E2dZw",
        "7RahmMfxUWFX",
        "4dal0iSwZVDO",
        "cl4HY4dFPxwV",
        "KNmrivCSRars",
        "eQ3tqkb41kuQ",
        "uBhFrCmQSMbE",
        "oCBy0f5P2HuO",
        "JW9c8pshSTcV",
        "wi8AFdXj3wpB",
        "kN3qYfF3aEOT",
        "5wH644LBbiS4",
        "gwgLq4nP4RwN",
        "MZU6VEDFPS4P",
        "DmMm3czRmL6X",
        "cfEujnBuPYKZ",
        "uKfLmxyG4wDd",
        "fM3Z4MVku8bf",
        "FaWefAtTuDK4",
        "VNaefqfn7vPn"
      ],
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2025.10"
      },
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}